<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>cpu-frequency-monitor</title>
      <link href="/2024/08/15/cpu-frequency-monitor/"/>
      <url>/2024/08/15/cpu-frequency-monitor/</url>
      
        <content type="html"><![CDATA[<h2 id="问题">问题</h2><p>频率观察手段的结果各不相同，什么原因，应该以哪个为主？ 1. A grep“core id|cpu MHz” /proc/cpuinfo &gt; cpuinfo.log ; 2. grep ./sys/devices/system/cpu/cpu<em>/cpufreq/cpuinfo_cur_freq &gt;cpuinfo_cur_freq.log; 3. grep ./sys/devices/system/cpu/cpu</em>/cpufreq/scaling_cur_freq 4. cpupowermonitor &gt; cpupower.log</p><h2 id="答案1">答案1</h2><ol type="1"><li>方法拿到的是历史某时刻值</li><li>是当前瞬时值.</li><li>CPU 频率调节器（governor）读取和控制的。</li><li>是实测值。</li></ol><p>优先使用第四种。</p><h2 id="答案2">答案2</h2><p>不同的工具和方法在读取 CPU频率时可能会产生不同的结果，这是因为它们可能从不同的源头获取数据，或者是因为读取数据的时刻不同。以下是每种方法的特点和可能导致结果不同的原因：</p><h3 id="a.-grep-core-idcpu-mhz-proccpuinfo-cpuinfo.log">a.<code>grep "core id\|cpu MHz" /proc/cpuinfo &gt; cpuinfo.log</code></h3><p><code>/proc/cpuinfo</code> 文件是 Linux内核提供的一个虚拟文件，包含了关于 CPU的各种信息，包括每个核心的当前频率 (<code>cpu MHz</code>)。</p><ul><li><strong>特点</strong>：信息是从内核直接读取的，通常是当前的频率。</li><li><strong>可能的原因</strong>：<code>/proc/cpuinfo</code>中的频率数据是动态的，可能在读取的瞬间发生变化。</li></ul><h3 id="b.-grep-.-sysdevicessystemcpucpucpufreqcpuinfo_cur_freq-cpuinfo_cur_freq.log">b.<code>grep . /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_cur_freq &gt; cpuinfo_cur_freq.log</code></h3><p><code>/sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_cur_freq</code>文件显示每个核心的当前频率。</p><ul><li><strong>特点</strong>：提供了每个核心的实时频率。</li><li><strong>可能的原因</strong>：这个文件显示的是内核中保存的当前频率值，可能会与<code>/proc/cpuinfo</code>中的信息略有不同，尤其是在频率快速变化时。</li></ul><h3 id="c.-grep-.-sysdevicessystemcpucpucpufreqscaling_cur_freq">c.<code>grep . /sys/devices/system/cpu/cpu*/cpufreq/scaling_cur_freq</code></h3><p><code>/sys/devices/system/cpu/cpu*/cpufreq/scaling_cur_freq</code>文件也显示每个核心的当前频率，但这个值是由 CPU频率调节器（governor）读取和控制的。</p><ul><li><strong>特点</strong>：显示的是由频率调节器管理的频率。</li><li><strong>可能的原因</strong>：这个值可能更接近于系统实际使用的频率，因为它是由频率调节器直接管理的。</li></ul><h3 id="d.-cpupower-monitor-cpupower.log">d.<code>cpupower monitor &gt; cpupower.log</code></h3><p><code>cpupower monitor</code> 是一个更高级的工具，可以监控 CPU的各种参数，包括频率、功耗等。</p><ul><li><strong>特点</strong>：提供更详细和实时的频率监控数据。</li><li><strong>可能的原因</strong>：<code>cpupower</code>工具可能会在更细粒度的时间间隔内读取频率，从而提供更即时的信息。</li></ul><h3 id="为什么结果不同">为什么结果不同？</h3><ol type="1"><li><strong>读取时间不同</strong>：各个工具和方法在不同的时间点读取频率，可能会有差异，尤其是在频率快速变化时。</li><li><strong>数据源不同</strong>：不同的方法可能从不同的内核数据结构中获取频率信息，导致结果略有不同。</li><li><strong>频率调节器的影响</strong>：频率调节器（governor）可能会影响频率的读取和显示，尤其是在节能模式和高性能模式之间切换时。</li></ol><h3 id="应该以哪个为主">应该以哪个为主？</h3><ul><li><strong>综合考虑</strong>：如果你需要非常准确和详细的频率信息，建议综合使用多种工具和方法。</li><li><strong>实时监控</strong>：如果需要实时监控，<code>cpupower monitor</code>和 <code>scaling_cur_freq</code> 通常会提供更准确的即时数据。</li><li><strong>系统分析</strong>：对于系统分析和调试，<code>/proc/cpuinfo</code>和 <code>cpuinfo_cur_freq</code> 可能会提供足够的信息。</li></ul><p>具体选择哪个方法取决于你的需求和具体应用场景。如果需要一致性，建议选择一个方法并一致使用。此外，了解各个工具的特点和读取机制，有助于更好地解释和理解结果的差异。</p>]]></content>
      
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Async-RTL</title>
      <link href="/2024/08/14/Async-RTL/"/>
      <url>/2024/08/14/Async-RTL/</url>
      
        <content type="html"><![CDATA[<p>异步时钟传输是指在没有共享时钟信号的情况下，数据在不同时钟域之间的传输。异步时钟传输可以分为单bit传输和多bit传输。每种传输方式都有不同的方法和挑战。</p><h3 id="单bit传输">单bit传输</h3><p>单bit传输通常用于简单的信号传递，例如控制信号。因为只涉及一个比特，这种传输方式相对简单，主要关注信号的稳定性和正确同步。常见方法有：</p><ol type="1"><li><strong>双FF同步器（Two Flip-Flop Synchronizer）</strong>：<ul><li><strong>工作原理</strong>：将输入信号通过两个串联的触发器（Flip-Flop），这样可以有效地减少亚稳态（Metastability）的概率。</li><li><strong>优点</strong>：简单、可靠。</li><li><strong>缺点</strong>：可能会有一个时钟周期的延迟。</li><li><strong>电路示例</strong>： <figure class="highlight verilog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> synchronizer (</span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> clk,      <span class="comment">// 目标时钟域</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> async_in, <span class="comment">// 异步输入信号</span></span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">wire</span> sync_out <span class="comment">// 同步输出信号</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> ff1, ff2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk) <span class="keyword">begin</span></span><br><span class="line">    ff1 &lt;= async_in;</span><br><span class="line">    ff2 &lt;= ff1;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assign</span> sync_out = ff2;</span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></tbody></table></figure></li></ul></li></ol><h3 id="多bit传输">多bit传输</h3><p>多bit传输涉及到多个数据位的同步传输，通常用在数据总线、地址总线等场景。由于多个比特需要同时传输，面临的问题更复杂。一些常用方法包括：</p><ol type="1"><li><strong>握手协议（Handshake Protocol）</strong>：<ul><li><strong>工作原理</strong>：发送方和接收方通过握手信号（如有效信号valid、确认信号acknowledge）来协调数据传输。</li><li><strong>优点</strong>：可靠性高，适用于任意数量的数据位。</li><li><strong>缺点</strong>：复杂度较高，传输速度可能较慢。</li><li><strong>电路示例</strong>： <figure class="highlight verilog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> async_fifo (</span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> wr_clk,          <span class="comment">// 写时钟</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> rd_clk,          <span class="comment">// 读时钟</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> [<span class="number">7</span>:<span class="number">0</span>] din,       <span class="comment">// 写数据</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> wr_en,           <span class="comment">// 写使能</span></span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">wire</span> [<span class="number">7</span>:<span class="number">0</span>] dout,     <span class="comment">// 读数据</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> rd_en,           <span class="comment">// 读使能</span></span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">wire</span> empty,          <span class="comment">// FIFO空标志</span></span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">wire</span> full            <span class="comment">// FIFO满标志</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// FIFO实现细节省略</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></tbody></table></figure></li></ul></li><li><strong>异步FIFO（Asynchronous FIFO）</strong>：<ul><li><strong>工作原理</strong>：利用FIFO（先进先出队列）来缓冲在不同时钟域之间传输的数据。写操作和读操作分别在不同的时钟域中进行。</li><li><strong>优点</strong>：适合高吞吐量、多比特传输。</li><li><strong>缺点</strong>：实现和验证较复杂。</li><li><strong>电路示例</strong>： <figure class="highlight verilog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> async_fifo (</span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> wr_clk,          <span class="comment">// 写时钟</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> rd_clk,          <span class="comment">// 读时钟</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> [<span class="number">7</span>:<span class="number">0</span>] din,       <span class="comment">// 写数据</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> wr_en,           <span class="comment">// 写使能</span></span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">wire</span> [<span class="number">7</span>:<span class="number">0</span>] dout,     <span class="comment">// 读数据</span></span><br><span class="line">    <span class="keyword">input</span> <span class="keyword">wire</span> rd_en,           <span class="comment">// 读使能</span></span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">wire</span> empty,          <span class="comment">// FIFO空标志</span></span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">wire</span> full            <span class="comment">// FIFO满标志</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// FIFO实现细节省略</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></tbody></table></figure></li></ul></li><li><strong>Gray Code 编码</strong>：<ul><li><strong>工作原理</strong>：在多比特传输中，使用GrayCode编码可以减少传输过程中数据变化的比特数，从而减少亚稳态的概率。</li><li><strong>优点</strong>：减少同步误差。</li><li><strong>缺点</strong>：需要额外的编码和解码逻辑。</li><li><strong>电路示例</strong>： <figure class="highlight 1c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Gray Code转换逻辑省略</span></span><br></pre></td></tr></tbody></table></figure></li></ul></li></ol><h3 id="总结">总结</h3><ul><li><strong>单bit传输</strong>：主要使用双FF同步器，简单高效。</li><li><strong>多bit传输</strong>：可以使用握手协议、异步FIFO和GrayCode编码等方法，根据应用场景选择合适的方式。</li></ul><p>每种方法都有其适用的场景和优缺点，设计时需要根据具体需求进行选择和优化。</p>]]></content>
      
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ISA-Diff</title>
      <link href="/2024/08/14/ISA-Diff/"/>
      <url>/2024/08/14/ISA-Diff/</url>
      
        <content type="html"><![CDATA[<p>当然，以下是x86、POWER、ARM和RISC-V架构中缓存管理指令、同步管理指令以及TLB（TranslationLookaside Buffer）管理指令的完整对比和描述。</p><hr><h2 id="总结">总结</h2><p>以下是x86、POWER、ARM和RISC-V架构在缓存管理、同步管理和TLB管理指令上的对比：</p><ul><li><strong>缓存管理指令</strong>：<ul><li><strong>x86</strong>：CLFLUSH, CLFLUSHOPT, CLWB, MFENCE</li><li><strong>POWER</strong>：dcbf, dcbst, icbi, sync</li><li><strong>ARM</strong>：DC CIVAC, DC CVAC, DC IVAC, ISB</li><li><strong>RISC-V</strong>：FENCE, FENCE.I</li></ul></li><li><strong>同步管理指令</strong>：<ul><li><strong>x86</strong>：LOCK前缀, XCHG, XADD</li><li><strong>POWER</strong>：lwarx, stwcx., sync</li><li><strong>ARM</strong>：LDREX, STREX, DMB, DSB</li><li><strong>RISC-V</strong>：LR.W, SC.W, AMO指令</li></ul></li><li><strong>TLB管理指令</strong>：<ul><li><strong>x86</strong>：INVLPG, MOV to CR3</li><li><strong>POWER</strong>：tlbie, tlbsync</li><li><strong>ARM</strong>：TLBI, DSB ISH</li><li><strong>RISC-V</strong>：SFENCE.VMA, HFENCE.VVMA</li></ul></li></ul><h2 id="同步管理指令对比">同步管理指令对比</h2><p>在处理器架构中，同步管理指令用于确保多线程或多核环境下的内存操作顺序和一致性。这些指令在不同的架构中有不同的实现方式和命名。以下是x86、POWER、ARM和RISC-V架构中同步管理指令的详细对比。</p><h3 id="x86架构的同步管理指令"><strong>x86架构的同步管理指令</strong></h3><p>x86架构提供了一组丰富的同步管理指令，主要用于内存屏障和I/O同步。这些指令包括：</p><ul><li><strong>MFENCE</strong>:确保所有之前的内存读写操作完成，适用于所有类型的内存访问。</li><li><strong>LFENCE</strong>:确保所有之前的读操作完成，通常用于内存读操作的同步。</li><li><strong>SFENCE</strong>:确保所有之前的写操作完成，通常用于内存写操作的同步。</li><li><strong>LOCK前缀</strong>:用于原子操作指令前，确保该指令在多处理器环境中的原子性。例如，<code>LOCK XCHG</code>指令。</li></ul><h3 id="power架构的同步管理指令"><strong>POWER架构的同步管理指令</strong></h3><p>POWER架构提供了一组同步管理指令，主要用于确保内存操作和指令执行的顺序。这些指令包括：</p><ul><li><strong>sync</strong>:全局同步指令，确保所有之前的读写操作完成，并且在多处理器环境中同步所有处理器的视图。</li><li><strong>lwsync (Light-Weight Sync)</strong>:轻量级同步指令，确保之前的存储操作在同一个处理器上完成，但不保证全局同步。</li><li><strong>eieio (Enforce In-Order Execution of I/O)</strong>:确保I/O操作按照程序顺序执行，主要用于I/O设备的同步。</li><li><strong>isync</strong>:确保之前的所有指令执行完成，通常用于指令流的同步，确保后续指令不会被重新排列。</li><li><strong>lwarx (Load Word and Reserve Indexed)</strong>:加载并保留，用于实现原子操作。</li><li><strong>stwcx. (Store Word Conditional Indexed)</strong>:条件存储，如果保留仍有效，则存储成功，用于实现原子操作。</li></ul><h3 id="arm架构的同步管理指令"><strong>ARM架构的同步管理指令</strong></h3><p>ARM架构（如ARMv8）提供了一组同步管理指令，用于确保内存操作的顺序和一致性。这些指令包括：</p><ul><li><strong>DSB (Data Synchronization Barrier)</strong>:确保所有之前的内存读写操作完成，适用于所有类型的内存访问。</li><li><strong>DMB (Data Memory Barrier)</strong>:确保之前的内存操作按照指定的顺序完成，可以指定不同的内存域（如系统域或内存域）。</li><li><strong>ISB (Instruction Synchronization Barrier)</strong>:确保之前的所有指令执行完成，通常用于指令流的同步，确保后续指令不会被重新排列。</li><li><strong>LDREX/STREX (Load-Exclusive/Store-Exclusive)</strong>:用于实现原子操作。ARMv8-A引入了更为细粒度的指令：<ul><li><strong>LDAXR/STLXR (Load-Acquire/Store-Release)</strong>:用于实现同步的原子操作。</li><li><strong>LDXR/STXR (Load-Exclusive/Store-Exclusive)</strong>:通用的原子操作。</li></ul></li><li><strong>CAS (Compare-And-Swap)</strong>:ARMv8.1引入的比较并交换指令，用于原子操作。</li><li><strong>SWP (Swap)</strong>:交换指令，用于将寄存器值与内存中的值进行交换。</li></ul><h3 id="risc-v架构的同步管理指令"><strong>RISC-V架构的同步管理指令</strong></h3><p>RISC-V架构的同步管理指令相对简洁，主要包括内存屏障和I/O同步指令。这些指令包括：</p><ul><li><strong>FENCE</strong>:用于内存和I/O访问的同步操作，确保之前的所有内存和I/O操作完成。可以通过参数指定同步的类型和范围，如<code>FENCE rw,rw</code> 表示所有读写操作的屏障。</li><li><strong>FENCE.I</strong>:确保之前的所有指令已被处理，通常用于指令流的同步，确保后续指令不会被重新排列。</li><li><strong>LR/SC (Load-Reserved/Store-Conditional)</strong>:用于实现原子操作：<ul><li><strong>LR.W</strong>: 加载保留字。</li><li><strong>SC.W</strong>: 条件存储字，如果保留仍有效，则存储成功。</li></ul></li><li><strong>AMO指令 (Atomic Memory Operations)</strong>:包括一系列的原子内存操作指令，如：<ul><li><strong>AMOSWAP</strong>: 原子交换。</li><li><strong>AMOADD</strong>: 原子加法。</li><li><strong>AMOXOR</strong>: 原子异或。</li><li><strong>AMOAND</strong>: 原子与。</li><li><strong>AMOMIN</strong>: 原子最小值。</li><li><strong>AMOMAX</strong>: 原子最大值。</li><li><strong>AMOMINU</strong>: 无符号原子最小值。</li><li><strong>AMOMAXU</strong>: 无符号原子最大值。</li></ul></li></ul><h3 id="总结-1">总结</h3><ul><li><strong>x86架构</strong>：提供了丰富的同步管理指令，包括内存屏障和I/O同步，适用于多处理器环境中的强一致性要求。</li><li><strong>POWER架构</strong>：提供了多种同步管理指令，涵盖全局同步、轻量级同步和I/O同步，适用于高性能计算和企业级应用。</li><li><strong>ARM架构</strong>：提供了一组同步管理指令，用于确保内存操作的顺序和一致性，广泛应用于移动设备和嵌入式系统。</li><li><strong>RISC-V架构</strong>：同步管理指令相对简洁，主要包括内存屏障和I/O同步，具有高度的灵活性和可扩展性。</li></ul><p>各个架构在同步管理指令上的设计反映了其自身的设计目标和应用需求，选择哪种架构通常取决于具体的应用场景和一致性要求。</p><h2 id="cache管理指令对比">cache管理指令对比</h2><p>POWER、ARM 和 RISC-V处理器架构在缓存管理指令方面有一些显著的区别和特点。缓存管理指令用于控制和优化缓存的行为，以提高处理器性能和数据一致性。以下是对这三种架构的缓存管理指令的对比：</p><h3 id="power架构的缓存管理指令"><strong>POWER架构的缓存管理指令</strong></h3><p>POWER架构（如POWER8和POWER9）提供了一组丰富的缓存管理指令，主要用于控制缓存的行为和保持数据一致性。这些指令包括：</p><ul><li><strong>dcbf (Data Cache Block Flush)</strong>:将指定地址的缓存块从数据缓存中清除。如果该缓存块被修改过，则将其写回到主存。</li><li><strong>dcbst (Data Cache Block Store)</strong>:将指定地址的缓存块写回主存，但不从缓存中清除。</li><li><strong>dcbt (Data Cache Block Touch)</strong>:预取指定地址的缓存块到数据缓存中，以便后续访问更快。</li><li><strong>dcbtst (Data Cache Block Touch for Store)</strong>:类似于dcbt，但专门针对即将写入的数据进行预取。</li><li><strong>dcbi (Data Cache Block Invalidate)</strong>:将指定地址的缓存块从数据缓存中无效化，不进行写回操作。</li><li><strong>icbi (Instruction Cache Block Invalidate)</strong>:将指定地址的缓存块从指令缓存中无效化。</li><li><strong>sync</strong>: 确保所有之前的存储操作完成。</li><li><strong>isync</strong>: 确保之前的指令执行完成。</li></ul><h3 id="arm架构的缓存管理指令"><strong>ARM架构的缓存管理指令</strong></h3><p>ARM架构（如ARMv8）同样提供了一组缓存管理指令，用于优化缓存行为和维护数据一致性。这些指令包括：</p><ul><li><strong>DC ZVA (Data Cache Zero by Virtual Address)</strong>:将一个缓存线清零。</li><li><strong>DC IVAC (Data Cache Invalidate by Virtual Address toPoC)</strong>: 使指定虚拟地址的缓存块无效。</li><li><strong>DC ISW (Data Cache Invalidate by Set/Way)</strong>:按照set/way无效缓存。</li><li><strong>DC CSW (Data Cache Clean by Set/Way)</strong>:按照set/way清理缓存。</li><li><strong>DC CVAU (Data Cache Clean by Virtual Address toPoU)</strong>: 将指定虚拟地址的缓存块写回到主存。</li><li><strong>DC CVAP (Data Cache Clean by Virtual Address toPoP)</strong>: 将指定虚拟地址的缓存块写回到持久存储。</li><li><strong>DC CVAC (Data Cache Clean by Virtual Address toPoC)</strong>: 将指定虚拟地址的缓存块写回到主存并保持在缓存中。</li><li><strong>IC IVAU (Instruction Cache Invalidate by Virtual Address toPoU)</strong>: 使指定虚拟地址的指令缓存块无效。</li><li><strong>IC IALLU (Instruction Cache Invalidate All to PoU)</strong>:无效所有指令缓存。</li><li><strong>DSB (Data Synchronization Barrier)</strong>:确保所有之前的存储操作完成。</li><li><strong>ISB (Instruction Synchronization Barrier)</strong>:确保之前的指令执行完成。</li></ul><h3 id="risc-v架构的缓存管理指令"><strong>RISC-V架构的缓存管理指令</strong></h3><p>RISC-V架构相对于POWER和ARM，缓存管理指令较为简单和灵活。RISC-V的缓存管理指令集往往依赖于具体的实现和扩展。以下是一些常见的缓存管理指令：</p><ul><li><strong>SFENCE.VMA (Supervisor Memory Management Fence for VirtualMemory Area)</strong>:用于虚拟内存管理的同步操作，确保之前的所有内存访问完成。</li><li><strong>FENCE</strong>:用于内存和I/O访问的同步操作，确保之前的所有内存和I/O操作完成。</li></ul><p>RISC-V的缓存管理指令没有ARM和POWER那么丰富，主要是因为RISC-V追求简洁和模块化设计。具体的缓存管理操作可能由特定的实现和扩展提供，例如通过自定义的控制寄存器或特定的指令集扩展。### <strong>x86架构的缓存管理指令</strong>x86架构（包括Intel和AMD处理器）有一组丰富的缓存管理指令，主要用于控制缓存行为、优化性能和维护数据一致性。这些指令包括：</p><ul><li><strong>CLFLUSH</strong>:刷新指定地址的缓存行，将其从缓存中清除并写回内存。</li><li><strong>CLFLUSHOPT</strong>:类似于CLFLUSH，但具有更好的性能优化。</li><li><strong>CLWB (Cache Line Write Back)</strong>:将缓存行写回内存但不清除缓存行。</li><li><strong>INVD</strong>: 使整个数据缓存无效，不进行写回操作。</li><li><strong>WBINVD</strong>: 将整个缓存内容写回内存并清除缓存。</li><li><strong>PREFETCHNTA, PREFETCHT0, PREFETCHT1, PREFETCHT2</strong>:预取数据到缓存中，不同级别的预取指令用于不同的缓存层级优化（如L1、L2、L3）。</li></ul><h3 id="总结-2">总结</h3><ul><li><p><strong>POWER架构</strong>：提供了丰富的缓存管理指令，能够对缓存进行细粒度的控制，适用于高性能计算和企业级应用。</p></li><li><p><strong>ARM架构</strong>：同样提供了一组丰富的缓存管理指令，涵盖数据缓存和指令缓存的各种操作，适用于广泛的应用场景，包括移动设备和嵌入式系统。</p></li><li><p><strong>RISC-V架构</strong>：缓存管理指令相对简洁，依赖于具体的实现和扩展。这种设计使RISC-V具有高度的灵活性和可扩展性。</p></li><li><p><strong>x86架构</strong>：提供了详细的缓存管理指令，能够进行缓存刷新、写回和预取等操作，适用于高性能桌面和服务器环境。</p></li></ul><p>每种架构在缓存管理指令上的设计都反映了其自身的设计目标和应用需求，选择哪种架构通常取决于具体的应用场景和性能需求。</p><h2 id="tlb管理指令">TLB管理指令</h2><h3 id="x86架构">x86架构</h3><ul><li><strong>INVLPG (Invalidate TLB Entry)</strong><ul><li><strong>语法</strong>：<code>INVLPG [mem]</code></li><li><strong>用途</strong>：使指定虚拟地址的TLB条目无效。用于确保某个特定地址的页表更改被正确反映。</li><li><strong>示例</strong>：<code>INVLPG [rax]</code>使寄存器<code>rax</code>指向的地址的TLB条目无效。</li></ul></li><li><strong>MOV to CR3</strong><ul><li><strong>语法</strong>：<code>MOV CR3, r32</code></li><li><strong>用途</strong>：加载CR3寄存器，刷新整个TLB。CR3寄存器通常保存页表基地址，更新CR3会导致整个TLB被刷新。</li><li><strong>示例</strong>：<code>MOV CR3, rax</code>使用寄存器<code>rax</code>的值更新CR3寄存器，刷新TLB。</li></ul></li><li><strong>INVPCID (Invalidate Process-Context Identifier)</strong><ul><li><strong>语法</strong>：<code>INVPCID r32, m128</code></li><li><strong>用途</strong>：使具有特定PCID（Process-ContextIdentifier）的TLB条目无效。支持细粒度的TLB管理，包括单个地址、单个PCID或整个上下文。</li><li><strong>示例</strong>：<ul><li><code>INVPCID eax, [rcx]</code>使寄存器<code>eax</code>和<code>rcx</code>指向的PCID和地址条目无效。</li><li>用于虚拟化和多进程环境，以提高性能。</li></ul></li></ul></li></ul><h3 id="power架构">POWER架构</h3><ul><li><strong>tlbie (TLB Invalidate Entry)</strong><ul><li><strong>语法</strong>：<code>tlbie RA</code></li><li><strong>用途</strong>：使特定的TLB条目无效。用于在页表更新后无效化某个特定地址的TLB条目。</li><li><strong>示例</strong>：<code>tlbie r3</code>使寄存器<code>r3</code>指向的地址的TLB条目无效。</li></ul></li><li><strong>tlbia (TLB Invalidate All)</strong><ul><li><strong>语法</strong>：<code>tlbia</code></li><li><strong>用途</strong>：使所有TLB条目无效。用于彻底刷新TLB。</li><li><strong>示例</strong>：<code>tlbia</code> 使整个TLB无效。</li></ul></li><li><strong>tlbsync</strong><ul><li><strong>语法</strong>：<code>tlbsync</code></li><li><strong>用途</strong>：同步TLB操作。确保所有先前的TLB无效化操作完成。</li><li><strong>示例</strong>：<code>tlbsync</code>确保所有先前的TLB操作已完成。</li></ul></li></ul><h3 id="arm架构">ARM架构</h3><ul><li><strong>TLBI (TLB Invalidate)</strong><ul><li><strong>语法</strong>：<code>TLBI &lt;type&gt; [&lt;Xt&gt;]</code></li><li><strong>用途</strong>：使TLB条目无效。可以无效化整个TLB或特定条目。<type>参数指定无效化的范围，如<code>VMALLE1</code>表示无效化所有EL1的TLB条目。</type></li><li><strong>示例</strong>：<ul><li><code>TLBI VMALLE1</code> 使所有EL1的TLB条目无效。</li><li><code>TLBI VAE1, &lt;Xt&gt;</code>使寄存器<code>Xt</code>指向的虚拟地址的TLB条目无效。</li></ul></li></ul></li><li><strong>DSB (Data Synchronization Barrier)</strong><ul><li><strong>语法</strong>：<code>DSB ISH</code></li><li><strong>用途</strong>：数据同步屏障。确保所有先前的内存访问完成，常与TLBI一起使用以确保TLB无效化操作完成。</li><li><strong>示例</strong>：<code>DSB ISH</code>确保所有先前的内存访问已完成。</li></ul></li><li><strong>ISB (Instruction Synchronization Barrier)</strong><ul><li><strong>语法</strong>：<code>ISB</code></li><li><strong>用途</strong>：指令同步屏障。确保之前的所有指令完成，常用于自修改代码。</li><li><strong>示例</strong>：<code>ISB</code>确保所有先前的指令已完成。</li></ul></li></ul><h3 id="risc-v架构">RISC-V架构</h3><ul><li><strong>SFENCE.VMA (Supervisor Fence Virtual Memory Access)</strong><ul><li><strong>语法</strong>：<code>SFENCE.VMA rs1, rs2</code></li><li><strong>用途</strong>：刷新虚拟内存访问。用于刷新整个TLB或特定地址范围的TLB条目。</li></ul></li><li><strong>HFENCE.VVMA (Hypervisor Fence Virtual MemoryAccess)</strong><ul><li><strong>语法</strong>：<code>HFENCE.VVMA rs1, rs2</code></li><li><strong>用途</strong>：指令用于刷新虚拟机的虚拟地址转换缓存（如TLB，Translation LookasideBuffer）。当虚拟机监控器（hypervisor）更改了虚拟机的页表条目或者其他影响虚拟地址映射的参数时，需要执行这个指令来确保这些更改对虚拟机是可见的。这个指令确保了在执行它之后的指令看到的是最新的地址映射。</li></ul></li><li><strong>HFENCE.GVMA(Hypervisor Guest VMA Fence)</strong><ul><li><strong>语法</strong>：<code>HFENCE.VVMA rs1, rs2</code></li><li><strong>用途</strong>：指令用于刷新嵌套虚拟化环境中的客户虚拟机（guestvirtualmachine）的虚拟地址转换缓存。在嵌套虚拟化中，一个虚拟机内部运行着另一个虚拟机。当外层虚拟机（也就是客户虚拟机的监控器）更改了内层虚拟机的页表条目或其他影响地址映射的参数时，需要执行<code>HFENCE.GVMA</code> 指令来确保这些更改对内层虚拟机是可见的。</li></ul></li></ul><h3 id="对比和区别">对比和区别</h3><ol type="1"><li><strong>指令数量和复杂性</strong>：<ul><li><strong>x86</strong>：提供的指令较少但功能集中（INVLPG、MOV toCR3、INVPCID）。</li><li><strong>POWER</strong>：提供了细粒度控制和同步（tlbie、tlbia、tlbsync）。</li><li><strong>ARM</strong>：提供了多种无效化选项和同步（TLBI、DSB、ISB）。</li><li><strong>RISC-V</strong>：提供了针对不同使用场景的指令（SFENCE.VMA、HFENCE.VVMA），灵活性更高。</li></ul></li><li><strong>指令用途和范围</strong>：<ul><li><strong>x86</strong>：INVLPG和MOV toCR3分别用于单个地址和整个TLB的刷新，INVPCID支持细粒度的TLB管理。</li><li><strong>POWER</strong>：tlbie用于单个地址的TLB无效化，tlbia用于整个TLB无效化，tlbsync确保TLB操作完成。</li><li><strong>ARM</strong>：TLBI提供了多种无效化选项，DSB确保操作顺序，ISB用于指令同步。</li><li><strong>RISC-V</strong>：SFENCE.VMA和HFENCE.VVMA提供了针对普通和虚拟化环境的TLB刷新指令。</li></ul></li><li><strong>应用场景</strong>：<ul><li><strong>x86</strong>：适用于需要快速无效化单个地址或整个TLB切换的场景，支持多进程和虚拟化环境。</li><li><strong>POWER</strong>：适用于需要细粒度控制和同步的场景，提供了全面的TLB管理。</li><li><strong>ARM</strong>：适用于需要多种无效化选项和同步的场景（特别是嵌入式和移动设备）。</li><li><strong>RISC-V</strong>：适用于灵活的TLB管理需求，特别是支持虚拟化的场景。</li></ul></li></ol><p>通过以上对比，可以看出不同架构在TLB管理指令上各有特色，适用于不同的应用场景和需求。开发者可以根据具体的应用需求选择适合的指令集架构和相应的TLB管理指令。</p><h2 id="指令预取到哪一级缓存">指令预取到哪一级缓存</h2><p>在处理器架构中，缓存管理指令能否指定将数据或指令预取到哪一级缓存（L1、L2或更高）取决于具体的架构和实现。以下是对于 POWER、ARM 和 RISC-V架构缓存管理指令在这方面的支持情况的详细说明。</p><h3 id="power架构-1">POWER架构</h3><p>在POWER架构中，缓存管理指令的设计相对丰富，提供了多种缓存控制功能。然而，具体到预取到哪一级缓存，POWER架构的指令集并没有直接提供细粒度的控制选项。通常，预取操作（如<code>dcbt</code> 和<code>dcbtst</code>）是由硬件自动决定预取的目标缓存层级。硬件会根据预取策略和当前的缓存层级来决定数据应该预取到L1缓存还是L2缓存。</p><h3 id="arm架构-1">ARM架构</h3><p>ARM架构（如ARMv8）提供了一些更细粒度的缓存管理指令，但同样没有明确的指令可以直接指定将数据或指令预取到特定的缓存层级。预取指令（如<code>PRFM</code>指令）允许预取数据到缓存中，但具体的缓存层级由硬件实现决定。硬件预取机制会根据当前的系统配置和缓存层级自动选择最合适的缓存层级进行预取。</p><p>ARM架构的缓存管理指令如 <code>DC</code> 系列和 <code>IC</code>系列指令，主要用于操作特定地址范围的缓存块，包括清理、无效化和写回等操作，但它们也没有直接控制缓存层级的功能。</p><h3 id="risc-v架构-1">RISC-V架构</h3><p>RISC-V架构的缓存管理指令集相对简洁且灵活，通常依赖于具体实现和扩展。RISC-V没有标准化的指令来指定预取到特定缓存层级。缓存控制和预取策略通常由硬件实现负责，具体的行为可能通过自定义扩展或特定的控制寄存器来实现。</p><p>例如，某些RISC-V实现可能会提供特定的控制寄存器或自定义指令来实现预取操作，但这些通常不是RISC-V标准指令集的一部分。</p><h3 id="总结-3">总结</h3><p>总体而言，虽然POWER、ARM和RISC-V处理器架构提供了丰富的缓存管理指令，但它们通常没有直接的指令来指定将数据或指令预取到特定的缓存层级。预取操作的目标缓存层级通常由硬件自动决定，基于当前系统配置和预取策略。</p><ul><li><strong>POWER架构</strong>：预取操作由硬件决定目标缓存层级。</li><li><strong>ARM架构</strong>：预取指令如 <code>PRFM</code>由硬件决定目标缓存层级。</li><li><strong>RISC-V架构</strong>：标准指令集中没有预取到特定缓存层级的指令，具体实现可能提供自定义方法。</li></ul><p>各个架构在缓存管理上的设计反映了其追求平衡性能和灵活性的不同策略。对于特定应用场景，深入理解硬件实现和预取策略是优化性能的关键。</p><p>非常感谢您的指正。您的观察是正确的。POWER架构确实有事务指令，而ARM和RISC-V架构都使用了LR/SC指令。以下是修正和补充后的信息：</p><hr><h2 id="各架构独有的特殊指令对比">各架构独有的特殊指令对比</h2><h3 id="x86架构特殊指令"><strong>x86架构特殊指令</strong></h3><ul><li><strong>REP指令前缀</strong>：<ul><li><code>REP MOVSB</code>, <code>REP MOVSW</code>,<code>REP MOVSD</code>: 按字节、字、双字拷贝数据。</li><li><code>REP STOSB</code>, <code>REP STOSW</code>,<code>REP STOSD</code>: 按字节、字、双字设置数据。</li><li><code>REP SCASB</code>, <code>REP SCASW</code>,<code>REP SCASD</code>: 按字节、字、双字扫描数据。</li><li><code>REP LODSB</code>, <code>REP LODSW</code>,<code>REP LODSD</code>: 按字节、字、双字加载数据。</li></ul></li><li><strong>XLAT</strong>: 翻译字节到表项，通过查找表进行数据转换。</li><li><strong>BSWAP</strong>: 字节交换，将寄存器中的字节顺序反转。</li><li><strong>CPUID</strong>: 获取处理器信息和功能标识。</li><li><strong>RDTSC</strong>: 读取时间戳计数器，用于高精度计时。</li><li><strong>RDMSR/WRMSR</strong>: 读取/写入Model-SpecificRegister（MSR），用于访问处理器的特定功能。</li><li><strong>SYSENTER/SYSEXIT</strong>:快速系统调用和返回指令，用于提高系统调用的效率。</li><li><strong>XADD</strong>:交换并加法，原子性地交换两个操作数并执行加法。</li></ul><h3 id="power架构特殊指令"><strong>POWER架构特殊指令</strong></h3><ul><li><strong>Transactional Memory (事务内存指令)</strong>：<ul><li><strong>tbegin.</strong>: 开始一个事务。</li><li><strong>tend.</strong>: 结束一个事务。</li><li><strong>tabort.</strong>: 中止一个事务。</li><li><strong>tcheck.</strong>: 检查事务状态。</li></ul></li><li><strong>mfcr (Move from Condition Register)</strong>:从条件寄存器中移动数据。</li><li><strong>mtcrf (Move to Condition Register Fields)</strong>:将数据移动到条件寄存器的特定字段。</li><li><strong>mfspr (Move from Special Purpose Register)</strong>:从特殊用途寄存器中移动数据。</li><li><strong>mtspr (Move to Special Purpose Register)</strong>:将数据移动到特殊用途寄存器。</li><li><strong>mtmsr (Move to Machine State Register)</strong>:将数据移动到机器状态寄存器。</li><li><strong>mfsr (Move from Segment Register)</strong>:从段寄存器中移动数据。</li><li><strong>mtsr (Move to Segment Register)</strong>:将数据移动到段寄存器。</li><li><strong>rlwimi (Rotate Left Word Immediate then MaskInsert)</strong>: 左旋转字并插入掩码。</li><li><strong>rlwinm (Rotate Left Word Immediate then AND withMask)</strong>: 左旋转字并与掩码进行AND操作。</li><li><strong>dcbz (Data Cache Block Zero)</strong>:将数据缓存块清零。</li></ul><h3 id="arm架构特殊指令"><strong>ARM架构特殊指令</strong></h3><ul><li><strong>UDF (Undefined Instruction)</strong>:生成未定义指令异常，用于调试和陷阱。</li><li><strong>SVC (Supervisor Call)</strong>:生成一个系统调用异常，进入特权模式。</li><li><strong>MCR/MRC (Move to/from Coprocessor)</strong>:将数据移动到协处理器或从协处理器移动数据。</li><li><strong>VMOV (Vector Move)</strong>: 在NEON寄存器之间移动数据。</li><li><strong>VADD (Vector Add)</strong>:在NEON寄存器中执行向量加法。</li><li><strong>VMLA/VMLS (Vector Multiply-Accumulate/Subtract)</strong>:在NEON寄存器中执行向量乘法并累加或减去。</li><li><strong>PLD (Preload Data)</strong>: 预取数据到缓存中。</li><li><strong>WFI (Wait For Interrupt)</strong>:进入低功耗状态等待中断。</li><li><strong>WFE (Wait For Event)</strong>: 进入低功耗状态等待事件。</li><li><strong>LDREX/STREX (Load-Exclusive/Store-Exclusive)</strong>:用于实现原子操作。ARMv8-A引入了更为细粒度的指令：<ul><li><strong>LDAXR/STLXR (Load-Acquire/Store-Release)</strong>:用于实现同步的原子操作。</li><li><strong>LDXR/STXR (Load-Exclusive/Store-Exclusive)</strong>:通用的原子操作。</li></ul></li></ul><h3 id="risc-v架构特殊指令"><strong>RISC-V架构特殊指令</strong></h3><ul><li><strong>ECALL (Environment Call)</strong>:生成一个环境调用异常，通常用于系统调用。</li><li><strong>EBREAK (Environment Breakpoint)</strong>:生成一个环境断点异常，通常用于调试。</li><li><strong>FENCE</strong>: 内存屏障指令，用于同步内存和I/O操作。</li><li><strong>FENCE.I</strong>:指令屏障，确保之前的所有指令已被处理。</li><li><strong>CSR指令 (Control and Status Register)</strong>:<ul><li><strong>CSRRW (Read and Write CSR)</strong>:读取和写入控制和状态寄存器。</li><li><strong>CSRRS (Read and Set CSR)</strong>:读取和设置控制和状态寄存器的位。</li><li><strong>CSRRC (Read and Clear CSR)</strong>:读取和清除控制和状态寄存器的位。</li></ul></li><li><strong>LR/SC (Load-Reserved/Store-Conditional)</strong>:用于实现原子操作，确保数据一致性：<ul><li><strong>LR.W</strong>: 加载保留字。</li><li><strong>SC.W</strong>: 条件存储字，如果保留仍有效，则存储成功。</li></ul></li><li><strong>AMO指令 (Atomic Memory Operations)</strong>:一组原子内存操作指令，如AMOSWAP、AMOADD、AMOXOR等。</li><li><strong>AUIPC (Add Upper Immediate to PC)</strong>:将一个立即数加到当前PC并将结果存储在寄存器中。</li><li><strong>LUI (Load Upper Immediate)</strong>:将一个立即数加载到寄存器的高位。</li></ul><hr><h3 id="总结-4">总结</h3><ul><li><strong>x86架构</strong>：提供了丰富的指令集，包括许多用于字符串操作、系统调用、处理器信息获取等的特殊指令，主要用于高性能和通用计算。</li><li><strong>POWER架构</strong>：提供了多种专门用于高性能计算和嵌入式系统的特殊指令，特别是在事务内存、寄存器操作和条件处理方面。</li><li><strong>ARM架构</strong>：提供了一组丰富的特殊指令，广泛应用于移动设备和嵌入式系统，特别是在节能和多媒体处理方面。其原子操作通过LDREX/STREX指令实现。</li><li><strong>RISC-V架构</strong>：指令集简洁但功能完备，具有高度的灵活性和可扩展性，特别是在原子操作和控制寄存器管理方面。</li></ul><p>这些特殊指令反映了各个架构的设计目标和应用需求，选择哪种架构通常取决于具体的应用场景和性能需求。</p><h2 id="arm架构中的ldaxrstlxr和ldxrstxr指令的区别">ARM架构中的LDAXR/STLXR和LDXR/STXR指令的区别</h2><h3 id="arm架构中的ldaxrstlxr和ldxrstxr指令">ARM架构中的LDAXR/STLXR和LDXR/STXR指令</h3><p>ARM架构中提供了一组用于实现原子操作的指令，其中包括Load-Exclusive和Store-Exclusive指令。这些指令有不同的变种，以满足不同的同步需求。</p><h4 id="ldaxrstlxr">LDAXR/STLXR</h4><p><strong>LDAXR（Load-Acquire ExclusiveRegister）</strong>和<strong>STLXR（Store-Release ExclusiveRegister）</strong>指令用于实现同步的原子操作。这些指令在执行时包含了内存顺序语义，以确保在多处理器环境中的正确性。</p><ul><li><strong>LDAXR</strong>：<ul><li><strong>功能</strong>：从内存地址加载数据到寄存器，并保留该地址以备后续的STLXR操作使用。</li><li><strong>内存顺序语义</strong>：具有Acquire语义，保证在此指令之后的内存访问不会被重新排序到此指令之前。</li><li><strong>语法</strong>：<code>LDAXR &lt;Rt&gt;, [&lt;Rn&gt;]</code></li><li><strong>例子</strong>：<code>LDAXR W0, [X1]</code></li></ul></li><li><strong>STLXR</strong>：<ul><li><strong>功能</strong>：将寄存器中的数据存储到内存地址，并根据保留状态决定存储是否成功。</li><li><strong>内存顺序语义</strong>：具有Release语义，保证在此指令之前的内存访问不会被重新排序到此指令之后。</li><li><strong>语法</strong>：<code>STLXR &lt;Ws&gt;, &lt;Wt&gt;, [&lt;Rn&gt;]</code></li><li><strong>例子</strong>：<code>STLXR W0, W2, [X1]</code></li></ul></li></ul><h4 id="ldarldxr和stlrstxr">LDAR/LDXR和STLR/STXR</h4><p><strong>LDXR（Load-ExclusiveRegister）</strong>和<strong>STXR（Store-ExclusiveRegister）</strong>指令用于实现通用的原子操作，但没有内存顺序语义。这些指令适用于不需要特定内存顺序的原子操作。</p><ul><li><strong>LDXR</strong>：<ul><li><strong>功能</strong>：从内存地址加载数据到寄存器，并保留该地址以备后续的STXR操作使用。</li><li><strong>内存顺序语义</strong>：没有内存顺序语义，仅实现原子加载操作。</li><li><strong>语法</strong>：<code>LDXR &lt;Rt&gt;, [&lt;Rn&gt;]</code></li><li><strong>例子</strong>：<code>LDXR W0, [X1]</code></li></ul></li><li><strong>STXR</strong>：<ul><li><strong>功能</strong>：将寄存器中的数据存储到内存地址，并根据保留状态决定存储是否成功。</li><li><strong>内存顺序语义</strong>：没有内存顺序语义，仅实现原子存储操作。</li><li><strong>语法</strong>：<code>STXR &lt;Ws&gt;, &lt;Wt&gt;, [&lt;Rn&gt;]</code></li><li><strong>例子</strong>：<code>STXR W0, W2, [X1]</code></li></ul></li></ul><h3 id="主要区别">主要区别</h3><ol type="1"><li><p><strong>内存顺序语义</strong>：</p><ul><li><strong>LDAXR/STLXR</strong>：具有Acquire和Release语义，保证内存访问顺序，适用于需要严格内存排序的同步操作。</li><li><strong>LDXR/STXR</strong>：没有内存顺序语义，仅提供原子性，不保证内存访问顺序，适用于不需要严格内存排序的原子操作。</li></ul></li><li><p><strong>使用场景</strong>：</p><ul><li><strong>LDAXR/STLXR</strong>：适用于实现锁、信号量等需要严格内存顺序的同步原语。</li><li><strong>LDXR/STXR</strong>：适用于实现简单的原子操作，如计数器增加、标志位设置等，不要求严格的内存顺序。</li></ul></li></ol><h3 id="示例代码">示例代码</h3><p>以下是使用LDAXR/STLXR和LDXR/STXR的示例代码，分别用于实现自旋锁和简单的计数器增加操作：</p><h4 id="自旋锁使用ldaxrstlxr">自旋锁（使用LDAXR/STLXR）</h4><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spin_lock:</span><br><span class="line">    LDAXR W0, [X1]        // 尝试加载锁的状态</span><br><span class="line">    CMP W0, #0            // 检查锁是否被占用</span><br><span class="line">    B.NE spin_lock        // 如果锁被占用，继续自旋</span><br><span class="line">    STLXR W0, W2, [X1]    // 尝试存储1到锁地址，以占用锁</span><br><span class="line">    CBNZ W0, spin_lock    // 如果存储失败，继续自旋</span><br><span class="line">    RET</span><br></pre></td></tr></tbody></table></figure><h4 id="计数器增加使用ldxrstxr">计数器增加（使用LDXR/STXR）</h4><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">increase_counter:</span><br><span class="line">    LDXR W0, [X1]         // 加载计数器的当前值</span><br><span class="line">    ADD W0, W0, #1        // 增加计数器</span><br><span class="line">    STXR W0, W0, [X1]     // 尝试存储新值到计数器地址</span><br><span class="line">    CBNZ W0, increase_counter  // 如果存储失败，继续重试</span><br><span class="line">    RET</span><br></pre></td></tr></tbody></table></figure><h3 id="总结-5">总结</h3><ul><li><strong>LDAXR/STLXR</strong>：用于需要严格内存顺序的同步操作，保证Acquire和Release语义。</li><li><strong>LDXR/STXR</strong>：用于不需要严格内存顺序的原子操作，仅提供原子性。</li></ul><p>这些指令的设计旨在满足不同的同步需求，选择使用哪种指令取决于具体的应用场景和性能要求。</p>]]></content>
      
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【機器學習2021】預測本頻道觀看人數 (上下) - 機器學習基本概念簡介</title>
      <link href="/2024/01/08/DeepLearning/"/>
      <url>/2024/01/08/DeepLearning/</url>
      
        <content type="html"><![CDATA[<h2 id="总结">总结</h2><ol type="1"><li>hand craft rules：人工设定的if then，不是真正的人工智能</li><li>机器学习（looking for Function ）：具备学习能力，分为3个步骤：</li></ol><ol type="a"><li>定义一组function：define a set of function</li><li>衡量function的好坏：goodness of function</li><li>优化：挑选出最好的function。 ## 不同类型的function ###回归regression 假设机器要预测未来某一个时间的 PM2.5的数值。机器要找一个函数 f，其输入是可能是种种跟预测 PM2.5有关的指数，包括今天的 PM2.5的数值、平均温度、平均的臭氧浓度等等，输出是明天中午的PM2.5的数值，找这个函数的任务称为回归(regression)。</li></ol><h3 id="分类classification">分类classification</h3><p>分类任务要让机器做选择题。人类先准备好一些选项，这些选项称为类别(class)，现在要找的函数的输出就是从设定好的选项里面选择一个当作输出，该任务称为分类。举个例子，每个人都有邮箱账户，邮箱账户里面有一个函数，该函数可以检测一封邮件是否为垃圾邮件。分类不一定只有两个选项，也可以有多个选项。AlphaGo 也是一个分类的问题，如果让机器下围棋，做一个AlphaGo，给出的选项与棋盘的位置有关。棋盘上有 19 × 19个位置，机器下围棋其实是一个有 19 × 19 个选项的选择题。</p><h3 id="structured-learning">Structured Learning</h3><p>在机器学习领域里面，除了回归跟分类以外，还有结构化学习（structuredlearning）。机器不只是要做选择题或输出一个数字，而是产生一个有结构的物体，比如让机器画一张图，写一篇文章。这种叫机器产生有结构的东西的问题称为结构化学习。</p><h2 id="点击量预测">点击量预测</h2><h3 id="model">model</h3><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112135.png" alt="20240815112135"><figcaption aria-hidden="true">20240815112135</figcaption></figure><p>y 是准备要预测的东西，要预测的是今天(2 月 26日)这个频道总共观看的人，y就假设是今天总共的观看次数。x1是这个频道，前一天(2 月 26 日)总共的观看次数，y 跟x1 都是数值，b 跟 w是未知的参数，它是准备要通过数据去找出来的，w 跟 b是未知的，只是隐约地猜测。猜测往往来自于对这个问题本质上的了解，即领域知识(domainknowledge)。机器学习就需要一些领域知识。这是一个猜测，也许今天的观看次数，总是会跟昨天的观看次数有点关联。y = b + w ∗ x1，而 b 跟 w是未知的。带有未知的参数(parameter)的函数称为模型(model)。模型在机器学习里面，就是一个带有未知的参数的函数，特征(feature)x1 是这个函数里面已知的，它是来自于后台的信息，2 月 25日点击的总次数是已知的，而 w 跟 b 是未知的参数。w 称为权重(weight)，b称为偏置(bias)。这个是第一个步骤。 ### loss <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112155.png" alt="20240815112155"></p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112230.png" alt="20240815112230"><figcaption aria-hidden="true">20240815112230</figcaption></figure><p>估测的值跟实际的值之间的差距，其实有不同的计算方法，计算 y 与 yˆ之间绝对值的差距，如式 (1.6) 所示，称为平均绝对误差(Mean AbsoluteError，MAE)。 e = |yˆ − y| (1.6) 如果算 y 与 yˆ 之间平方的差距，如式(1.7) 所示，则称为均方误差(Mean Squared Error，MSE)。 e = (yˆ − y)2(1.7) 有一些任务中 y 和 yˆ 都是概率分布，这个时候可能会选择交叉熵(crossentropy)。 ### 优化 #### 梯度下降(gradient descent)</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112253.png" alt="20240815112253"><figcaption aria-hidden="true">20240815112253</figcaption></figure><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112319.png" alt="20240815112319"><figcaption aria-hidden="true">20240815112319</figcaption></figure><p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112333.png" alt="20240815112333"> ## training <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112430.png" alt="20240815112430"> <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112439.png" alt="20240815112439"></p><h2 id="线性模型">线性模型</h2><h3 id="问题model-bias">问题：model bias</h3><p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112452.png" alt="20240815112452"> ### 分段线性曲线 <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112507.png" alt="20240815112507"></p><h4 id="sigmoid逼近hard-sigmoid">sigmoid逼近Hard sigmoid</h4><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112534.png" alt="20240815112534"><figcaption aria-hidden="true">20240815112534</figcaption></figure><h4 id="求和叠加">求和叠加</h4><p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112547.png" alt="20240815112547"> <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112644.png" alt="20240815112644"></p><p>输入x，为前不同天数的数据。</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112703.png" alt="20240815112703"><figcaption aria-hidden="true">20240815112703</figcaption></figure><h4 id="转换成矩阵运算">转换成矩阵运算</h4><p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112718.png" alt="20240815112718"> <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112730.png" alt="20240815112730"> <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112744.png" alt="20240815112744"></p><h5 id="所有参数θ">所有参数θ</h5><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112759.png" alt="20240815112759"><figcaption aria-hidden="true">20240815112759</figcaption></figure><h4 id="batch和epoch">batch和epoch</h4><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815112817.png" alt="20240815112817"><figcaption aria-hidden="true">20240815112817</figcaption></figure><h3 id="模型变形rectified-linear-unitrelu">模型变形Rectified LinearUnit，ReLU</h3><p><strong><font color="red">Sigmoid 或 ReLU 称为激活函数(activationfunction)</font></strong></p><p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815113056.png" alt="20240815113056"> <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815113109.png" alt="20240815113109"></p><h3 id="改进模型">改进模型</h3><h4 id="单层改进">单层改进：</h4><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815113125.png" alt="20240815113125"><figcaption aria-hidden="true">20240815113125</figcaption></figure><p>连续使用 10 个 ReLU作为模型，跟用线性模型的结果是差不多的，但连续使用100 个 ReLU 作为模型，结果就有显著差别了，100 个 ReLU在训练数据上的损失就可以从 320 降到 280，有 100 个 ReLU就可以制造比较复杂的曲线，本来线性就是一直线，但 100 个 ReLU 就可以产生100 个折线的函数，在测试数据上也好了一些. 使用 1000 个 ReLU作为模型，在训练数据上损失更低了一些，但是在没看过的数据上，损失没有变化。#### 多层改进： <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815113133.png" alt="20240815113133"></p><h2 id="训练框架">训练框架</h2><p>训练集就要拿来训练模型，训练的过程是 3 个步骤。 1. 先写出一个有未知数θ 的函数，θ 代表一个模型里面所有的未知参数。fθ(x) 的意思就是函数叫fθ(x)，输入的特征为 x，; 2.定义损失，损失是一个函数，其输入就是一组参数，去判断这一组参数的好坏; 3.解一个优化的问题，找一个 θ，该 θ可以让损失的值越小越好。让损失的值最小的 θ 为 θ∗，即 θ∗ = arg minL<br>## Deep Learning <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815113149.png" alt="20240815113149"> ### 为什么不用单层更多参数，而是用更多层呢？<img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815113158.png" alt="20240815113158"></p><h3 id="overfitting">overfitting</h3><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20240815113208.png" alt="20240815113208"><figcaption aria-hidden="true">20240815113208</figcaption></figure><h2 id="参考">参考</h2><p>https://youtu.be/Ye018rCVvOo?si=o_ucZVVK27npvEpmhttps://www.youtube.com/watch?v=CXgbekl66jc&amp;list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&amp;index=1&amp;t=859s&amp;ab_channel=Hung-yiLeehttps://github.com/datawhalechina/leedl-tutorial?tab=readme-ov-file</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>形式化验证</title>
      <link href="/2023/11/16/%E5%BD%A2%E5%BC%8F%E5%8C%96%E9%AA%8C%E8%AF%81/"/>
      <url>/2023/11/16/%E5%BD%A2%E5%BC%8F%E5%8C%96%E9%AA%8C%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="形式化验证">形式化验证</h2><p>形式化验证工具是一类用于验证硬件或软件系统设计是否满足特定规范或性质的工具。这些工具基于数学模型和逻辑推理，能够自动化地验证系统的正确性。以下是几种常见的形式化验证工具：1. 模型检查器（Model Checkers）： *SPIN：用于验证并发系统的模型检查器，使用 Promela 语言描述系统模型。 *NuSMV 和SPIN：用于验证硬件和软件系统的模型检查器，使用类似于时序逻辑（temporallogic）的规范语言。 *UPPAAL：用于验证实时系统的模型检查器，可以验证具有时间约束的系统行为。2. 定理证明器（Theorem Provers）： * Isabelle/HOL：支持高阶逻辑（HigherOrder Logic），能够进行复杂的数学定理证明。 *Coq：基于计算的定理证明器，支持依赖类型（dependenttypes），用于证明程序正确性和数学定理。 3. 符号执行工具（SymbolicExecution Tools）： *KLEE：用于自动化生成测试用例和验证程序的符号执行工具，主要用于 C 和 C++代码的验证。 * SAGE：用于自动化分析和发现软件漏洞的符号执行工具。 4.形式化语言和工具： *ACL2：一个包含逻辑和编程环境的工具，用于验证计算机系统和算法的正确性。 *TLA+：一种用于设计和验证分布式系统的形式化语言和工具。这些工具在验证对象、验证领域和使用方式上有所不同。有些工具更适合硬件系统（如处理器、芯片等）的验证，而有些则更适合软件系统（如程序、算法等）的验证。它们的共同目标是提供自动化的、精确的、可靠的验证手段，帮助设计者发现并修复系统设计中的潜在问题，确保系统符合规范和性能要求。选择合适的形式化验证工具通常取决于你的验证需求、所验证对象的类型以及你的经验和熟悉程度。深入了解每个工具的优势和适用范围能够更好地选择合适的工具来完成你的验证任务。</p><h2 id="验证流程">验证流程</h2><p>当涉及形式化验证时，一个经典的例子是验证缓存一致性协议。在多核处理器系统中，为了保证数据的一致性，通常会使用缓存一致性协议，比如MESI 协议。</p><p>考虑一个简化的缓存一致性协议，我们可以使用模型检查器来验证它是否满足一致性和正确性属性。以下是一个可能的验证流程：</p><ol type="1"><li>建立模型：</li></ol><ul><li>使用模型检查器的输入语言描述缓存一致性协议，定义缓存的状态、操作和状态转换规则。</li></ul><ol start="2" type="1"><li>定义性质：</li></ol><ul><li>定义需要验证的性质。例如，我们可能希望验证所有核心对于共享数据的访问是否都能够遵守一致性协议的规定。</li></ul><ol start="3" type="1"><li>模型检查：</li></ol><p>运行模型检查器对定义的性质进行验证。模型检查器将会尝试在状态空间中寻找违反性质的情况。4. 分析结果：</p><ul><li><p>如果模型检查器找到违反性质的情况，它将会给出一个反例（counterexample），展示了违反性质的状态序列，帮助识别问题所在。</p></li><li><p>如果验证通过，那么协议就在给定性质下被证明是正确的。</p></li></ul><p>这种验证过程允许工程师在设计阶段发现潜在的问题，例如在并发操作中可能出现的竞争条件或不一致性情况。通过形式化验证，可以确保缓存一致性协议在不同场景下都能正确地维护数据的一致性。</p><p>这只是形式化验证的一个示例。实际上，在硬件、软件、协议和系统设计中，形式化验证都可以应用于不同的场景，以确保设计的正确性和一致性。</p><h2 id="例子">例子</h2><p>对于缓存一致性协议的形式化验证，可以使用类似于模型检查器（如SPIN）的工具来实现。</p><p>举例来说，可以使用 Promela语言描述缓存一致性协议的状态转换和规则，然后使用 SPIN工具进行模型检查。以下是一个简化的例子：</p><p>假设有一个简单的缓存一致性协议，包含了两个核心（Core 0 和 Core1）以及一个共享的内存（Memory）。协议使用 MESI 协议进行缓存管理。</p><p>下面是一个可能的 Promela 代码片段示例：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">mtype = {INVALID, SHARED, MODIFIED, EXCLUSIVE};</span><br><span class="line"></span><br><span class="line">chan core_to_mem = [2] of {mtype, mtype};  // 两个核心和内存之间的通道</span><br><span class="line"></span><br><span class="line">proctype Core(int id; chan c_to_m; chan m_to_c) {</span><br><span class="line">    mtype cache_state = INVALID;</span><br><span class="line">    mtype memory_state = INVALID;</span><br><span class="line"></span><br><span class="line">    do</span><br><span class="line">    :: </span><br><span class="line">        // 读取或写入操作的模拟</span><br><span class="line">        if</span><br><span class="line">            :: (cache_state == INVALID) -&gt; </span><br><span class="line">                // 从内存读取数据</span><br><span class="line">                c_to_m ! (id, READ);</span><br><span class="line">                m_to_c ? memory_state;</span><br><span class="line">                cache_state = memory_state;</span><br><span class="line">            :: (cache_state == SHARED) -&gt; </span><br><span class="line">                // 从共享缓存读取数据</span><br><span class="line">                // ...</span><br><span class="line">            :: (cache_state == MODIFIED) -&gt; </span><br><span class="line">                // 在本地缓存中执行写操作</span><br><span class="line">                // ...</span><br><span class="line">        fi;</span><br><span class="line">        // 省略其他操作...</span><br><span class="line">    od;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">// 内存处理进程</span><br><span class="line">proctype Memory(chan m_to_c; chan c_to_m) {</span><br><span class="line">    mtype memory_state = INVALID;</span><br><span class="line"></span><br><span class="line">    do</span><br><span class="line">    :: </span><br><span class="line">        // 处理来自核心的读写请求</span><br><span class="line">        c_to_m ? memory_state;</span><br><span class="line">        m_to_c ! memory_state;</span><br><span class="line">        // 处理缓存和内存之间的通信</span><br><span class="line">        // ...</span><br><span class="line">    od;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">// 主进程，启动核心和内存</span><br><span class="line">active [2] proctype Cores() {</span><br><span class="line">    chan core_to_mem = [2] of {mtype, mtype};</span><br><span class="line">    chan mem_to_core = [2] of {mtype, mtype};</span><br><span class="line"></span><br><span class="line">    run Core(0, core_to_mem[0], mem_to_core[0]);</span><br><span class="line">    run Core(1, core_to_mem[1], mem_to_core[1]);</span><br><span class="line">    run Memory(mem_to_core[0], core_to_mem[0]);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>这个示例中使用了 Promela语言来描述了两个核心和内存之间的通信以及状态转换规则。你可以使用 SPIN工具对这个模型进行模型检查，验证在不同的操作序列下，是否会出现不一致性或违反协议规则的情况。</p><p>这个示例是一个简化的模型，实际的协议会更加复杂，但基本思路是使用类似的形式化语言描述系统的状态和行为，然后使用相应的模型检查器或形式化验证工具进行验证。</p>]]></content>
      
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gem5</title>
      <link href="/2023/11/16/gem5/"/>
      <url>/2023/11/16/gem5/</url>
      
        <content type="html"><![CDATA[<p>首先分析事件驱动的步骤：</p><p>在gem5模拟器中，simulate.cc 中doSimLoop循环的调用eventq的service成员函数；该成员函数会从二级链表的event中，抽取event，调用event→process（）；event是一个指针，是gem5中其他组件的基类之一，因此可以通过多态的方法，访问其他组件的process函数；在调用process函数之前，调用setCurTick(event→when())，即将event的when设置为当前的curTick(),这时也就对系统的时间进行了更新；然后调用event→process（）；即调用了一个具体对象的process，假如这个对象是ALU；这时ALU将会执行其功能的具体任务，这时它可能只能完成一个颗粒度的任务，比如一个时钟的加，或者三个时钟的乘法（具体乘法是由process函数分三步完成，每步一个cycle还是一步完成，一步三个cycle是可以DIY的），完成之后。然后调用schedule函数，这个函数是经由Eventwrapper包装，实际上是EventQueue的成员函数，它实现了：更新when，也就是下一次什么时候再次触发event 将event插入到eventqueue中，在插入eventqueue时，queue时二级链表，这个链表是按照各个器件下一次发生的时间进行排序的，在插入时，也是要进行一次排序，找到合适的位置进行插入。（在queue中有bin，怀疑是同一批时间的在一个bin，不同时间的是不同的bin）。when的值，是在调用schedule时，可以将下一次的时间通过调用clockEdge(Cycles(n))获取的。总体说来，就是不同的器件在process中：</p><p>1）完成自身的功能；</p><p>2）将下一次何时触发，插入queue中</p><p>要注意的是，插入queue中的是每个对象的event指针，不需要复制，也不是完整的对象，只是指针。</p><p>如果A器件在100cycle时，执行process，完成自身功能后，将event-&gt;when设置为107，插入queue中；表示下一次在107时刻触发；然后，B器件在100cycle时，执行process，完成自身功能后，将event-&gt;when设置为120，插入queue中；表示下一次在120时刻触发；然后C器件在103cycle时，执行process，完成自身功能后，将event-&gt;when设置为109，插入queue中；表示下一次在109时刻触发；</p><p>那么在gem5中，执行的过程将是</p><ol type="1"><li>a调度，更新系统时间为100，执行完毕后，插入事件a 107；</li><li>b调度，更新系统时间（或不更新），执行完毕后，插入事件b 120；</li><li>查找queue，发现下一次是c触发，将系统时间更新为103，执行完毕后，插入事件c109；</li><li>查找queue，发现下一次是a触发，将系统时间更新为107，执行完毕后，插入下一次a事件；</li><li>查找queue，发现下一次是c触发，将系统时间更新为109，执行完毕后，插入下一次c事件；</li><li>查找queue，发现下一次是b触发，将系统时间更新为120，执行完毕后，插入下一次b事件；这就是基于事件驱动的原理。</li></ol>]]></content>
      
      
      <categories>
          
          <category> PerformanceModel </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>roofline</title>
      <link href="/2023/11/16/roofline/"/>
      <url>/2023/11/16/roofline/</url>
      
        <content type="html"><![CDATA[<h2 id="introduction">introduction</h2><p>计算机体系结构中的传统智慧导致了同构设计。几乎每台台式机和服务器都使用缓存、流水线、超标量指令和无序执行。尽管指令集不同，但微处理器都属于同一类设计。转到多核意味着微处理器将变得更加多样化，因为它们还没有传统智慧。例如，一些提供许多简单的处理器而不是较少的复杂处理器，一些依赖于多线程，而一些甚至用显式寻址的本地存储来替换缓存。制造商可能会提供多个产品，每个产品的核心数量不同，以覆盖多个价格性能点，因为每芯片的核心数量可能会每两年翻一番[4]。虽然多样性可能在这个不确定的时期是可以理解的，但它加剧了程序员、编译器编写员甚至架构师已经困难的工作。因此，一个易于理解的模型，提供性能指导方针，可能是特别有价值的。模型不需要完美，只需要有洞察力。例如，缓存的3Cs模型是一种比喻[19]。它不是一个完美的模型，因为它忽略了可能很重要的因素，如块大小、块分配策略和块替换策略。此外，它还有怪癖。例如，在一个设计中，未命中的可以标记为容量，而在同一大小的另一个缓存中可以标记为冲突。然而，3Cs模型已经流行了将近20年，因为它提供了对程序行为的洞察，帮助程序员、编译器编写员和架构师改善各自的设计。本文提出了这样一个模型，并使用四个关键的浮点内核在四种不同的多核计算机上进行了演示。</p><h2 id="performance-model">performance model</h2><p>Stochastic analytical models [14][28] and statistical performancemodels [7][27]可以准确地预测程序在多处理器上的性能。然而，它们很少提供如何提高程序、编译器或计算机的性能的见解，或者可能难以被非专家使用[27]。另一种更简单的替代方法是boundand bottleneck分析。与其尝试预测性能，它提供了[20]“对影响计算机系统性能的主要因素的重要见解。特别是，系统瓶颈的关键影响被突出和量化。”</p><p>最著名的例子无疑是阿姆达尔定律（Amdahl'sLaw），该定律简单地表明，并行计算机的性能提升受到并行程序串行部分（serialportion）的限制。它最近被应用于异构多核计算机[4][18]。</p><h2 id="roofline-model">roofline model</h2><p>我们认为，<strong>在不久的过去和可预见的未来，芯片外的内存带宽往往会是制约资源[23]</strong>。因此，我们需要一个模型来将处理器性能与芯片外内存流量联系起来。为了实现这一目标，我们使用operational intensity 来表示DRAM operationsperbyte。我们将总字节访问定义为经过缓存层次结构过滤后进入主内存的字节。也就是说，我们衡量的是缓存和内存之间的流量，而不是处理器和缓存之间的流量。因此，operationalintensity表明内核在特定计算机上所需的DRAM带宽。</p><p>我们使用operational intensity而不是arithmetic intensity [16] ormachine balance [8][11] 有两个原因。首先，arithmetic intensity 和machinebalance衡量的是处理器和缓存之间的流量，而我们想要衡量的是缓存和DRAM之间的流量。这个微妙的变化允许我们将计算机的内存优化纳入我们的边界和瓶颈模型。其次，我们认为该模型适用于非算术运算的kernel（见第7部分），因此我们需要一个比算术更一般的术语。</p><p>所提出的<strong>模型将floating-point performance, operationalintensity, and memory performance结合在一个二维图中</strong>。可以使用硬件规格或微基准测试来找到峰值浮点性能。我们在这里考虑的内核工作集无法完全适应芯片上缓存，因此峰值内存性能由缓存背后的内存系统定义。尽管您可以使用STREAM基准[22]找到内存性能，但为了这项工作，我们编写了一系列逐步优化的微基准测试，旨在确定可持续的DRAM带宽。它们包括获得最佳内存性能的所有技术，包括预取和数据对齐。（附录中的A.1部分给出了如何测量处理器和内存性能以及operationalintensity的更多细节。）</p><p>图1a显示了双插槽系统中2.2 GHz AMD OpteronX2型号2214的模型，该图采用对数-对数刻度。Y轴表示可达到的浮点运算性能，X轴表示运算强度，从每DRAM字节1/4Flops到每DRAM字节16Flops不等。通过基准测试，模拟器在双精度浮点运算上的峰值性能为每秒17.6GFlops，内存带宽峰值每秒15GBytes。后一个测量值是计算机内存的稳定状态带宽潜力，而不是DRAM芯片的引脚带宽。</p><p>Attainable GFlops/sec = Min(Peak Floating Point Performance, PeakMemory Bandwidth x Operational Intensity)</p><p>屋脊点（即对角线屋顶和水平屋顶的交汇点）反映了计算机整体性能。屋脊点的x坐标是实现最大性能所需的最小operationalintensity。如果屋脊点在右侧很远的地方，那么只有具有非常高operationalintensity的kernel才能实现该计算机的最大性能。如果它在左侧很远的地方，那么几乎任何kernel都可能达到最大性能。我们将看到（第6.3.5节），屋脊点表明程序员和编译器编写者实现峰值性能的难度水平。</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/5d34f76673fab7d9166f8768110ce4b8.png" alt="5d34f76673fab7d9166f8768110ce4b8"><figcaption aria-hidden="true">5d34f76673fab7d9166f8768110ce4b8</figcaption></figure><p>如图1b所示：operational intensity 更高才能发挥出OpteronX4的性能。</p><h2 id="adding-ceilings-to-the-model">ADDING CEILINGS TO THE MODEL</h2>]]></content>
      
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo</title>
      <link href="/2023/11/15/hexo/"/>
      <url>/2023/11/15/hexo/</url>
      
        <content type="html"><![CDATA[<h2 id="搭建blog">搭建blog</h2><p>工具： 1. hexo 2. github 3. vscode 4. Markdown All in One(vscode扩展)5. picgo(vscode扩展) 6. hexo主题</p><h2 id="hexo">hexo</h2><h3 id="安装">安装</h3><p>https://blog.csdn.net/weixin_51216553/article/details/118958664</p><h3 id="hexo-使用">hexo 使用</h3><p>liuyueji@408570 Desktop % cd blog</p><p>liuyueji@408570 blog % hexo new coz INFO Validating config INFOCreated: ~/Desktop/blog/source/_posts/coz.md</p><ul><li>换主题</li></ul><figure class="highlight ebnf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">hexo clean</span></span><br><span class="line"><span class="attribute">hexo g</span></span><br><span class="line"><span class="attribute">hexo s</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><h2 id="github">github</h2><p>https://blog.csdn.net/yijing_jia/article/details/135989846</p><p>https://styiwe.github.io/2021/01/29/mac-xia-da-jian-ji-yu-hexo-github-de-ge-ren-bo-ke/</p><h4 id="history">history</h4><figure class="highlight basic"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="symbol">1269 </span> hexo g</span><br><span class="line"><span class="symbol">1270 </span> hexo s</span><br><span class="line"><span class="symbol">1271 </span> hexo d</span><br><span class="line"><span class="symbol">1272 </span> hexo <span class="keyword">new</span> page <span class="number">404</span></span><br><span class="line"><span class="symbol">1273 </span> vi ~/Desktop/blog/source/<span class="number">404</span>/index.md</span><br><span class="line"><span class="symbol">1274 </span> cp themes/melody/_config.yml _config.melody.yml</span><br><span class="line"><span class="symbol">1275 </span> vi _config.melody.yml</span><br><span class="line"><span class="symbol">1276 </span> vi _config.yml</span><br><span class="line"><span class="symbol">1277 </span> vi _config.yml</span><br><span class="line"><span class="symbol">1278 </span> vi _config.melody.yml</span><br><span class="line"><span class="symbol">1279 </span> hexo clean</span><br><span class="line"><span class="symbol">1280 </span> hexo g</span><br><span class="line"><span class="symbol">1281 </span> hexo s</span><br><span class="line"><span class="symbol">1282 </span> hexo clean</span><br><span class="line"><span class="symbol">1283 </span> hexo g</span><br><span class="line"><span class="symbol">1284 </span> hexo s</span><br></pre></td></tr></tbody></table></figure><h2 id="vscode使用picgo扩展上传照片">vscode使用picgo扩展上传照片：</h2><p>option+command+u</p><h3 id="参考链接">参考链接</h3><p>VSCode+PicGo+Github搭建免费Markdown图床https://juejin.cn/post/7031461637986975757</p><p>https://blog.csdn.net/qq_44314954/article/details/122951033</p><p>https://blog.csdn.net/qq_43827595/article/details/104274769</p><h3 id="图床">图床</h3><p>使用账号gmail邮箱</p><h2 id="markdown">markdown</h2><p>https://blog.csdn.net/weixin_42782150/article/details/104878759</p><h3 id="公式显示问题">公式显示问题</h3><p>http://chenhao.space/post/59292.html#step-2-stop-using-hexo-math</p>]]></content>
      
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coz</title>
      <link href="/2023/11/15/coz/"/>
      <url>/2023/11/15/coz/</url>
      
        <content type="html"><![CDATA[<h1 id="coz-finding-code-that-counts-with-causal-profiling">COZ: FindingCode that Counts with Causal Profiling</h1><h2 id="摘要">摘要</h2><p>提高性能是软件开发者关注的中心问题。为了确定优化机会，开发人员依靠软件分析器。然而，这些分析器只能报告程序在何处花费时间：优化该代码可能对性能没有影响。因此，过去的性能分析器既浪费开发人员的时间，也使他们难以发现重要的优化机会。</p><p>介绍了一种叫做“因果分析”的技术。这种技术与以往的性能分析方法不同，能够精确地指出程序员应该将优化工作的重点放在哪里，并量化他们可能产生的影响。“因果分析”通过在程序执行过程中运行性能实验来实现这一点。每个实验通过插入暂停来减慢所有其他并发运行的代码，从而计算出任何潜在优化的影响。关键在于，这种速度下降与加快运行该行的速度具有相同的相对效果，因此可以“虚拟地”加速它。这种方法可以确定哪些部分的代码可能会对程序的总体性能产生最大的影响，因此可以为程序员提供优化工作的重点。</p><p>一种名为COZ的因果分析工具，该工具被用于评估一系列高度优化的应用，包括Memcached、SQLite和PARSEC基准测试套件。COZ能够识别之前未知的优化机会，这些优化机会既具有重要意义又具有针对性。在COZ的指导下，我们将Memcached的性能提高了9%，将SQLite的性能提高了25%，并将六个PARSEC应用加速了高达68%。在大多数情况下，这些优化仅涉及修改不到10行的代码。</p><h2 id="介绍">介绍</h2><p>手动检查程序以找到优化的操作机会是不切实际的，因此开发人员使用分析器。传统的分析器按其对总执行时间的贡献对代码进行排名。突出的例子包括oprofile、perf和gprof[17、27、29]。不幸的是，即使分析器准确地报告程序花费时间的地方，这些信息也可能误导程序员。长时间运行的代码不一定是优化的好选择。例如，优化在文件下载期间绘制加载动画的代码不会使程序运行更快，尽管这段代码的运行时间与下载时间一样长。</p><p>这个现象并不仅限于I/O操作。图1展示了一个简单的程序，说明了现有分析器的缺点，例如gprof分析器的图2a。该程序产生两个线程，分别调用函数fa和fb。大多数分析器会报告这些函数约占总执行时间的一半。其他分析器可能会报告fa处于关键路径上，或者主线程花费大致相等的时间等待fa和fb[ 23]。虽然准确，但所有这些信息都可能误导。完全优化fa只会使程序加速4.5%，因为fb成为新的关键路径。</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/e21794df244cee59295e4e998dfcd980.png" alt="e21794df244cee59295e4e998dfcd980"><figcaption aria-hidden="true">e21794df244cee59295e4e998dfcd980</figcaption></figure><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/494414da71cb9d7aeb2ade516db65299.png" alt="494414da71cb9d7aeb2ade516db65299"><figcaption aria-hidden="true">494414da71cb9d7aeb2ade516db65299</figcaption></figure><p>在因果分析中，y轴显示了通过加速每个代码行以x轴上显示的速度百分比而实现的程序加速。灰色区域显示标准误差。+gprof报告fa和fb占总运行时间的相似部分，但优化fa最多可以提高性能4.5%，而优化fb不会影响性能。+ 因果分析预测两种结果在0.5%以内。</p><p>传统profiler不能分析潜在的优化效果，开发者要根据对程序的了解自己预测优化效果。</p><p>causalprofiling，该方法能够准确、精确地指出程序员应该集中精力进行优化的地方，并量化其潜在影响。图2b显示了我们因果分析器原型COZ的运行结果。该分析图绘制了一行代码的假设加速(x轴)与它对执行时间的影响(y轴)的关系。图形显示了单独优化fa或fb不会有太大影响。</p><p><font color="red"> coz怎么看出来的单独优化效果不好？ </font></p><p>causalprofiling进行一系列性能实验以观察潜在优化措施的效果。当然，不可能通过任意数量自动加速任何一行代码。相反，因果分析器使用虚拟加速的新技术来模拟通过固定数量优化特定代码行的影响。每当该行运行时，通过插入暂停来减慢所有其他线程，从而使该行虚拟加速。关键的见解是这种放缓与加快该行的运行速度具有相同的相对效果，从而“虚拟地”加速它。图3显示了虚拟加速和实际加速的等效性。</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/6f4f0a92e3fd513d05007fcc710f4f9e.png" alt="6f4f0a92e3fd513d05007fcc710f4f9e"><figcaption aria-hidden="true">6f4f0a92e3fd513d05007fcc710f4f9e</figcaption></figure><p>每次性能实验都测量了通过特定量来虚拟加速一行代码的效果。通过在0%（无变化）和100%（该行代码完全消除）的虚拟加速范围内进行许多性能实验，因果分析器可以预测任何潜在优化对程序性能的影响。</p><p>causalprofiling与传统的分析方法的另一个不同之处是，使得开发人员可以查看优化对吞吐量和延迟的影响。1. 为了分析吞吐量，开发人员指定一个progresspoint，表示代码中工作结束相对应的行,通过测量每个progresspoint的访问率，以确定任何潜在优化对吞吐量的影响。 2.为了分析延迟，程序员们会放置两个progresspoint，它们对应于感兴趣的事件的开始和结束，例如当事务开始和完成时。因果分析器然后报告潜在优化对这两个progresspoint之间的平均延迟的影响。</p><p>为了证明causalprofiling的有效性，我们开发了COZ，这是一种用于Linux的因果分析工具。我们发现COZ只产生较低的执行时间开销（平均：17%，最小：0.1%，最大：65%），使其比gprof快得多（最高达6倍的开销）。我们发现因果分析可以准确地预测优化机会，并且能够有效地指导优化工作。我们将COZ应用于Memcached、SQLite和广泛研究的PARSEC基准测试套件。在COZ输出的指导下，我们将Memcached的性能提高了9%，将SQLite的性能提高了25%，并将六个PARSEC应用程序的性能提高了高达68%。这些优化通常涉及修改不到10行的代码。当可能准确测量COZ所确定的优化行的大小时，我们将观察到的性能改进与COZ的预测进行比较：在每种情况下，我们发现我们优化的实际效果与COZ的预测相匹配。</p><h3 id="贡献">贡献</h3><ol type="1"><li>它提供了causalprofiling，识别出可以进行优化并产生最大影响的代码。使用虚拟加速和progresspoint，因果分析直接测量潜在优化对吞吐量和延迟的影响（第2节）。</li><li>它介绍了COZ，这是一种在未修改的Linux二进制文件上工作的因果分析器。它描述了COZ的实现（第3节），并展示了其在识别优化机会方面的效率和效果（第4节）。</li></ol><h2 id="causal-profiling-overview">Causal Profiling Overview</h2><h3 id="profiler-startup.">Profiler startup.</h3><p>用户使用 coz run --- <program> <args> 形式的命令调用COZ。在程序执行开始时，COZ收集可执行文件和所有已加载库的调试信息。用户可以指定文件和二进制范围，这将限制COZ 的实验，仅在指定的文件中进行加速。默认情况下，COZ将考虑来自主可执行文件的任何源文件的加速。</args></program></p><p><strong>COZ使用程序的调试信息和指定的范围从指令构建到源行的映射。一旦构建了源映射，COZ将创建一个分析器线程并恢复正常执行。</strong></p><h3 id="experiment-initialization.">Experiment initialization.</h3><p><strong>COZ需要选择两个参数：代码行line和加速百分比。</strong></p><p>这两个参数都必须随机选择；任何系统性的方法来探索lines或加速都可能导致剖析结果的系统性偏差。人们可能认为COZ可以排除在早期实验中没有表现出性能影响的lines或虚拟加速量，但基于过去结果的实验优先级将阻止COZ识别重要lines，如果其性能仅在某些预热期之后才重要。一旦选择了一条line和加速，剖析器线程就会保存每个progresspoint的访问次数并开始实验。</p><h3 id="applying-a-virtual-speedup.">Applying a virtual speedup.</h3><p>每次被分析的程序创建线程时，COZ 就会开始从这个线程中采样指令指针。COZ在每个线程中处理样本以实现虚拟加速的采样版本。在3.4节中，我们展示了图3所示的虚拟加速机制与COZ使用的采样方法之间的等价性。</p><p><strong>每次有样本可用时，线程会检查样本是否落在所选用于虚拟加速的代码行中。如果是，它就会强制其他线程暂停。此过程一直持续到分析器线程表明实验已完成。</strong></p><h4 id="例子1">例子1</h4><p>f=100 g=30 + t1：100 + 30 + 100 = 230 + t2： 30 + 100 +30 = 160</p><p>优化f为60后： + t1：60 + 30 + 60 = 150 （优化了80） + t2：30 + 60 +30= 120</p><p>采用virtual加速f为60： + t1：100 + 40 + 30 + 100 = 270 （270 - 40*3 =150） + t2：30 + 40 + 100 +30 +40 = 240</p><p>可以看出virtual加速计算出来的加速后时间150等于实际加速效果.</p><h4 id="例子2加速线程t1导致t2成为瓶颈">例子2：加速线程t1，导致t2成为瓶颈</h4><p>f=100 g=60 + t1：100 + 100 = 200 + t2： 60 + 60 = 120</p><p>优化f为50后： + t1：50 + 50 = 100 + t2： 60 + 60 = 120（优化效果为200到120）</p><p>采用virtual加速f为50： + t1：100 + 100 = 200 + t2：60 + 50 + 60 +50 =220 （220 - 50*2 = 120）</p><p>可以看出virtual加速计算出来的加速后时间120等于实际加速效果.</p><p>分析： </p><figure class="highlight asciidoc"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="bullet">* </span>执行下来的最长用时的线程（关键线程）所用的时间=关键线程自己原本执行时间+其他线程导致的pause时间</span><br><span class="line"><span class="bullet">*   </span>virtual加速 = 关键线程的执行时间-所有线程导致的pause时间</span><br><span class="line"><span class="bullet">*              </span>= 关键线程的执行时间-其他线程导致的pause时间-关键线程导致的pause时间</span><br><span class="line"><span class="bullet">*              </span>= 关键线程自己原本执行时间-关键线程导致的pause时间</span><br><span class="line"><span class="bullet">*              </span>= 加速后的关键线程 </span><br><span class="line"><span class="bullet">*            </span></span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="ending-an-experiment.">Ending an experiment.</h3><p>经过预定的时间后，COZ会结束实验。如果在实验过程中对进展点的访问次数太少（默认最小值为5），COZ会将剩余的执行时间加倍。一旦实验完成，分析线程会记录实验结果，包括: *实验的有效持续时间（运行时间减去插入的总延迟） * 选定的行和加速效果 *所有进展点的访问次数。</p><p>在开始下一个实验之前，COZ将暂停一段短暂的冷却时间，以便在下次实验开始之前处理任何剩余的样本。</p><h3 id="producing-a-causal-profile.">Producing a causal profile.</h3><p>产生因果剖面。在应用程序被COZ分析后，所有性能实验的结果可以组合起来产生profile文件。</p><p>每个实验有两个自变量： * 选择的用于虚拟加速的代码行line和 *虚拟加速值。</p><p>COZ记录了因变量： * 每个progress point的访问次数 *实验的有效持续时间（实际运行时间减去所有暂停的时间）。</p><p>具有相同自变量的实验可以合并：将progresspoint访问次数和实验持续时间相加来组合。</p><p>COZ就按照加速代码行对实验进行分组。 *任何没有0%虚拟加速测量的代码行line都会被丢弃；如果没有这个基线测量，我们无法计算相对于原始程序的百分比加速。单独测量每个代码行的基线，可确保任何与线路相关的虚拟加速开销，例如在频繁执行的线路运行时插入延迟所需的额外跨线程通信，不会影响性能剖面结果。*默认情况下，COZ还将丢弃任何具有少于5个不同虚拟加速量的line(只显示75%虚拟加速效果的图不是特别有用)。* 最后，我们计算相对于基线（虚拟速度提升0%）的加速比</p><p>COZ然后绘制每个线路的速度提升表格，产生本文中显示的性能图。</p><h3 id="interpreting-a-causal-profile.">Interpreting a causalprofile.</h3><p>一旦生成了因果剖面图，用户就可以解释它们，并做出一个有根据的选择，哪些线条可能需要进行优化。为了帮助用户识别重要的线条，COZ按照线性回归的斜率对图形进行排序。<font color="blue"> 1. 陡峭的上升斜率表示一条线，表示优化很有效果 2.平坦的线条表示优化此线条不会提高程序性能 3.COZ还找到具有陡峭下降斜率的线条，这意味着对此代码行的任何优化实际上都会损害性能。这种向下倾斜的剖面图是contention的一个强烈迹象；几乎加速的代码行干扰了程序的关键路径，优化此线条增加了干扰量。这种现象非常普遍，往往会导致重大的优化机会。在我们的评估中，我们识别和修复了三个应用程序中的争用问题：fluidanimate、streamcluster和memcached，分别提高了速度的37.5%，68.4%和9.4%。</font></p><font color="blue"></font><p><font color="blue"></font></p><h2 id="implementation">Implementation</h2><h3 id="core-mechanisms">Core Mechanisms</h3><p>使用LD—PRELOAD库实现对程序地址空间的分析,可以在程序的startup和shutdown中间进行采样，采样是基于perf—eventAPI获取程序PC和user-space调用栈，调用间隔是1ms，COZ默认处理10个样本为一批（每批更频繁地采样不太可能提高准确性，还会增加开销）。</p><p><strong>Attributing samples to source locations.</strong></p><p>COZ 使用DWARF调试信息，用于将采样程序计数器值映射到源代码位置。程序不需要包含DWARF行信息；COZ将使用类似GDB的进程定位外部调试信息.DWARF（Debug With Arbitrary RecordFormat）是一种用于调试和记录程序执行信息的标准。它被广泛用于Unix和Unix-like操作系统中，特别是在GCC（GNUCompilerCollection）编译器套件中。DWARF提供了有关程序执行期间变量的值、函数调用的参数、返回值和源代码行号等信息，使得调试器能够更准确地确定程序在何处出错，并提供更详细的错误信息。DWARF还提供了用于记录程序执行期间发生的各种事件的信息，例如函数调用、跳转和返回等。这些信息对于理解程序的执行流程非常有用。DWARF信息被存储在编译生成的二进制文件中，可以通过调试器进行读取和分析。</p><h3 id="performance-experiment-implementation">Performance ExperimentImplementation</h3><p>COZ使用专用的分析线程进行实验。此线程负责选择加入一条line来加速，选择虚拟的加速比例，对progresspoints测量虚拟加速情况，以及编写proﬁler输出。</p><p>加速比例从0%~100%，以5%的步长增加。p0表示不进行虚机加速所用的程序时间（progresspoint之间的），ps表示进行虚拟加速后的实践。那么程序性能的影响就是1-ps/p0.</p><p>Lines for virtual speedup must be selected randomly to prevent biasin the results of performance experiments.</p><p><font color="red"> 为何不随机就会有偏差？ </font>例如，如果一个line对initialization有性能影响，但是对后续执行阶段没有，就会夸大效果，如果对initialization没有性能影响，可能后续执行就不会再实验了。</p><h3 id="progress-point-implementation">Progress PointImplementation</h3><p>COZ支持三种progress point：源代码级、断点、采样。 1. 源代码级progresspoint。是唯一需要程序修改的progress point。要指示源代码级的progresspoint，开发人员只需在程序的源代码中插入COZ PROGRESS宏。 2. 断点progresspoint。在命令行中指定。COZ使用Linux perf事件API在第一条指令处设置断点。3. 采样progress point。在命令行上指定。然而，与源代码级和断点progresspoint不同，采样progress point等不记录访问progresspoint的次数。相反，采样progresspoint会计算落到指定代码行的样本数量。</p><p><font color="red"> 在后面评估case中如何使用的？ </font></p><h4 id="测量延迟">测量延迟。</h4><p>源代码级和断点progresspoint数还可以用来衡量优化措施对于延迟的影响（而不是吞吐量）。要测量延迟，开发人员必须指定两个progresspoint：一个在开始时，另一个在最后。起始progress pointd的visitrate是arrivalrate，起点和终点的计数之间的差异告诉我们目前有多少请求正在进行中。L为正在处理的请求数，λ 为 arrival rate。根据Little’sLaw，我们可以计算出平均延迟W， 这几乎适用于任何排队系统：L = λW [ 30]。重写Little定律，然后计算平均延迟L/λ。</p><h3 id="virtual-speedup-implementation">Virtual SpeedupImplementation</h3><p><span class="math display">\[s \approx \frac{n * \bar{t}}{P}\]</span> * s: The number of samples in the selected line * P: theperiod of time between samples * t: the average time required to run theselected line once * n: is the number of times the selected line isexecuted.</p><p><span class="math display">\[\bar{t_{e}} = \frac{(n -s)*\bar{t} +s*(\bar{t}-d)}{n} \]</span> + <span class="math inline">\(\bar{t_{e}}\)</span> The effective average time torun the selected line + d: 加速的时间</p><p><span class="math display">\[\bar{t_{e}} = \bar{t} * (1- \frac{d}{P})\]</span></p><p><span class="math display">\[\triangle{\bar{t}} = (1-\frac{\bar{t_{e}}}{\bar{t}}) = \frac{d}{P} \]</span></p><ul><li><p><span class="math inline">\(\triangle{\bar{t}}\)</span>:theamount of virtual Potentially unblocking calls speedup</p></li><li><p>Pausing otherthreads.为了降低overhead，不适用POSIX的signal，使用counter对每个线程的pause计数，有globalcount和每个线程自己的localcounter，local小于global就需要pause。</p></li><li><p>Ensuring accuratetiming.使用nanosleep，保证pause的实践至少是要求的时间，超过的部分会在将来的pause减掉。</p></li><li><p>Thread creation.新的线程创建继承父进程的local delaycounter。</p></li></ul><h4 id="handling-suspended-threads">Handling Suspended Threads</h4><ul><li><p>由于IO挂起的线程，在不阻塞后，加上插入pause。</p></li><li><p>由于线程间同步原因挂起的线程，在不阻塞后，不需要pause（因为释放mutex的线程在释放前已经执行了delay，那么等待mutex的线程等同于被delay了）。</p></li><li><p>表1：当线程invoking其他线程之前需要吧delay全部执行。</p></li><li><p>表2：当线程进入阻塞前后，需要更新delay counter。</p></li></ul><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/446c965e2bbacbe4fd777574deef9415.png" alt="446c965e2bbacbe4fd777574deef9415"><figcaption aria-hidden="true">446c965e2bbacbe4fd777574deef9415</figcaption></figure><h4 id="attributing-samples-to-source-lines">Attributing Samples toSource Lines</h4><p>怎么样将采样对应到代码行：根据调用栈，找到最上层的调用函数。</p><p>When a sample does not fall in any in-scope source line, the profilerwalks the sampled callchain to find the first in-scope address.</p><p>For example, a program may call printf, which calls vfprintf, whichin turn calls strlen. Any samples collected during this chain of callswill be attributed to the source line that issues the original printfcall.</p><h3 id="optimization-minimizing-delays">Optimization: MinimizingDelays</h3><p>当所有线程都执行了代码行，对所有线程都进行delay，是不必要的，会降低执行效率。当线程采样到选定的代码行，就增加该线程的local delaycounter，如果local小于global，coz插入pause。如果local delaycount大于global，那么就增加global delay count。</p><h4 id="adjusting-for-phases">Adjusting for phases</h4><p>一个程序在不执行选定代码行的阶段时，cox不会进行performance测试，这就会带来偏差，导致优化效果overstate。</p><p>程序执行分完成两个阶段： + A：选定行会执行 + B：选定行不执行</p><p><span class="math display">\[T = {t_{A}} + {t_{B}} \]</span> *总执行时间T等于两个阶段的时间和。</p><p><span class="math display">\[P = \frac{T}{N} = \frac{ {t_{A}} +{t_{B}} }{N}\]</span></p><ul><li>P : The average progress rate, 处理效率，即吞吐。</li></ul><p><span class="math display">\[s_{obs} = s *\frac{t_{obs}}{t_{A}}  \]</span></p><p><span class="math display">\[t_{A} \approx s *\frac{t_{obs}}{s_{obs}}  \]</span></p><ul><li><span class="math inline">\(s_{obs}\)</span>:性能测试期间采样到指定代码行的次数</li><li><span class="math inline">\(t_{obs}\)</span> ：性能测试的时间</li></ul><p><span class="math display">\[\triangle{p_{A}} = \frac{p_{A}-p_{A}^{'}}{p_{A}} \]</span></p><p><span class="math display">\[\triangle{p_{A}} =\frac{\frac{t_{A}}{n_{A}} -\frac{t_{A}^{'}}{n_{A}}}{\frac{t_{A}}{n_{A}}} =\frac{t_{A}-t_{A}^{'}}{t_{A}} \]</span></p><p><span class="math display">\[{P^{'}} =\frac{t_{A}^{'}+t_{B}}{N}  \]</span></p><p><span class="math display">\[\triangle{P} = \frac{P- P^{'}}{P} =\frac{\frac{t_{A}+t_{B}}{N}  - \frac{t_{A}^{'}+t_{B}}{N}}{\frac{T}{N}} = \frac{t_{A}-t_{A}^{'}}{T}\]</span></p><p><span class="math display">\[\triangle{P} =\triangle{p_{A}}\frac{t_{A}}{T} \approx \triangle{p_{A}}*\frac{t_{obs}}{s_{obs}} * \frac{s}{T}\]</span></p><h2 id="evaluation">Evaluation</h2><p>table3 总结了优化效果。</p><ol type="1"><li>cases where COZ found optimization op- portunities that gprof andperf did not (dedup, ferret, and SQLite);</li><li>cases where COZ identified contention (fluidani- mate,streamcluster, and Memcached);</li><li>cases where both COZ and a conventional profiler identified theoptimiza- tion we implemented (blackscholes and swaptions).</li></ol><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/3e570a7f1535a9fe210216f56bd2757e.png" alt="3e570a7f1535a9fe210216f56bd2757e"><figcaption aria-hidden="true">3e570a7f1535a9fe210216f56bd2757e</figcaption></figure><h3 id="case-study-dedup">Case Study: dedup</h3><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/1eb0da42674b21e5a56771950809904a.png" alt="1eb0da42674b21e5a56771950809904a"><figcaption aria-hidden="true">1eb0da42674b21e5a56771950809904a</figcaption></figure><ul><li><p>coz: We placed a progress point immediately after dedup completescompression of a single block of data (encoder.c:189).</p></li><li><p>分析:定位到hashtable.c:217,即hashtable search是做hash遍历，发现如图4：hash map不均衡，97%的bucket内有使用。</p></li><li><p>优化：采用remove bit shifting step和对32 bitchunks的key使用bitwise的XOR，来提高性能。</p></li><li><p>优化效果 8.95% ± 0.27% 。</p></li><li><p>gprof的缺陷： hashtable search had the largest share of highestexecution time at 14.38%, but calls to hashtable search from the hashcomputation stage accounted for just 0.48% of execution time; Gprof’scall graph actually obscured the importance of this code.</p></li></ul><h3 id="case-study-ferret">Case Study: ferret</h3><ul><li><p>分析吞吐，We first inserted a progress point in the final stageof the image search pipeline to measure throughput(ferret-parallel.c:398).</p></li><li><p>优化方案：thread allocation of 20, 1, 22, and 21 to segmentation,feature extraction, indexing, and ranking respectively.</p></li><li><p>优化效果： 21.27% ± 0.17% speedup</p></li><li><p>gprof的缺陷：优化前后用gprof观察不到显著区别。 <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/4927328700490394c84d46a6cdcc94be.png" alt="4927328700490394c84d46a6cdcc94be"></p></li></ul><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/2b18748360aca39c287e308e1690ce15.png" alt="2b18748360aca39c287e308e1690ce15"><figcaption aria-hidden="true">2b18748360aca39c287e308e1690ce15</figcaption></figure><h3 id="case-study-sqlite">Case Study: SQLite</h3><ul><li><p>Replacing these indirect calls with direct calls resulted in a25.60% ± 1.00% speedup.</p></li><li><p>perf缺陷：不是热点，没有发现问题。</p></li></ul><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/f7fcf04e3d0a329add71693e81f2a2f9.png" alt="f7fcf04e3d0a329add71693e81f2a2f9"><figcaption aria-hidden="true">f7fcf04e3d0a329add71693e81f2a2f9</figcaption></figure><h3 id="case-study-fluidanimate">Case Study: fluidanimate</h3><ul><li>coz: We placed a progress point immediately after the barrier, so itexecutes each time all threads complete a phase of the computation.</li><li>COZ also identified two significant points of contention, indicatedby a downward sloping causal profile.</li><li>优化方案：Removing this spinning from the barrier would reduce thecontention, but it was simpler to replace the custom barrier with thedefault pthread barrier implementation</li><li>效果：37.5% ± 0.56%</li></ul><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/284c3a1234d65ab474aa310ab7da77f7.png" alt="284c3a1234d65ab474aa310ab7da77f7"><figcaption aria-hidden="true">284c3a1234d65ab474aa310ab7da77f7</figcaption></figure><h3 id="case-study-streamcluster">Case Study: streamcluster</h3><ul><li>worker threads execute in concurrent phases separated by a custombarrier, where we placed a progress point.</li><li>Replacing this barrier with the default pthread barrier led to a68.4% ± 1.12% speedup.</li></ul><h3 id="case-study-memcached">Case Study: Memcached</h3><ul><li><p>We placed a progress point at the end of the process commandfunction, which handles each client request.</p></li><li><p>Because reference counts are updated atomically, we can safelyremove the lock from this function, which resulted in a 9.39% ± 0.95%speedup.</p></li></ul><h3 id="case-study-blackscholes">Case Study: blackscholes</h3><ul><li>We placed a progress point after each thread completes one round ofthe iterative approximation to the dif- ferential equation(blackscholes.c:259).</li><li>Manu- ally eliminating common subexpressions and combining 61piecewise calculations into 4 larger expressions resulted in a 2.56% ±0.41% program speedup. ### Case Study: swaptions</li><li>We placed a progress point after each iteration of the main loop ex-ecuted by worker threads (HJM Securities.cpp:99).</li><li>Reordering these loops and replacing the first loop with a call tomemset sped execution by 15.8% ± 1.10%.</li></ul><h3 id="effectiveness-summary">Effectiveness Summary</h3><p>In most cases, COZ identified around 20 lines of interest, with asmany as 50 for larger programs (Mem- cached and x264). COZ identifiedoptimization opportunities in all of the PARSEC benchmarks, but somerequired more invasive changes that are out of scope for this paper.<img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/b2de75fd51419add7018a677acc21e78.png" alt="b2de75fd51419add7018a677acc21e78"></p><h3 id="accuracy">Accuracy</h3><ul><li>为了优化 ferret，我们将索引阶段的线程数从 16 个增加到 22 个，这将第320 行的吞吐量提高了 27%。 COZ 预测这一改进将导致程序加速21.4%，这与我们观察到的 21.2% 几乎相同。</li><li>对于dedup，COZ 识别了遍历哈希桶链表的 while 循环的顶部。通过替换退化哈希函数，我们将每个哈希桶中的平均元素数量从 76.7 个减少到2.09 个。 此更改将迭代次数从 77.7 次减少到 3.09次（考虑到循环的最终行程）。 这一减少相当于 COZ 线加速了 96%。对于这次加速，COZ 预测性能提升为 9%，非常接近我们观察到的 8.95%的加速。</li></ul><h3 id="efficiency">Efficiency</h3><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/7eb9496c751a289797b09bc05984b12a.png" alt="7eb9496c751a289797b09bc05984b12a"><figcaption aria-hidden="true">7eb9496c751a289797b09bc05984b12a</figcaption></figure><p>减少开销。 大多数程序都有足够长的运行时间（平均：103秒）来分摊处理调试信息的成本，但在启动时处理特别大的可执行文件可能会很昂贵（例如x264 和 vips）。 可以修改 COZ 以延迟收集和处理调试信息，以减少启动开销。采样开销主要来自于在线程创建和退出时使用 perf event API 启动和停止采样。可以通过全局采样而不是按线程采样来摊销此成本，这需要大多数计算机上的root 权限。 如果 perf 事件 API支持对进程中的所有线程进行采样，则可以消除此开销。 延迟开销是 COZ总开销的最大组成部分，可以通过允许程序在每次实验之间正常执行一段时间来减少。增加实验之间的时间将显着减少开销，但需要更长的分析运行才能收集可用的配置文件。效率总结。 COZ 的分析开销平均为 17.6%（最小值：0.1%，最大值：65%）。对于除三个基准之外的所有基准，其开销均低于 30%。 鉴于广泛使用的 gprof分析器可能会产生更高的开销（例如，雪貂为 6 倍，而 COZ 为6%），这些结果证实 COZ 在实践中具有足够低的开销。</p><h2 id="related-work">Related Work</h2><p>因果分析识别并量化优化机会，而过去大多数分析器的工作都集中在以较低的开销收集详细的（尽管不一定是可操作的）信息。### 通用分析器 通用分析器通常使用仪器、采样或两者来实现。基于抽样（包括因果分析）的系统可以任意减少探测效应，尽管抽样必须是无偏的[35]。UNIX prof 工具和 oprofile 都专门使用采样 [29, 42]。 Oprofile可以使用各种硬件性能计数器进行采样，这些计数器可用于识别缓存恶意代码、预测不佳的分支和其他硬件瓶颈。Gprof 结合了仪器和采样来测量执行时间 [17]。 Gprof生成一个调用图配置文件，它对按调用者隔离的函数的调用进行计数。乔，莫斯利，等人通过交错检测和未检测执行来减少 Gprof 调用图分析的开销[9]。路径分析器添加了更多详细信息，计算通过过程或跨过程的每个路径的执行情况[2, 6]。</p><h3 id="并行分析器">并行分析器</h3><p>过去有关并行分析的工作主要集中在识别关键路径或瓶颈上，尽管优化关键路径或消除瓶颈可能不会显着提高程序性能。关键路径分析。 IPS使用消息传递程序的跟踪来识别关键路径，并报告每个过程对关键路径贡献的时间量[34]。 IPS-2 通过对共享内存并行性的有限支持扩展了这种方法 [33, 44]。其他关键路径分析器依赖具有first-class线程和同步的语言来识别关键路径[21,37,40]。识别关键路径可以帮助开发人员找到优化会产生一定影响的代码，但这些方法不会向开发人员提供有关在关键路径更改之前可能获得多少性能增益的任何信息。Hollingsworth 和 Miller引入了两个新指标来估算优化潜力：松弛，在关键路径发生变化之前可以改进多少过程；逻辑归零，即完全删除程序时关键路径长度的减少[22]。这些指标类似于因果分析器测量的优化潜力，但只能使用完整的程序活动图来计算。收集程序活动图的成本很高，并且可能会引入显著的探测效应。</p><h3 id="瓶颈识别">瓶颈识别。</h3><p>有几种方法使用硬件性能计数器来识别硬件级性能瓶颈[8,12,32]。基于二进制检测的技术可以识别缓存和堆性能问题、争用锁和其他程序热点[5,31,36]。ParaShares 和 Harmony 识别在很少或没有并行性的时期运行的基本块 [25,26]。 这些工具识别的代码是并行化或经典串行优化的良好候选者。 Bottlenecks是一种配置文件分析工具，它使用启发式方法通过调用树配置文件 [3]来识别瓶颈。给定不同执行的调用树配置文件，瓶颈可以查明哪些过程导致性能差异。FreeLunch 分析器和 Visual Studio的争用分析器可识别导致大量线程阻塞时间的锁 [11, 16]。 BIS使用类似的技术来识别非对称多处理器上高度竞争的关键部分，并自动将性能关键代码迁移到更快的内核[24]。 瓶图以视觉格式呈现线程执行时间和并行性，突出显示程序瓶颈[13]。与因果分析不同，这些工具无法预测消除瓶颈对性能的影响。所有这些系统只能识别显式线程通信引起的瓶颈，而因果分析可以测量任何来源的并行性能问题，包括缓存一致性协议、调度依赖性和I/O。 ### 分析并行化和可扩展性。已经开发了几个系统来测量串行程序中潜在的并行性[15,43,45]。与因果分析一样，这些系统可以识别可以从开发人员时间中受益的代码。与因果分析不同，这些工具的目的不是诊断已经并行化的代码中的性能问题。Kulkarni、Pai 和 Schuff 提出了可用并行性和可扩展性的一般指标[28]。Cilkview 可扩展性分析器使用 Cilk约束并行性的性能模型来估计添加额外硬件线程的性能影响 [20]。因果分析可以检测由于当前硬件平台上的扩展不良而导致的性能问题。</p><h3 id="时间归因分析器">时间归因分析器。</h3><p>时间归因分析器根据其他线程正在执行的操作将“责任”分配给并发执行的代码。Quartz引入了“正常处理器时间”的概念，这会给在大部分其他线程被阻塞时运行的代码分配很高的成本[4]。CPPROFJ 通过方面[19]将此方法扩展到 Java 程序。 CPPROFJ对时间使用更精细的类别：正在运行、阻塞较高优先级线程、等待监视器以及阻塞其他事件。Tallent 和 Mellor-Crummey 进一步扩展了这种方法来支持 Cilk程序，并添加了管理并行性所花费的时间类别 [41]。 WAIT工具添加了细粒度的分类来识别大规模生产 Java 系统中的瓶颈 [1]。与因果分析不同，这些分析器只能捕获直接影响其调度程序状态的线程之间的干扰。</p><h3 id="性能指导和实验">性能指导和实验</h3><p>一些系统已经利用延迟来提取有关程序执行时间的信息。 1.米特科维奇等人使用延迟来验证单线程 Java 程序上分析器的输出 [35]。 1.斯内利克，Ja ́Ja ́ 等人使用延迟来分析并行程序[38]。这种方法测量组合减速的影响，这需要针对指数数量的配置中的每一个完整执行程序。主动依赖发现（ADD）向分布式系统引入性能扰动并测量其对响应时间的影响[7]。ADD需要系统组件的完整枚举，并且需要开发人员手动插入性能扰动。 1.古纳维，阿格拉瓦尔等人使用延迟来识别 EMC Centera存储系统中事件之间的因果关系，以分析 Centera 的协议和策略 [18]。 1. Song和 Lu 使用机器学习来识别源代码中的性能反模式 [39]。</p><p>与因果分析不同，这些方法不能预测潜在优化的效果。</p><h2 id="结论">结论</h2><p>分析器是程序员工具箱中用于识别性能调整机会的主要工具。以前的分析器仅观察实际执行并将代码与执行时间或性能计数器关联起来。该信息的用途可能有限，因为所花费的时间不一定对应于程序员应该将优化工作的重点放在哪里。过去的分析器还仅限于报告端到端执行时间，这对于服务器和交互式应用程序来说并不重要，因为它们感兴趣的关键指标是吞吐量和延迟。因果分析是一种基于实验的新方法，可在假设的优化及其效果之间建立因果关系。通过虚拟地加速代码行，因果分析可以识别并量化任何程度的优化对任何代码行的吞吐量或延迟的影响。我们的原型因果分析器 COZ 在指导优化工作方面高效、准确且有效。</p>]]></content>
      
      
      <categories>
          
          <category> profiling </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux_kernel</title>
      <link href="/2023/09/18/linux-kernel/"/>
      <url>/2023/09/18/linux-kernel/</url>
      
        <content type="html"><![CDATA[<h2 id="内核同步介绍">9 内核同步介绍</h2><h3 id="临界区和同步">临界区和同步</h3><p>临界区：访问和共享数据的代码段。同步：避免并发和防止竞争条件称为同步（synchronization）。 ###为什么需要保护？为什么需要有临界区？ 银行系统</p><h3 id="怎么保护">怎么保护？</h3><p>处理器提供原子指令，先读后写。对于不那么固定长度的临界区，采用锁机制。各种锁机制的主要区别在于锁被占用是的处理行为： 忙等待 睡眠直到锁可用</p><h3 id="造成并发的原因">造成并发的原因</h3><p>中断 软中断和tasklet 内核抢占 睡眠及用户空间的同步 对称多处理机</p><p>加锁不难，难的是发现潜在并发可能性，有意识地放置并发。中断安全代码（interrupt-safe） SMP安全代码（SMP-safe）抢占安全代码（preempt-safe）</p><h3 id="死锁">死锁</h3><p>死锁类型： 自死锁：获取自己已经持有的锁ABBA死锁：每个线程持有其他线程需要的锁。 如何避免？ 按顺序加锁放置发生饥饿 不要重复请求同一个锁 设计力求简单：越复杂越有可能死锁</p><h3 id="锁争用和扩展性">锁争用和扩展性</h3><p>锁的高度争用会造成系统的瓶颈，严重降低系统性能。细粒度加锁可以避免不必要的竞争，但是过细的粒度会加大系统开销，造成浪费。</p>]]></content>
      
      
      <categories>
          
          <category> kernel </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>books</title>
      <link href="/2023/08/25/books/"/>
      <url>/2023/08/25/books/</url>
      
        <content type="html"><![CDATA[<h2 id="积灰中">积灰中</h2><h2 id="科学">科学</h2><ul><li>无穷大简史</li><li>从一到无穷大</li><li>古今数学思想</li><li>费曼物理学讲义</li><li>量子物理史话</li><li>裸眼观星：零障碍天文观测指南</li><li>所罗门王的指环:科普、自然</li><li>万物简史</li><li>哥白尼革命</li></ul><h2 id="技术">技术</h2><ul><li>半导体简史</li><li>芯片战争</li><li>失控</li><li>编译器设计</li><li>现代CPU性能分析与优化</li><li>CPU设计实战</li><li>高性能计算系列丛书·CUDA并行程序设计</li><li>昇腾AI处理器架构与编程</li><li>KVM实战：原理、进阶与性能调优</li><li>AI加速器架构设计与实现</li><li>ChatGPT原理与实战：大型语言模型的算法、技术和私有化</li><li>深度学习</li><li>深入Linux内核架构</li><li>深入理解Linux内核</li><li>深度探索Linux系统虚拟化</li><li>Linux内核设计与实现</li><li>程序员的自我修养</li><li>性能之巅</li><li>BPF之巅</li><li>kubernetes权威指南</li><li>Linux/UNIX系统编程手册</li></ul><h2 id="文学">文学</h2><ul><li>万火归一</li><li>神曲</li><li>老舍经典全集</li></ul><h2 id="社会科学与历史">社会科学与历史</h2><ul><li>文化失忆</li><li>旧制度与大革命</li><li>用后即弃的人</li><li>虚构的以色列地</li><li>改变心理学的40项研究</li><li>人类简史</li><li></li></ul><h2 id="哲学">哲学</h2><ul><li>大问题</li><li>人生的智慧：叔本华影响世界的哲学箴言</li><li>哥德尔、艾舍尔、巴赫：集异璧之大成</li></ul><h2 id="医学">医学</h2><ul><li>癌症真相</li></ul><h2 id="自然">自然</h2><ul><li>DK博物百科</li></ul><h2 id="to-read-list">TO read list</h2><h3 id="自然生物">自然、生物</h3><p>https://m.douban.com/subject_collection/EC445KZ2Q中国鸟类野外手册</p><h3 id="科普">科普</h3><p>宇宙的琴弦：弦理论</p><h3 id="心理学">心理学</h3><p>对伪心理学说不(无货)</p><h3 id="社会">社会</h3><h3 id="历史">历史</h3><h3 id="小说">小说</h3><h3 id="科技">科技</h3><ul><li>计算机程序的构造和解释 (ToSee)</li><li>深入理解计算机系统 (ToSee)</li><li>Python机器学习 (ToSee)</li><li>计算机网络：自顶向下方法 (ToSee)</li><li>算法导论 (ToSee)</li><li>人工智能：一种现代的方法 (ToSee)</li></ul>]]></content>
      
      
      <categories>
          
          <category> personal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>benchmark for network</title>
      <link href="/2023/08/25/network/"/>
      <url>/2023/08/25/network/</url>
      
        <content type="html"><![CDATA[<h2 id="qperf">qperf</h2><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># more qperf.sh</span></span><br><span class="line">echo <span class="string">"qperf test"</span></span><br><span class="line"><span class="attribute">server</span>=192.168.3.4</span><br><span class="line"><span class="attribute">ts</span>=$(date <span class="string">'+%Y%m%d%H%M%S'</span>)</span><br><span class="line"><span class="attribute">log</span>=amd-7w83-nps1-qperf-bandwidth-latency-bycore-$ts.csv</span><br><span class="line"></span><br><span class="line">echo <span class="string">""</span> &gt; <span class="variable">$log</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> {0<span class="built_in">..</span>127<span class="built_in">..</span>1}</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  #qperf bw</span><br><span class="line">  <span class="attribute">result</span>=`qperf --cpu_affinity <span class="variable">$c</span> <span class="variable">$server</span> tcp_bw  | tail -n 1`</span><br><span class="line">  <span class="attribute">bw</span>=`echo <span class="variable">$result</span> | awk <span class="string">'{print $3}'</span>`</span><br><span class="line"></span><br><span class="line">  #qperf latency</span><br><span class="line">  <span class="attribute">result</span>=`qperf --cpu_affinity <span class="variable">$c</span> <span class="variable">$server</span> tcp_lat  | tail -n 1`</span><br><span class="line">  <span class="attribute">lat</span>=`echo <span class="variable">$result</span> | awk <span class="string">'{print $3}'</span>`</span><br><span class="line"></span><br><span class="line">  echo <span class="variable">$c</span>,<span class="variable">$bw</span>,<span class="string">"GB/s"</span>,<span class="variable">$lat</span>,<span class="string">"us"</span> &gt;&gt; <span class="variable">$log</span></span><br><span class="line"></span><br><span class="line">done</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>qperf --cpu_affinity 100 192.168.3.4 tcp_lat tcp_lat: latency = 10.5us</p>]]></content>
      
      
      <categories>
          
          <category> profiling </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>perf</title>
      <link href="/2023/06/21/perf/"/>
      <url>/2023/06/21/perf/</url>
      
        <content type="html"><![CDATA[<h2 id="perf">perf</h2><h3 id="基础介绍">基础介绍</h3><p>perf的基础介绍可以参考：http://man7.org/linux/man-pages/man1/perf.1.htmlhttp://wiki.csie.ncku.edu.tw/embedded/perf-tutorial#perf-tophttps://blog.csdn.net/zhangskd/article/details/37902159</p><h2 id="perf-top宏观了解程序行为及热点函数">perftop：宏观了解程序行为及热点函数</h2><p>-p：指定进程号，常用 perf top -p 12345输出如下：第一列为函数耗时占比。第二列第三列显示的是函数 <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230621174110.png" alt="20230621174110"> 按a可以看汇编热点： <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/f118de541dc59778ea65e4277426797f.png" alt="f118de541dc59778ea65e4277426797f"></p><h2 id="perf-record记录程序行为以便分析">perfrecord：记录程序行为以便分析</h2><p>-g：用来记录函数调用栈，是火焰图的基础 -F 指定采样频率为99Hz(每秒99次) -- sleep ：用来控制采样记录的时长，一般60s;注意有空格</p><p>命令：perf record -g -p 12345 -- sleep 60 输出：当前目录下的perf.data处理该perf.data变为可读有两种办法(推荐第一种）： 1. perf script -iperf.data &gt; output.file 2. perf report -i perf.data</p><h3 id="火焰图">火焰图</h3><p>火焰图可以看到函数调用栈和热点函数（当热点函数连续的持续调用时间长，分散的是不太好从火焰图中直接观察到的）#### 下载链接 https://github.com/brendangregg/FlameGraph里面有处理脚本，无需安装 #### 生成火焰图在获得了上述perf统计的数据后，生成火焰图的命令如下： cat output.file |../FlameGraph-master/stackcollapse-perf.pl |../FlameGraph-master/flamegraph.pl &gt; flame.svg想要只观察指定函数的火焰图可以： cat output.file |../FlameGraph-master/stackcollapse-perf.pl | grep functionA |../FlameGraph-master/flamegraph.pl &gt; functionA.svg 展示如下： <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230621174147.png" alt="20230621174147"></p><h4 id="分散热点分析">分散热点分析</h4><p>上面提到对于分散的函数热点，火焰图不太好直接观测，可以采用下面的方法：1. 获取折叠的数据（格式如下）：cat output.file |../FlameGraph-master/stackcollapse-perf.pl &gt; perf.data.folded <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230621174205.png" alt="20230621174205"> 1. 提取要观测的函数例如FetchFromSpans: grepFetchFromSpans perf.data.folded | awk -F ' ' '{sum+=<span class="math inline">\(NF} END {print "Sum = ", sum}'2.  想要知道上述函数的比例需要计算所有函数的样本点：cat perf.data.folded| awk -F ' ' '{sum+=\)</span>NF} END {print "Sum = ",sum}'</p><h2 id="perf-sched">perf sched</h2><h3 id="timeline">timeline</h3><h4 id="根据传参对pid进行采集">根据传参，对pid进行采集</h4><p>perf sched record -a -g -p $pid -o perf.data -- sleep 5 ####对数据做格式化处理，输出时间片信息 perf sched timehist -f -i perf.data&gt; timehist.txt #### 对输出信息进行格式化处理，生成timehist.csv cattimehist.txt |sed 1,3d | awk '{print $1,$3,$4,$5,$6,$7}'|sed "s/[//g"|sed "s/]/ /g"|sed "s/// /g"|awk '{if(NF==7) {print$1,$2,"null",$3,$4,$5,$6,$7} else {print $0}}' &gt; timehist.csv</p><figure class="highlight haskell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@bjdd-acg-tge39-77f89.bjdd.baidu.com feedroiuserq]# perf sched record -<span class="type">F</span> <span class="number">99</span> -a -g -p <span class="number">83998</span> -o perf.<span class="class"><span class="keyword">data</span> <span class="comment">-- sleep 20</span></span></span><br><span class="line"><span class="type">Warning</span>:</span><br><span class="line"><span class="type">PID</span>/<span class="type">TID</span> switch overriding <span class="type">SYSTEM</span></span><br><span class="line">[ perf record: <span class="type">Woken</span> up <span class="number">107</span> times to write <span class="class"><span class="keyword">data</span> ]</span></span><br><span class="line">[ perf record: <span class="type">Captured</span> and wrote <span class="number">251.718</span> <span class="type">MB</span> perf.<span class="class"><span class="keyword">data</span> (1576867 <span class="title">samples</span>) ]</span></span><br><span class="line">[root@bjdd-acg-tge39-77f89.bjdd.baidu.com feedroiuserq]# ls</span><br><span class="line"><span class="title">err</span>.log  perf.<span class="class"><span class="keyword">data</span>  r000ps  r001ue  r002hs  r003macc  r004macc  r005mc  r006tr  r007hpc  r008io  r009mc  r010hs</span></span><br><span class="line">[root@bjdd-acg-tge39-77f89.bjdd.baidu.com feedroiuserq]# perf sched timehist -f -i perf.<span class="class"><span class="keyword">data</span> &gt; timehist.txt</span></span><br><span class="line">[root@bjdd-acg-tge39-77f89.bjdd.baidu.com feedroiuserq]# vi timehist.txt</span><br><span class="line">[root@bjdd-acg-tge39-77f89.bjdd.baidu.com feedroiuserq]#  cat timehist.txt | grep -vE ':|lost' | sed <span class="number">1</span>,3d | head</span><br><span class="line"> <span class="number">6037529.749004</span> [<span class="number">0044</span>]  feedroiuserq[<span class="number">84007</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">0.000</span>    __sched_text_start &lt;- __sched_text_start &lt;- futex_wait_queue_me &lt;- futex_wait &lt;- do_futex &lt;- sys_futex</span><br><span class="line"> <span class="number">6037529.749021</span> [<span class="number">0045</span>]  feedroiuserq[<span class="number">84005</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">0.000</span>    __sched_text_start &lt;- __sched_text_start &lt;- futex_wait_queue_me &lt;- futex_wait &lt;- do_futex &lt;- sys_futex</span><br><span class="line"> <span class="number">6037529.749971</span> [<span class="number">0051</span>]  feedroiuserq[<span class="number">91170</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">0.000</span>    __sched_text_start &lt;- __sched_text_start &lt;- futex_wait_queue_me &lt;- futex_wait &lt;- do_futex &lt;- sys_futex</span><br><span class="line"> <span class="number">6037529.750255</span> [<span class="number">0044</span>]  feedroiuserq[<span class="number">84007</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">1.250</span>    __sched_text_start &lt;- __sched_text_start &lt;- futex_wait_queue_me &lt;- futex_wait &lt;- do_futex &lt;- sys_futex</span><br><span class="line"> <span class="number">6037529.750277</span> [<span class="number">0045</span>]  feedroiuserq[<span class="number">84005</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">1.256</span>    __sched_text_start &lt;- __sched_text_start &lt;- futex_wait_queue_me &lt;- futex_wait &lt;- do_futex &lt;- sys_futex</span><br><span class="line"> <span class="number">6037529.750796</span> [<span class="number">0043</span>]  feedroiuserq[<span class="number">91178</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">0.000</span>    __sched_text_start &lt;- __sched_text_start &lt;- schedule_hrtimeout_range_clock &lt;- ep_poll &lt;- sys_epoll_wait &lt;- do_syscall_64</span><br><span class="line"> <span class="number">6037529.750976</span> [<span class="number">0052</span>]  feedroiuserq[<span class="number">91174</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">0.000</span>    __sched_text_start &lt;- __sched_text_start &lt;- schedule_hrtimeout_range_clock &lt;- ep_poll &lt;- sys_epoll_wait &lt;- do_syscall_64</span><br><span class="line"> <span class="number">6037529.751031</span> [<span class="number">0048</span>]  feedroiuserq[<span class="number">91176</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">0.000</span>    __sched_text_start &lt;- __sched_text_start &lt;- futex_wait_queue_me &lt;- futex_wait &lt;- do_futex &lt;- sys_futex</span><br><span class="line"> <span class="number">6037529.751043</span> [<span class="number">0043</span>]  feedroiuserq[<span class="number">91178</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">0.247</span>    __sched_text_start &lt;- __sched_text_start &lt;- schedule_hrtimeout_range_clock &lt;- ep_poll &lt;- sys_epoll_wait &lt;- do_syscall_64</span><br><span class="line"> <span class="number">6037529.751111</span> [<span class="number">0047</span>]  feedroiuserq[<span class="number">91177</span>/<span class="number">83998</span>]           <span class="number">0.000</span>      <span class="number">0.000</span>      <span class="number">0.000</span>    __sched_text_start &lt;- __sched_text_start &lt;- futex_wait_queue_me &lt;- futex_wait &lt;- do_futex &lt;- sys_futex</span><br><span class="line">[root@bjdd-acg-tge39-77f89.bjdd.baidu.com feedroiuserq]# cat timehist.txt | grep -vE ':|lost' | sed <span class="number">1</span>,3d | awk '{print $<span class="number">1</span>,$<span class="number">3</span>,$<span class="number">4</span>,$<span class="number">5</span>,$<span class="number">6</span>,$<span class="number">7</span>}' | head |sed <span class="string">"s/\[/ /g"</span> |sed <span class="string">"s/\]/ /g"</span> |sed <span class="string">"s/\// /g"</span>|awk '{<span class="keyword">if</span>(<span class="type">NF</span>==<span class="number">7</span>) {print $<span class="number">1</span>,$<span class="number">2</span>,$<span class="number">3</span>,$<span class="number">3</span>,$<span class="number">4</span>,$<span class="number">5</span>,$<span class="number">6</span>,$<span class="number">7</span>} <span class="keyword">else</span> {print $<span class="number">0</span>}}' |sed <span class="string">"s/[ ][ ]*/,/g"</span></span><br><span class="line"><span class="number">6037529.749004</span>,feedroiuserq,<span class="number">84007</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.749021</span>,feedroiuserq,<span class="number">84005</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.749971</span>,feedroiuserq,<span class="number">91170</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.750255</span>,feedroiuserq,<span class="number">84007</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">1.250</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.750277</span>,feedroiuserq,<span class="number">84005</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">1.256</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.750796</span>,feedroiuserq,<span class="number">91178</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.750976</span>,feedroiuserq,<span class="number">91174</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.751031</span>,feedroiuserq,<span class="number">91176</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.751043</span>,feedroiuserq,<span class="number">91178</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">0.247</span>,__sched_text_start</span><br><span class="line"><span class="number">6037529.751111</span>,feedroiuserq,<span class="number">91177</span>,<span class="number">83998</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,<span class="number">0.000</span>,__sched_text_start</span><br></pre></td></tr></tbody></table></figure><h3 id="perf-sched-latency">perf sched latency</h3><figure class="highlight crmsh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@bjdd-acg-tge39-<span class="number">77</span>f89.bjdd.baidu.com lyj]<span class="comment"># perf sched latency -s runtime</span></span><br><span class="line"></span><br><span class="line"> -----------------------------------------------------------------------------------------------------------------</span><br><span class="line">  Task                  |   Runtime <span class="keyword">ms</span>  <span class="title">| Switches</span> | Average delay <span class="keyword">ms</span> <span class="title">| Maximum</span> delay <span class="keyword">ms</span> <span class="title">| Maximum</span> delay at       |</span><br><span class="line"> -----------------------------------------------------------------------------------------------------------------</span><br><span class="line">  cc1:(<span class="number">201</span>)             |   <span class="number">6777.688</span> <span class="keyword">ms</span> <span class="title">|      294</span> | avg:    <span class="number">0.004</span> <span class="keyword">ms</span> <span class="title">| max</span>:    <span class="number">0.023</span> <span class="keyword">ms</span> <span class="title">| max</span> at: <span class="number">10766938.333270</span> s</span><br><span class="line">  machine_load_co:(<span class="number">4</span>)   |    <span class="number">901.555</span> <span class="keyword">ms</span> <span class="title">|       26</span> | avg:    <span class="number">0.002</span> <span class="keyword">ms</span> <span class="title">| max</span>:    <span class="number">0.007</span> <span class="keyword">ms</span> <span class="title">| max</span> at: <span class="number">10766932.445528</span> s</span><br><span class="line">  ld:(<span class="number">89</span>)               |    <span class="number">873.351</span> <span class="keyword">ms</span> <span class="title">|      112</span> | avg:    <span class="number">0.013</span> <span class="keyword">ms</span> <span class="title">| max</span>:    <span class="number">1.133</span> <span class="keyword">ms</span> <span class="title">| max</span> at: <span class="number">10766934.072955</span> s</span><br><span class="line">  configure:(<span class="number">483</span>)       |    <span class="number">754.665</span> <span class="keyword">ms</span> <span class="title">|     2210</span> | avg:    <span class="number">0.007</span> <span class="keyword">ms</span> <span class="title">| max</span>:    <span class="number">0.691</span> <span class="keyword">ms</span> <span class="title">| max</span> at: <span class="number">10766932.195960</span> s</span><br><span class="line">  halolet:(<span class="number">75</span>)          |    <span class="number">745.764</span> <span class="keyword">ms</span> <span class="title">|    10530</span> | avg:    <span class="number">0.001</span> <span class="keyword">ms</span> <span class="title">| max</span>:    <span class="number">2.572</span> <span class="keyword">ms</span> <span class="title">| max</span> at: <span class="number">10766934.423655</span> s</span><br></pre></td></tr></tbody></table></figure><p>Task：这一列显示了任务或进程的名称或标识符。 Runtimems：此列表示任务的运行时间，以毫秒为单位。它显示了任务在调度期间的实际运行时间。Switches：此列表示任务的上下文切换次数。上下文切换是指从一个正在执行的任务切换到另一个任务的过程。Average delayms：这一列显示了任务的平均调度延迟，以毫秒为单位。它表示任务在等待调度时的平均延迟时间。Maximum delayms：此列显示了任务的最大调度延迟，以毫秒为单位。它表示任务在等待调度时的最长延迟时间。Maximum delayat：这一列显示了任务出现最大调度延迟的时间戳，通常以秒为单位。</p>]]></content>
      
      
      <categories>
          
          <category> profiling </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>stream</title>
      <link href="/2023/06/07/stream/"/>
      <url>/2023/06/07/stream/</url>
      
        <content type="html"><![CDATA[<p>https://www.cs.virginia.edu/stream/FTP/Code/stream.chttps://bbs.huaweicloud.com/blogs/388380https://zhuanlan.zhihu.com/p/407489860</p><h2 id="服务器资源监控工具stream">服务器资源监控工具——Stream</h2><h3 id="原理">原理</h3><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230607145033.png" alt="20230607145033"><figcaption aria-hidden="true">20230607145033</figcaption></figure><h3 id="编译安装stream">编译安装——Stream</h3><h4 id="源码编译安装">源码编译安装</h4><p>​ 下载源码： </p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.cs.virginia.edu/stream/FTP/Code/stream.c</span><br></pre></td></tr></tbody></table></figure> ​ 解压编译： <figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -O3 -fopenmp -DSTREAM_ARRAY_SIZE=2000000 -DNTIMES=10 stream.c -o stream</span><br></pre></td></tr></tbody></table></figure> ​ 参数说明：<figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">-O3：</span><br><span class="line">    指定最高编译优化级别，即3</span><br><span class="line"></span><br><span class="line">-fopenmp：</span><br><span class="line">    启用OpenMP，适应多处理器环境，更能得到内存带宽实际最大值。开启后，程序默认运行线程为CPU线程数</span><br><span class="line"></span><br><span class="line"><span class="attribute">-DSTREAM_ARRAY_SIZE</span>=2000000：</span><br><span class="line">    指定测试数组a[]、b[]、c[]的大小（Array size）。若stream.c为5.10版本，参数名变为-DSTREAM_ARRAY_SIZE，默认值10000000）。</span><br><span class="line">    注意：必须设置测试数组大小远大于CPU 最高级缓存（一般为L3 Cache）的大小，否则就是测试CPU缓存的吞吐性能，而非内存吞吐性能。</span><br><span class="line">    推荐计算公式：{最高级缓存X MB}×1024×1024×4.1×CPU路数/8，结果取整数</span><br><span class="line">    解释：由于stream.c源码推荐设置至少4倍最高级缓存，且STREAM_ARRAY_SIZE的数据为double类型=8 Byte。所以公式为：最高级缓存(单位：Byte)×4.1倍×CPU路数/8</span><br><span class="line">    例如：测试机器是双路CPU，最高级缓存32MB，则计算值为32×1024×1024×4.1×2/8≈34393292</span><br><span class="line"></span><br><span class="line"><span class="attribute">-DNTIMES</span>=10：</span><br><span class="line">    执行的次数，并从这些结果中选最优值。</span><br><span class="line"></span><br><span class="line">stream.c：</span><br><span class="line">    待编译的源码文件</span><br><span class="line"></span><br><span class="line">stream：</span><br><span class="line">    输出的可执行文件名</span><br><span class="line"></span><br><span class="line">其他参数：</span><br><span class="line"><span class="attribute">-mtune</span>=native <span class="attribute">-march</span>=native：</span><br><span class="line">    针对CPU指令的优化，此处由于编译机即运行机器。故采用native的优化方法。更多编译器对CPU的优化参考</span><br><span class="line">    </span><br><span class="line"><span class="attribute">-mcmodel</span>=medium：</span><br><span class="line">    当单个Memory Array Size 大于2GB时需要设置此参数</span><br><span class="line">    </span><br><span class="line"><span class="attribute">-DOFFSET</span>=4096：</span><br><span class="line">    数组的偏移，一般可以不定义</span><br></pre></td></tr></tbody></table></figure><p></p>]]></content>
      
      
      <categories>
          
          <category> benchmark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SPEC CPU2017</title>
      <link href="/2023/06/07/SPEC%20CPU2017/"/>
      <url>/2023/06/07/SPEC%20CPU2017/</url>
      
        <content type="html"><![CDATA[<p>https://www.zhihu.com/question/19773867/answer/2857416414</p><p>https://tosiron.com/papers/2018/SPEC2017_ISPASS18.pdf</p>]]></content>
      
      
      <categories>
          
          <category> benchmark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>benchmark</title>
      <link href="/2023/06/07/benchmark/"/>
      <url>/2023/06/07/benchmark/</url>
      
        <content type="html"><![CDATA[<table><colgroup><col style="width: 21%"><col style="width: 52%"><col style="width: 26%"></colgroup><thead><tr><th style="text-align: left;"></th><th style="text-align: left;">测试内容</th><th style="text-align: left;">benchmark</th></tr></thead><tbody><tr><td style="text-align: left;">CPU性能</td><td style="text-align: left;">整型</td><td style="text-align: left;">SPECint</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">浮点</td><td style="text-align: left;">SPECfp</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">综合</td><td style="text-align: left;">unixbench</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;">Cinebench</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;">stress-ng</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">cpu core</td><td style="text-align: left;">coremark</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">SIMD</td><td style="text-align: left;">Linpack</td></tr><tr><td style="text-align: left;">CPU频率</td><td style="text-align: left;">CPU空载频率</td><td style="text-align: left;">frequency_monitoring</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">CPUSPECInt频率（跑SPECint时的平均频率）</td><td style="text-align: left;">SPECInt2017+</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;">frequency_monitoring</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">CPUSPECfp频率（跑SPECfp时的平均频率）</td><td style="text-align: left;">SPECfp2017+</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;">frequency_monitoring</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">CPU SIMD频率</td><td style="text-align: left;">Linpack+</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">（跑avx/avx2/avx3/TMUL时的频率）</td><td style="text-align: left;">frequency_monitoring、cpupower</td></tr><tr><td style="text-align: left;">内存</td><td style="text-align: left;">带宽(lolcal/remote)</td><td style="text-align: left;">stream</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;">MLC</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;">ramspeed</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">延时</td><td style="text-align: left;">MLC</td></tr><tr><td style="text-align: left;">cache</td><td style="text-align: left;">L1/L2/L3延时</td><td style="text-align: left;">lmbench</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">L3带宽</td><td style="text-align: left;">MLC</td></tr><tr><td style="text-align: left;">磁盘</td><td style="text-align: left;">带宽/IOPS</td><td style="text-align: left;">FIO</td></tr><tr><td style="text-align: left;">网络</td><td style="text-align: left;">带宽/IOPS</td><td style="text-align: left;">iperf</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;">netperf</td></tr><tr><td style="text-align: left;">虚拟化</td><td style="text-align: left;"></td><td style="text-align: left;">SPECvirt Datacenter</td></tr><tr><td style="text-align: left;">Java</td><td style="text-align: left;"></td><td style="text-align: left;">SPECjbb</td></tr><tr><td style="text-align: left;">功耗</td><td style="text-align: left;">整机功耗</td><td style="text-align: left;">SPECPOWER</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;"></td><td style="text-align: left;">Sert</td></tr><tr><td style="text-align: left;">监控</td><td style="text-align: left;"></td><td style="text-align: left;">PTU</td></tr><tr><td style="text-align: left;">压力</td><td style="text-align: left;"></td><td style="text-align: left;">PTU</td></tr><tr><td style="text-align: left;">总线（PCIE/UPI）</td><td style="text-align: left;"></td><td style="text-align: left;">intel工具</td></tr></tbody></table><ul><li>memory带宽和延迟的曲线关系<ul><li>done：https://nga.178.com/read.php?tid=21282980&amp;rand=601</li></ul></li></ul><h2 id="lmbench">lmbench</h2><p>lmbench是一个用来测量Linux/Unix系统性能的工具套件，其名字来源于"LM",即 Larry McVoy 和 “benchmark”的组合，LarryMcVoy是lmbench的主要开发者。</p><p>lmbench工具套件包含多个基准测试工具，每个工具都是用来测量特定系统或硬件性能的，包括CPU（如L1、L2缓存、内存等）、系统调用、管道、进程创建、网络性能（TCP、UDP等）、文件系统等多个方面。该工具套件使用C语言编写，采用微基准测试（micro-benchmark）的方式，即通过大量反复执行简单且对性能影响明显的操作（如读写操作、系统调用）来测量性能。</p><p>具体运行时，你可以通过指定参数来选择你想要测试的设备或功能，lmbench将执行相应的操作进行测试，然后统计和分析这些操作的执行时间或者速度，据此来评估系统性能。</p><p>其原理主要基于计算机科学中的基准测试原理，即通过一组预定义的操作来客观地评估硬件或软件的性能，并通过这些结果来进行系统优化或者进行设备之间的比较。</p><p>https://blog.csdn.net/qq_36393978/article/details/125989992</p><h2 id="mlc">mlc</h2><p>https://www.intel.cn/content/www/cn/zh/developer/articles/tool/intelr-memory-latency-checker.html</p><p>https://zhuanlan.zhihu.com/p/447936509</p><p>Intel开发的Memory LatencyChecker（MLC）是一种工具，用于在Intel处理器上测量内存子系统的延迟和带宽。它主要通过两种方法进行测试：</p><p>内存延迟测试：MLC使用Load-Use或者PointerChasing的方法来测算内存访问的延迟时间。“Load-Use”是将一条指令的输出作为后续指令的输入，通过这种依赖关系测量从内存加载数据到CPU寄存器的时间。“PointerChasing”则是创建一个指针数组，然后使CPU沿着这些指针"追踪"数据，这种方法能够有效的测量处理器对内存的访问延迟。</p><p>内存带宽测试：MLE通过特定的内存访问模式如顺序访问或随机访问，以及固定数量的并行访问线程，来测量处理器能够达到的最大内存带宽。这个测试能够反映出内存子系统的负载情况，以及多核心间的内存带宽共享情况。</p><p>通过这两种方法，MLE可以全面地测量和理解处理器的内存性能，从而帮助系统优化专家针对性的进行硬件调整和软件优化，以充分挖掘和利用计算机系统的定向性能。</p><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">Intel(R) Memory Latency Checker - v3.<span class="number">10</span></span><br><span class="line">Measuring idle latencies for sequential access (in ns)...</span><br><span class="line">        Numa node</span><br><span class="line">Numa node         <span class="number">0</span>     <span class="number">1</span></span><br><span class="line">       <span class="number">0</span>      <span class="number">83</span>.<span class="number">4</span> <span class="number">132</span>.<span class="number">9</span></span><br><span class="line">       <span class="number">1</span>     <span class="number">136</span>.<span class="number">5</span>  <span class="number">79</span>.<span class="number">7</span></span><br><span class="line"></span><br><span class="line">Measuring Peak Injection Memory Bandwidths for the system</span><br><span class="line">Bandwidths are in MB/sec (<span class="number">1</span> MB/sec = <span class="number">1</span>,<span class="number">000,000</span> Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using traffic with the following read-write ratios</span><br><span class="line">ALL Reads        :    <span class="number">107686.1</span></span><br><span class="line"><span class="number">3</span>:<span class="number">1</span> Reads-Writes :    <span class="number">90658.9</span></span><br><span class="line"><span class="number">2</span>:<span class="number">1</span> Reads-Writes :    <span class="number">86887.9</span></span><br><span class="line"><span class="number">1</span>:<span class="number">1</span> Reads-Writes :    <span class="number">68752.4</span></span><br><span class="line">Stream-triad like:    <span class="number">74245.6</span></span><br><span class="line"></span><br><span class="line">Measuring Memory Bandwidths between nodes within system</span><br><span class="line">Bandwidths are in MB/sec (<span class="number">1</span> MB/sec = <span class="number">1</span>,<span class="number">000,000</span> Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using Read-only traffic type</span><br><span class="line">        Numa node</span><br><span class="line">Numa node         <span class="number">0</span>     <span class="number">1</span></span><br><span class="line">       <span class="number">0    111204.7</span><span class="number">34309.2</span></span><br><span class="line">       <span class="number">1    34283.0</span><span class="number">110464.5</span></span><br><span class="line"></span><br><span class="line">Measuring Loaded Latencies for the system</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using Read-only traffic type</span><br><span class="line">Inject    LatencyBandwidth</span><br><span class="line">Delay    (ns)MB/sec</span><br><span class="line">==========================</span><br><span class="line"> <span class="number">00000    257</span>.<span class="number">07</span> <span class="number">219957.7</span></span><br><span class="line"> <span class="number">00002    257</span>.<span class="number">55</span> <span class="number">220385.6</span></span><br><span class="line"> <span class="number">00008    260</span>.<span class="number">01</span> <span class="number">219768.3</span></span><br><span class="line"> <span class="number">00015    256</span>.<span class="number">79</span> <span class="number">220255.4</span></span><br><span class="line"> <span class="number">00050    253.01</span> <span class="number">221044.1</span></span><br><span class="line"> <span class="number">00100    255.28</span> <span class="number">220292.6</span></span><br><span class="line"> <span class="number">00200    128.30</span> <span class="number">173953.4</span></span><br><span class="line"> <span class="number">00300    111.38</span> <span class="number">118262.0</span></span><br><span class="line"> <span class="number">00400    108.22</span>  <span class="number">89920.4</span></span><br><span class="line"> <span class="number">00500    116.18</span>  <span class="number">71995.6</span></span><br><span class="line"> <span class="number">00700    105.37</span>  <span class="number">52788.4</span></span><br><span class="line"> <span class="number">01000</span>     <span class="number">97</span>.<span class="number">67</span>  <span class="number">37175.9</span></span><br><span class="line"> <span class="number">01300</span>     <span class="number">95</span>.<span class="number">87</span>  <span class="number">28641.6</span></span><br><span class="line"> <span class="number">01700</span>     <span class="number">94</span>.<span class="number">88</span>  <span class="number">22091.6</span></span><br><span class="line"> <span class="number">02500</span>     <span class="number">93</span>.<span class="number">82</span>  <span class="number">15327.3</span></span><br><span class="line"> <span class="number">03500</span>     <span class="number">92</span>.<span class="number">26</span>  <span class="number">11095.0</span></span><br><span class="line"> <span class="number">05000</span>     <span class="number">92</span>.<span class="number">03</span>   <span class="number">7988</span>.<span class="number">1</span></span><br><span class="line"> <span class="number">09000</span>     <span class="number">91</span>.<span class="number">29</span>   <span class="number">4704</span>.<span class="number">6</span></span><br><span class="line"> <span class="number">20000</span>     <span class="number">91</span>.<span class="number">24</span>   <span class="number">2537</span>.<span class="number">2</span></span><br><span class="line"></span><br><span class="line">Measuring cache-to-cache transfer latency (in ns)...</span><br><span class="line">Local Socket L2-&gt;L2 HIT  latency    <span class="number">51</span>.<span class="number">4</span></span><br><span class="line">Local Socket L2-&gt;L2 HITM latency    <span class="number">51</span>.<span class="number">5</span></span><br><span class="line">Remote Socket L2-&gt;L2 HITM latency (data address homed in writer socket)</span><br><span class="line">            Reader Numa Node</span><br><span class="line">Writer Numa Node     <span class="number">0</span>         <span class="number">1</span></span><br><span class="line">            <span class="number">0</span>         - <span class="number">113</span>.<span class="number">5</span></span><br><span class="line">            <span class="number">1</span>     <span class="number">113</span>.<span class="number">5</span>     -</span><br><span class="line">Remote Socket L2-&gt;L2 HITM latency (data address homed in reader socket)</span><br><span class="line">            Reader Numa Node</span><br><span class="line">Writer Numa Node     <span class="number">0</span>         <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><p>./mlc --loaded_latency -d0 -b${buffer} -${OPERATION} -t${DRATION} -T-k${cores}</p><p>在CORES的CPU上配置buffer大小的内存对象，执行OPERATION操作DURATION秒。</p><p>mlc --c2c_latency -w${dest} -c${SRC} </p><figure class="highlight llvm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="title">@bddwd-sys-xaware08.bddwd.baidu.com</span> Linux]# numactl -N <span class="number">1</span> ./mlc --<span class="keyword">c</span><span class="number">2</span>c_latency -w<span class="number">0</span> -<span class="keyword">c</span><span class="number">24</span></span><br><span class="line">Intel(R) Memory Latency Checker - v<span class="number">3.10</span></span><br><span class="line">Command line parameters: --<span class="keyword">c</span><span class="number">2</span>c_latency -w<span class="number">0</span> -<span class="keyword">c</span><span class="number">24</span></span><br><span class="line"></span><br><span class="line">Measuring cache-<span class="keyword">to</span>-cache transfer latency (in ns)...</span><br><span class="line"></span><br><span class="line">Latency <span class="operator">=</span> <span class="number">294.8</span> base frequency clocks (<span class="number">113.7</span> ns)</span><br><span class="line">[root<span class="title">@bddwd-sys-xaware08.bddwd.baidu.com</span> Linux]# numactl -N <span class="number">1</span> ./mlc --<span class="keyword">c</span><span class="number">2</span>c_latency -w<span class="number">24</span> -<span class="keyword">c</span><span class="number">0</span></span><br><span class="line">Intel(R) Memory Latency Checker - v<span class="number">3.10</span></span><br><span class="line">Command line parameters: --<span class="keyword">c</span><span class="number">2</span>c_latency -w<span class="number">24</span> -<span class="keyword">c</span><span class="number">0</span></span><br><span class="line"></span><br><span class="line">Measuring cache-<span class="keyword">to</span>-cache transfer latency (in ns)...</span><br><span class="line"></span><br><span class="line">Latency <span class="operator">=</span> <span class="number">459.1</span> base frequency clocks (<span class="number">177.0</span> ns)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure> ## stream ### 原理原理:copy+scale+add+triad <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230607145033.png" alt="20230607145033"><p></p><h3 id="编译安装stream">编译安装——Stream</h3><h4 id="源码编译安装">源码编译安装</h4><p>​ 下载源码： </p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.cs.virginia.edu/stream/FTP/Code/stream.c</span><br></pre></td></tr></tbody></table></figure> ​ 解压编译： <figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -O3 -fopenmp -DSTREAM_ARRAY_SIZE=2000000 -DNTIMES=10 stream.c -o stream</span><br></pre></td></tr></tbody></table></figure> ​ 参数说明：<figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">-O3：</span><br><span class="line">    指定最高编译优化级别，即3</span><br><span class="line"></span><br><span class="line">-fopenmp：</span><br><span class="line">    启用OpenMP，适应多处理器环境，更能得到内存带宽实际最大值。开启后，程序默认运行线程为CPU线程数</span><br><span class="line"></span><br><span class="line"><span class="attribute">-DSTREAM_ARRAY_SIZE</span>=2000000：</span><br><span class="line">    指定测试数组a[]、b[]、c[]的大小（Array size）。若stream.c为5.10版本，参数名变为-DSTREAM_ARRAY_SIZE，默认值10000000）。</span><br><span class="line">    注意：必须设置测试数组大小远大于CPU 最高级缓存（一般为L3 Cache）的大小，否则就是测试CPU缓存的吞吐性能，而非内存吞吐性能。</span><br><span class="line">    推荐计算公式：{最高级缓存X MB}×1024×1024×4.1×CPU路数/8，结果取整数</span><br><span class="line">    解释：由于stream.c源码推荐设置至少4倍最高级缓存，且STREAM_ARRAY_SIZE的数据为double类型=8 Byte。所以公式为：最高级缓存(单位：Byte)×4.1倍×CPU路数/8</span><br><span class="line">    例如：测试机器是双路CPU，最高级缓存32MB，则计算值为32×1024×1024×4.1×2/8≈34393292</span><br><span class="line"></span><br><span class="line"><span class="attribute">-DNTIMES</span>=10：</span><br><span class="line">    执行的次数，并从这些结果中选最优值。</span><br><span class="line"></span><br><span class="line">stream.c：</span><br><span class="line">    待编译的源码文件</span><br><span class="line"></span><br><span class="line">stream：</span><br><span class="line">    输出的可执行文件名</span><br><span class="line"></span><br><span class="line">其他参数：</span><br><span class="line"><span class="attribute">-mtune</span>=native <span class="attribute">-march</span>=native：</span><br><span class="line">    针对CPU指令的优化，此处由于编译机即运行机器。故采用native的优化方法。更多编译器对CPU的优化参考</span><br><span class="line">    </span><br><span class="line"><span class="attribute">-mcmodel</span>=medium：</span><br><span class="line">    当单个Memory Array Size 大于2GB时需要设置此参数</span><br><span class="line">    </span><br><span class="line"><span class="attribute">-DOFFSET</span>=4096：</span><br><span class="line">    数组的偏移，一般可以不定义</span><br></pre></td></tr></tbody></table></figure><p></p><p>https://zhuanlan.zhihu.com/p/407489860https://www.cnblogs.com/iouwenbo/p/14377478.html</p><h2 id="multichase">multichase</h2><p>https://github.com/google/multichase</p><h2 id="fio">fio</h2><p>fio是一个灵活的I/O性能测试工具，它可以生成和测量各种类型的I/O负载。它被广泛用于性能分析和基准测试。fio可以模拟多种I/O工作负载，包括顺序读写、随机读写、混合工作负载等。 ‎</p><h3 id="命令解析">命令解析</h3><p>‎ 一个基本的 fio 命令可能看起来像这样： ‎ </p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fio <span class="attribute">--name</span>=test <span class="attribute">--ioengine</span>=libaio <span class="attribute">--iodepth</span>=4 <span class="attribute">--rw</span>=read <span class="attribute">--bs</span>=4k <span class="attribute">--direct</span>=1 <span class="attribute">--size</span>=1G <span class="attribute">--numjobs</span>=1 <span class="attribute">--runtime</span>=60</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p></p><p>下面是一些常用的 fio 参数： ‎</p><ul><li>--name: 测试的名称。</li><li>--ioengine: I/O引擎类型（如 sync, libaio, posixaio, mmap 等）。</li><li>--iodepth: 对于异步I/O引擎，这指定了队列深度。</li><li>--rw: I/O模式（如 read, write, randread, randwrite, randrw等）。</li><li>--bs: 块大小，即每次I/O操作的数据量。</li><li>--direct: 是否绕过缓存。1 表示绕过操作系统的缓存。</li><li>--size: 测试文件的大小。</li><li>--numjobs: 同时运行的作业数。</li><li>--runtime: 测试运行的时间。 ‎</li></ul><h3 id="结果解读">结果解读</h3><p>‎ fio 输出的结果包含了多个部分，主要包括： ‎</p><ul><li>IOPS: 每秒输入/输出操作数。这是衡量存储性能的关键指标之一。</li><li>BW: 带宽，通常以MB/s（兆字节每秒）表示，显示了数据传输的速度。</li><li>clat (Completion latency):完成延迟，即从I/O请求发出到完成所需的时间。</li><li>slat (Submission latency):提交延迟，即从I/O请求生成到提交给I/O引擎所需的时间。</li><li>lat (Latency): 总延迟，包括提交延迟和完成延迟。 ‎ 一个典型的 fio输出可能包含以下内容：</li></ul><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">test</span>: (groupid=<span class="number">0</span>, jobs=<span class="number">1</span>): err= <span class="number">0</span>: pid=<span class="number">1234</span></span><br><span class="line">  <span class="attribute">read</span>: IOPS=<span class="number">25</span>.<span class="number">0</span>k, BW=<span class="number">98</span>.<span class="number">0</span>MiB/s (<span class="number">102</span>MB/s)(<span class="number">5</span>.<span class="number">74</span>GiB/<span class="number">60001</span>msec)</span><br><span class="line">    <span class="attribute">slat</span> (usec): min=<span class="number">2</span>, max=<span class="number">12</span>, avg= <span class="number">4</span>.<span class="number">00</span>, stdev= <span class="number">1</span>.<span class="number">20</span></span><br><span class="line">    <span class="attribute">clat</span> (usec): min=<span class="number">20</span>, max=<span class="number">3400</span>, avg=<span class="number">40</span>.<span class="number">00</span>, stdev= <span class="number">7</span>.<span class="number">50</span></span><br><span class="line">     <span class="attribute">lat</span> (usec): min=<span class="number">22</span>, max=<span class="number">3412</span>, avg=<span class="number">44</span>.<span class="number">00</span>, stdev= <span class="number">7</span>.<span class="number">70</span></span><br></pre></td></tr></tbody></table></figure><p>‎ 这表示： ‎</p><ul><li>测试名称为 test，作业数为1。</li><li>没有错误发生。</li><li>读取操作的IOPS为25,000，带宽为98.0MiB/s。</li><li>提交延迟的最小值为2微秒，最大值为12微秒，平均值为4微秒，标准差为1.2微秒。</li><li>完成延迟的最小值为20微秒，最大值为3400微秒，平均值为40微秒，标准差为7.5微秒。</li><li>总延迟的最小值为22微秒，最大值为3412微秒，平均值为44微秒，标准差为7.7微秒。‎</li></ul><p>fio的输出非常详细，可以提供关于存储性能的深入见解。解读这些结果时，重要的是要关注与你的特定测试目标最相关的指标。例如，如果你关心随机读写性能，那么随机读写的IOPS和延迟将是你最关注的指标。如果你在测试顺序读写性能，那么带宽可能是更重要的指标。</p><h2 id="netperf">netperf</h2><p>netperf是一个网络性能测试工具，它可以测试网络连接的各种方面，包括吞吐量、延迟和包传输速率。netperf主要由两个组件组成：一个服务器端 (netserver) 和一个客户端(netperf)。服务器端在待测试的网络节点上运行，而客户端从另一端连接到服务器端以进行测试。‎</p><h3 id="使用-netperf">使用 netperf</h3><p>‎ 在开始测试之前，你需要在两台机器上安装netperf。一台机器将作为服务器运行 netserver，另一台机器将作为客户端运行netperf。 ‎</p><ol type="1"><li>启动服务器端： 在服务器机器上，运行以下命令来启动 netserver：netserver ‎</li><li>运行客户端测试： 在客户端机器上，使用 netperf命令来执行测试。例如，要测试TCP连接的吞吐量，可以运行：</li></ol><p>netperf -H <server_ip_address> 其中 <server_ip_address>是服务器端的IP地址。 ‎</server_ip_address></server_ip_address></p><h3 id="命令解析-1">命令解析</h3><p>‎ netperf 提供了多种选项来定制测试。以下是一些常用的选项： ‎</p><ul><li><p>-H 或 --host：指定服务器端的主机名或IP地址。</p></li><li><p>-p 或 --port：指定服务器端的端口号（默认是12865）。</p></li><li><p>-t 或 --test：指定要运行的测试类型，如TCP_STREAM（TCP吞吐量测试）或 UDP_STREAM（UDP吞吐量测试）。</p></li><li><p>-l 或 --time：指定测试持续的时间（秒）。</p></li><li><p>-i 或 --interval：指定显示中间结果的时间间隔（秒）。</p></li><li><p>-- -m：指定发送缓冲区的大小（字节）。</p></li><li><p>-- -M：指定接收缓冲区的大小（字节）。 ‎ ### 结果解读 ‎ netperf输出的结果会根据所选的测试类型而有所不同。对于一个基本的TCP吞吐量测试，输出可能包含以下内容：‎</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MIGRATED TCP STREAM TEST <span class="built_in">from</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span> (<span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>) port <span class="number">0</span> AF_INET <span class="built_in">to</span> &lt;server_ip_address&gt; (x.x.x.x) port <span class="number">0</span> AF_INET</span><br><span class="line">Recv   Send    Send</span><br><span class="line">Socket Socket  Message  Elapsed</span><br><span class="line">Size   Size    Size     Time     Throughput</span><br><span class="line"><span class="keyword">bytes</span>  <span class="keyword">bytes</span>   <span class="keyword">bytes</span>    <span class="built_in">secs</span>.    <span class="number">10</span>^<span class="number">6</span>bits/<span class="built_in">sec</span></span><br><span class="line">‎</span><br><span class="line"> <span class="number">87380</span>  <span class="number">16384</span>  <span class="number">16384</span>    <span class="number">10.00</span>    <span class="number">939.64</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure> ‎ 这表示： ‎<p></p></li><li><p>测试类型是TCP流（吞吐量）测试。</p></li><li><p>发送和接收缓冲区的大小分别是16384字节。</p></li><li><p>测试持续了10秒。</p></li><li><p>吞吐量是939.64 Mbps（百万比特每秒）。 ‎</p></li></ul><p>在解读结果时，重要的是要关注与你的测试目标最相关的指标。对于吞吐量测试，你会关注Throughput字段，它表示在测试期间网络连接的平均数据传输速率。对于延迟测试，你会关注往返时间（RTT）或事务延迟。‎netperf是一个强大的工具，可以提供关于网络性能的详细信息。正确地解读这些结果可以帮助你识别网络瓶颈、评估网络设备性能或验证服务质量（QoS）。</p>]]></content>
      
      
      <categories>
          
          <category> benchmark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>question</title>
      <link href="/2023/06/07/interview/"/>
      <url>/2023/06/07/interview/</url>
      
        <content type="html"><![CDATA[<h2 id="过往重点工作">过往重点工作</h2><h3 id="hxt">HXT：</h3><ul><li>QSBv3.1.ppt</li></ul><h3 id="ict">ICT</h3><p>处理器核设计 处理器多核互联设计，互联总线用的什么？</p><h2 id="todo">TODO:</h2><ul><li>PMU事件多核采集的时候：core之间如何同步，保证采集同时段。<ul><li>uarch monitor没有单独采集每个core的？</li><li>整机：每个core的事件的差值计算后，多个core求和，每个core的采集过程并没有同步。</li><li>容器：</li></ul></li></ul><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">perf_event_open</span><span class="params">(<span class="keyword">struct</span> perf_event_attr *attr,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">pid_t</span> pid, <span class="type">int</span> cpu, <span class="type">int</span> group_fd,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">unsigned</span> <span class="type">long</span> flags)</span></span>;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//pid和cpu组合可以实现不同的监控对象</span></span><br><span class="line">The pid <span class="keyword">and</span> cpu arguments allow specifying which process <span class="keyword">and</span> CPU</span><br><span class="line">       to monitor:</span><br><span class="line"> </span><br><span class="line">       pid == <span class="number">0</span> <span class="keyword">and</span> cpu == <span class="number">-1</span> <span class="comment">// 监控当前线程，无论运行在哪个CPU上</span></span><br><span class="line">              This measures the calling process/thread on any CPU.</span><br><span class="line"> </span><br><span class="line">       pid == <span class="number">0</span> <span class="keyword">and</span> cpu &gt;= <span class="number">0</span> <span class="comment">// 监控当前线程，只有运行在指定cpu上才监控</span></span><br><span class="line">              This measures the calling process/thread only when running</span><br><span class="line">              on the specified CPU.</span><br><span class="line"> </span><br><span class="line">       pid &gt; <span class="number">0</span> <span class="keyword">and</span> cpu == <span class="number">-1</span> <span class="comment">// 监控指定的pid线程，无论运行在哪个CPU上</span></span><br><span class="line">              This measures the specified process/thread on any CPU.</span><br><span class="line"> </span><br><span class="line">       pid &gt; <span class="number">0</span> <span class="keyword">and</span> cpu &gt;= <span class="number">0</span> <span class="comment">// 监控指定cpu上的指定的pid线程（容器的监控使用该配置，传入的pid是该容器的fd）</span></span><br><span class="line">              This measures the specified process/thread only when</span><br><span class="line">              running on the specified CPU.</span><br><span class="line"> </span><br><span class="line">       pid == <span class="number">-1</span> <span class="keyword">and</span> cpu &gt;= <span class="number">0</span> <span class="comment">// 监控指定cpu上的所有线程（当前machine监控使用该配置）</span></span><br><span class="line">              This measures all processes/threads on the specified CPU.</span><br><span class="line">              This <span class="keyword">requires</span> <span class="built_in">CAP_PERFMON</span> (since Linux <span class="number">5.8</span>) <span class="keyword">or</span></span><br><span class="line">              CAP_SYS_ADMIN capability <span class="keyword">or</span> a</span><br><span class="line">              /proc/sys/kernel/perf_event_paranoid value of less than <span class="number">1.</span></span><br><span class="line"> </span><br><span class="line">       pid == <span class="number">-1</span> <span class="keyword">and</span> cpu == <span class="number">-1</span></span><br><span class="line">              This setting is invalid <span class="keyword">and</span> will <span class="keyword">return</span> an error.</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><h3 id="为什么要自己写个pmu-monitor不用perf">为什么要自己写个PMUmonitor，不用perf？</h3><ul><li><p>支持优先级采集，一键采集所有的。</p></li><li><p>perf版本没有打平，不同机器上不一样</p></li><li><p>perf不支持容器，uarch monitor如何支持容器的？</p></li><li><p>perf不支持所有事件，例如TMA</p><ul><li>google有个perf patch可以采集TMA L1 bound。但L1不够</li></ul></li></ul><h2 id="经验">经验</h2><ul><li>优先讲熟悉的项目</li><li>直接回答问题，不要先讲其他的</li><li>编译：精度选项可以优化；自己写的汇编没有编译器好。</li><li>如何讲好项目<ul><li>做项目的前期环境</li><li>项目目标</li><li>如何做的，要思路清晰</li><li>达成效果</li></ul></li></ul><p>网卡 大包小包 打散 第三方库共享 内存问题</p><p>1.会更多地关注你的项目:技术、角色、表达能力等 2.技术广度3.技术之外的软技能 沟通能力，跨部门合作之类 负责NUMAV3方案的设计、开发和上线，组织并实现了6个团队(hac、matrix、paas，运维、idw、noah）的协同工作，协同了20+业务方进行NUMA落地并解决落地问题。 对业务的理解和思考全栈的软硬结合的性能分析和优化 理解业务逻辑强化多层次联动的性能分析:业务、内核、编译、微架构从优化手段出发，融会贯通。 难点： 全栈的联合分析调优落地实践的标准化流程</p><p>软硬结合领域，目前CPU领域的调优在学术界已经很成熟，不过落地还有不少工作。还有个方向就是CPU和GPU联合调优分析。</p><p>责任心 4.职业规划相关 职业经历 跳槽的原因：所在项目迟迟无法商业化5.开放性问题 6.你的问题 在招的岗位规划 团队的规模、人员情况了解部门和团队的业务</p><p>这个是技术终面一般会问到的点需要准备个问题（职业生涯中觉得最成功/最有成就感的事情是什么）</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>CPU频率调节器（Governor）和P-state、C-state</title>
      <link href="/2023/06/07/p-state/"/>
      <url>/2023/06/07/p-state/</url>
      
        <content type="html"><![CDATA[<h2 id="cpu频率调节器governor">CPU频率调节器（Governor）</h2><h3 id="performance模式">1.performance模式</h3><ul><li>描述:performance模式将CPU频率固定在最高可用频率。这意味着无论系统负载如何，CPU都会一直运行在其最大频率以提供最佳性能。</li><li>工作原理: 在这种模式下，CPU不进行频率调整，直接运行在最高频率。</li><li>适用场景:<ul><li>高性能计算任务</li><li>游戏服务器</li><li>需要最低延迟和最高吞吐量的应用程序</li></ul></li><li>优点:<ul><li>最大化性能</li><li>最低延迟</li></ul></li><li>缺点:<ul><li>高功耗</li><li>高温度</li><li>可能会缩短硬件寿命</li></ul></li></ul><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有CPU的调节器设置为 performance 模式</span></span><br><span class="line">sudo cpufreq-<span class="built_in">set</span> -r -g performance</span><br></pre></td></tr></tbody></table></figure><h3 id="powersave模式">2.powersave模式</h3><ul><li>描述:powersave模式将CPU频率固定在最低可用频率。这意味着无论系统负载如何，CPU都会一直运行在最低频率以最大限度地节省能量。</li><li>工作原理: 在这种模式下，CPU不进行频率调整，直接运行在最低频率。</li><li>适用场景:<ul><li>电池供电的设备（如笔记本电脑）</li><li>服务器待机模式</li><li>对性能要求不高但对能效要求高的场景</li></ul></li><li>优点:<ul><li>最低功耗</li><li>降低发热量</li><li>延长电池寿命</li></ul></li><li>缺点:<ul><li>性能较低</li><li>可能导致高负载任务运行缓慢 <figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有CPU的调节器设置为 powersave 模式</span></span><br><span class="line">sudo cpufreq-<span class="built_in">set</span> -r -g powersave</span><br></pre></td></tr></tbody></table></figure></li></ul></li></ul><h3 id="conservative模式">3.conservative模式</h3><ul><li>描述:conservative模式根据系统负载逐步调整CPU频率。当负载增加时，频率逐步提升；当负载减少时，频率逐步降低。相比ondemand模式，conservative模式的频率调整更加缓和。</li><li>工作原理:conservative模式会监控CPU负载，当负载超过某个阈值时，逐步提升频率；当负载低于某个阈值时，逐步降低频率。</li><li>适用场景:<ul><li>需要平衡性能和能效的任务</li><li>希望避免频繁的频率波动</li></ul></li><li>优点:<ul><li>平衡性能和能效</li><li>频率调整较为平缓，减少频率变化带来的开销</li></ul></li><li>缺点:<ul><li>响应速度较慢，可能导致短暂的高负载任务性能不佳 <figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有CPU的调节器设置为 conservative 模式</span></span><br><span class="line">sudo cpufreq-<span class="built_in">set</span> -r -g conservative</span><br></pre></td></tr></tbody></table></figure></li></ul></li></ul><h3 id="ondemand模式">4.ondemand模式</h3><ul><li>描述:ondemand模式根据系统负载快速调整CPU频率。当负载增加时，立即将频率提升到最高；当负载减少时，立即将频率降低到最低。</li><li>工作原理:ondemand模式会监控CPU负载，当负载超过某个阈值时，立即将频率提升到最高；当负载低于某个阈值时，立即将频率降低到最低。</li><li>适用场景:<ul><li>动态负载环境，例如桌面系统、普通服务器</li><li>需要快速响应负载变化的场景</li></ul></li><li>优点:<ul><li>能快速响应负载变化</li><li>性能与能效平衡较好</li></ul></li><li>缺点:<ul><li>频繁的频率切换可能导致系统不稳定</li><li>频率切换带来的开销 <figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有CPU的调节器设置为 ondemand 模式</span></span><br><span class="line">sudo cpufreq-<span class="built_in">set</span> -r -g ondemand</span><br></pre></td></tr></tbody></table></figure></li></ul></li></ul><h3 id="schedutil模式">5.schedutil模式</h3><ul><li>描述:schedutil模式基于Linux内核调度器的负载跟踪机制来调整CPU频率。这个调节器利用调度器的负载信息，通常能提供较好的性能和能效平衡。</li><li>工作原理:schedutil模式直接从调度器获取负载信息，并根据这个信息来调整CPU频率。频率调整更加智能和动态。</li><li>适用场景:<ul><li>现代Linux系统</li><li>需要智能频率调整的场景</li></ul></li><li>优点:<ul><li>调整频率更智能</li><li>性能和能效平衡较好</li><li>频率调整更加平滑</li></ul></li><li>缺点:<ul><li>需要较新的内核版本支持</li><li>可能在某些特定场景下不如专门的调节器高效 <figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有CPU的调节器设置为 schedutil 模式</span></span><br><span class="line">sudo cpufreq-<span class="built_in">set</span> -r -g schedutil</span><br></pre></td></tr></tbody></table></figure></li></ul></li></ul><h3 id="选择合适的调节器模式">选择合适的调节器模式</h3><p>选择合适的调节器模式需要根据具体的使用场景和需求来决定： *高性能需求: * 选择performance模式 *适用于需要最高性能的场景，如高性能计算、游戏服务器等。 * 节能需求: *选择powersave模式 *适用于对能效要求高的场景，如电池供电设备、待机模式等。 * 平衡性能和能效:* 选择conservative、ondemand或schedutil模式 *适用于需要动态调整频率以平衡性能和能效的场景，如桌面系统、普通服务器等。</p><h2 id="p-state-performance-state">P-state (Performance State)</h2><h3 id="概述">概述</h3><p>P-state代表CPU的不同性能状态，每个P-state定义了一个特定的电压和频率组合。更高的P-state（如P0）通常意味着更高的频率和电压，从而提供更高的性能和更高的功耗。更低的P-state（如P1,P2等）则意味着较低的频率和电压，从而降低性能和功耗。 ### 工作原理在操作系统或固件的控制下，P-state可以动态调整，以适应当前的工作负载。当系统负载较高时，CPU会使用较高的P-state以获得更高的性能。当系统负载较低时，CPU会使用较低的P-state以节省能量。### 具体实现 * Intel P-state 驱动：Linux内核中有一个专用的IntelP-state驱动程序，它可以直接与Intel处理器硬件交互，以更高效地管理P-state。* AMD P-state驱动：类似地，AMD处理器也有专用的P-state驱动程序，能够更精细地控制P-state。### P-state 的调节器（Governor） * performance: 固定选择最高的P-state。* powersave: 固定选择最低的P-state。 * conservative:根据系统负载逐步调整P-state。 * ondemand: 根据系统负载快速调整P-state。* schedutil: 基于调度器的负载跟踪机制来调整P-state。</p><h3 id="查看p-state信息">查看P-state信息</h3><ol type="1"><li>cpupower 工具 cpupower是一个命令行工具，可以用来查看和管理CPU的P-state。 安装 cpupower： sudoapt-get install linux-tools-common linux-tools-$(uname -r)查看P-state信息： sudo cpupower frequency-info该命令将显示当前CPU频率、可用频率范围、当前调速器（governor）等信息。</li><li>/sys 文件系统 Linux内核通过 /sys文件系统暴露了许多与CPU相关的信息，包括P-state。查看当前调速器（governor）： cat/sys/devices/system/cpu/cpu0/cpufreq/scaling_governor 查看当前CPU频率：cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq查看可用频率范围： cat/sys/devices/system/cpu/cpu0/cpufreq/scaling_available_frequencies查看可用的调速器（governor）： cat/sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors ###设置P-state</li><li>使用 cpupower 工具 你可以使用 cpupower工具来设置P-state，例如设置调速器（governor）和频率范围。设置调速器（governor）： sudo cpupower frequency-set -g performance将调速器设置为 performance 模式。这意味着CPU将尽可能运行在最高频率。设置最小和最大频率： sudo cpupower frequency-set -d 1.2GHz -u 2.8GHz将CPU频率限制在1.2GHz到2.8GHz之间。</li><li>修改 /sys 文件系统 你也可以直接修改 /sys文件系统中的配置文件来设置P-state。 设置调速器（governor）： echo"performance" | sudo tee/sys/devices/system/cpu/cpu<em>/cpufreq/scaling_governor 将调速器设置为performance 模式。 设置最小和最大频率： echo 1200000 | sudo tee/sys/devices/system/cpu/cpu</em>/cpufreq/scaling_min_freq echo 2800000 |sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_max_freq将CPU频率限制在1.2GHz到2.8GHz之间。注意，频率值以千赫兹（kHz）为单位。### 高级配置</li><li>BIOS/UEFI 设置有些系统允许在BIOS或UEFI设置中配置P-state。你可以在启动计算机时进入BIOS/UEFI设置界面，通常通过按下特定的键（如F2,Del,Esc等）。在电源管理或高级设置菜单中，你可能会找到P-state相关的设置。</li><li>内核参数 你可以通过内核参数来配置P-state。例如，Intel处理器可以使用intel_pstate 驱动，并通过内核参数进行配置。 编辑GRUB配置文件/etc/default/grub： sudo nano /etc/default/grub 在GRUB_CMDLINE_LINUX_DEFAULT 行中添加：GRUB_CMDLINE_LINUX_DEFAULT="intel_pstate=enable"更新GRUB配置并重启系统： sudo update-grub sudo reboot</li><li>使用 turbostat 工具 turbostat是另一个强大的工具，可以提供详细的CPU状态信息，包括P-state。 安装turbostat： sudo apt-get install linux-tools-common linux-tools-$(uname-r) 运行 turbostat： sudo turbostat ### 总结通过上述方法，你可以在Linux系统中查看和设置P-state。了解和调整P-state可以帮助优化系统的功耗和性能，特别是在不同的应用场景中。通过合理的配置，可以在性能和能效之间找到最佳平衡点。## C-state (CPU Idle State) ### 概述C-state代表CPU的空闲状态，用于减少CPU在空闲时的功耗。C-state的等级越高，CPU的功耗越低，但从这种状态恢复到工作状态所需的时间也越长。### 工作原理当CPU没有工作负载时，它可以进入不同的C-state以节省能量。C-state从C0（完全活跃）到更高的C-state（如C1,C2,C3等），每个状态减少更多的功耗，但也增加了从该状态恢复到C0的延迟。</li></ol><ul><li>C0: 活跃状态，CPU正在执行指令。</li><li>C1: 轻度空闲状态，CPU停止执行指令，但可以迅速恢复到C0。</li><li>C2: 中度空闲状态，进一步减少功耗，但恢复时间较长。</li><li>C3: 深度空闲状态，CPU缓存被刷新，功耗进一步降低，恢复时间更长。</li><li>Cn: 更高级的空闲状态，可能进一步降低功耗，但恢复时间也更长。 C-state的管理</li><li>操作系统控制：操作系统可以通过ACPI（Advanced Configuration and PowerInterface）管理C-state。操作系统通过查询硬件和固件，决定进入哪个C-state。</li><li>硬件控制：一些C-state（如C1E）由硬件自动管理，而不需要操作系统干预。</li></ul><h3 id="查看c-state信息">查看C-state信息</h3><ol type="1"><li>cpupower 工具 cpupower是一个命令行工具，用于管理和查看CPU的电源管理设置。你可以使用它来查看C-state信息。安装 cpupower： sudo apt-get install linux-tools-commonlinux-tools-$(uname -r) 查看C-state信息： sudo cpupower idle-info</li><li>/sys 文件系统 Linux内核通过 /sys文件系统暴露了许多与CPU相关的信息，包括C-state。 查看C-state统计信息：cat /sys/devices/system/cpu/cpu0/cpuidle/state<em>/name cat/sys/devices/system/cpu/cpu0/cpuidle/state</em>/usage这将显示每个C-state的名称和使用次数。</li><li>turbostat 工具 turbostat是另一个强大的工具，可以提供详细的CPU状态信息，包括C-state。 安装turbostat： sudo apt-get install linux-tools-common linux-tools-$(uname-r) 运行 turbostat： sudo turbostat ### 修改C-state设置</li><li>禁用特定的C-state可以通过内核参数在启动时禁用特定的C-state。例如，要禁用C6状态，可以在引导加载器（如GRUB）的配置文件中添加以下参数：编辑GRUB配置文件 /etc/default/grub： sudo nano /etc/default/grub 在GRUB_CMDLINE_LINUX_DEFAULT 行中添加：GRUB_CMDLINE_LINUX_DEFAULT="intel_idle.max_cstate=5"这将最大C-state限制为C5，从而禁用C6。 更新GRUB配置： sudo update-grub重启系统： sudo reboot</li><li>使用 cpupower 工具 cpupower 工具也可以用于设置C-state。限制最大C-state： sudo cpupower idle-set -d 3 这将禁用C-state3及其以上的状态。 启用所有C-state： sudo cpupower idle-set -e all ###高级配置</li><li>BIOS/UEFI 设置很多系统允许在BIOS或UEFI固件中配置C-state。你可以在启动计算机时进入BIOS/UEFI设置界面，通常通过按下特定的键（如F2,Del,Esc等）。在电源管理或高级设置菜单中，你可能会找到C-state相关的设置，可以启用或禁用特定的C-state。</li><li>内核配置 在编译自定义内核时，可以通过配置选项来控制C-state。编辑内核配置： make menuconfig 导航到 Processor type and features -&gt;CPU idle PM support，然后根据需要启用或禁用特定的C-state支持。 ##P-state 和 C-state 的区别</li></ol><ul><li>P-state:主要用于动态调整CPU的频率和电压，以平衡性能和能效。在运行负载时使用。</li><li>C-state:主要用于减少CPU在空闲状态下的功耗。不同的C-state代表不同的空闲深度和恢复时间。### 交互与优化P-state和C-state经常一起工作，以优化系统的整体性能和能效。</li><li>高负载场景：在高负载情况下，CPU通常在较高的P-state（如P0）运行，以提供最高性能。此时，CPU可能很少进入高等级的C-state。</li><li>低负载或空闲场景：在低负载或空闲情况下，CPU可能会使用较低的P-state，并进入较高等级的C-state，以最大限度地节省能量。</li></ul><h2 id="cpu频率调节器governor与p-state的关系">CPU频率调节器（Governor）与P-state的关系</h2><p>在现代CPU中，特别是Intel和AMD的处理器中，P-state（PerformanceState）和频率调节器（governor）是密切相关的概念，但它们工作在不同的层面上。CPU频率调节器（governor）在操作系统层面工作，它们决定了在给定的负载条件下选择哪一个P-state。可以认为，governor是操作系统用于管理和选择P-state的策略。### 工作原理 1. Governor（操作系统层面）监控系统负载。 2.根据系统负载，Governor决定需要哪种性能状态。 3.Governor选择相应的P-state。 4. CPU根据选择的P-state调整其频率和电压。### 各种Governor与P-state的关系 performance 模式 * 描述:固定选择最高的P-state（如P0）。 * P-state选择:始终选择最高性能的P-state。 * 适用场景: 高性能计算任务、游戏服务器等。powersave 模式 * 描述: 固定选择最低的P-state。 * P-state选择:始终选择最低性能的P-state。 * 适用场景: 电池供电设备、服务器待机模式等。conservative 模式 * 描述: 根据系统负载逐步调整P-state。 * P-state选择:根据负载情况在不同的P-state之间逐步切换。 * 适用场景:平衡性能和能效的任务。 ondemand 模式 * 描述:根据系统负载快速调整P-state。 * P-state选择:负载高时立即选择最高的P-state，负载低时立即选择最低的P-state。 *适用场景: 动态负载环境，例如桌面系统、普通服务器。 schedutil 模式 *描述: 基于Linux内核调度器的负载跟踪机制来调整P-state。 * P-state选择:根据调度器的负载信息动态调整P-state。 * 适用场景:现代Linux系统，适用于各种任务。 ### Intel P-state 驱动对于Intel处理器，Linux内核提供了一个专用的IntelP-state驱动程序，它直接与CPU硬件交互来控制P-state。这种驱动程序可以更高效地管理P-state，因为它可以更精细地调整频率和电压。Intel P-state 驱动的Governor * powersave: 在IntelP-state驱动中，powersave governor并不像传统的powersavegovernor那样固定在最低频率。相反，它会动态调整频率，但倾向于更低的频率，以节省能量。* performance: 在Intel P-state驱动中，performancegovernor将频率尽可能地保持在最高。 ### AMD P-state 驱动类似地，AMD处理器也有专用的P-state驱动程序，能够更精细地控制P-state。不同的调节器模式在AMD处理器上也会有相似的效果。### 总结 * P-state: 由硬件和固件管理，定义不同的频率和电压组合。 *Governor: 由操作系统管理，决定选择哪个P-state以平衡性能和能效。 *Governor与P-state的关系:Governor通过监控系统负载来选择合适的P-state，从而动态调整CPU频率和电压。了解P-state与Governor的关系有助于更好地优化系统性能和能效，通过选择合适的Governor，可以在不同的使用场景中实现最佳的性能和能效平衡。</p>]]></content>
      
      
      <categories>
          
          <category> cpu </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ARM-Ampere-Altra</title>
      <link href="/2023/05/30/ARM-Ampere-Altra/"/>
      <url>/2023/05/30/ARM-Ampere-Altra/</url>
      
        <content type="html"><![CDATA[<h2 id="整体">整体</h2><p>Amper在core，CPU，双路互联3个层面跟Intel和AMD均有差异，需要分析差异并给出对应优化</p><h2 id="core解析">Core解析</h2><p>https://en.wikichip.org/wiki/arm_holdings/microarchitectures/neoverse_n1</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530230049.png" alt="20230530230049"><figcaption aria-hidden="true">20230530230049</figcaption></figure><p>跟x86相比核心的几个差异点：</p><ul><li>指令集不兼容，适配成本高</li><li>弱内存序 vs x86强内存序，需适配</li><li>无HT，L1/L2大，资源独占无竞争，更适合云场景</li></ul><h3 id="指令集">指令集</h3><table><colgroup><col style="width: 50%"><col style="width: 50%"></colgroup><thead><tr><th style="text-align: left;"><strong>指令集</strong></th><th style="text-align: left;"><strong>ARM与x86对比分析</strong></th></tr></thead><tbody><tr><td style="text-align: left;">基础指令</td><td style="text-align: left;">ARM指令与x86指令不兼容，需移植适配</td></tr><tr><td style="text-align: left;">SIMD指令</td><td style="text-align: left;">ARM支持NEON128*2，Intel支持avx512*2，ARM支持avx256*2，单核SIMD性能较差。</td></tr><tr><td style="text-align: left;">原子指令</td><td style="text-align: left;">ARMv8.1支持LSE指令，相比LL/SC性能大幅提升</td></tr><tr><td style="text-align: left;">特殊指令</td><td style="text-align: left;">WFE、WFI，CPU空闲进入低功耗，性能有影响</td></tr></tbody></table><h3 id="弱内存序">弱内存序</h3><p>ARM弱内存序，无锁队列场景需要优化，具体参见：</p><table><thead><tr><th style="text-align: left;"><strong>内存序</strong></th><th style="text-align: left;"><strong>Ampere</strong></th><th style="text-align: left;"><strong>X86</strong></th></tr></thead><tbody><tr><td style="text-align: left;">Load Load</td><td style="text-align: left;">不保证顺序一致性</td><td style="text-align: left;">顺序一致性</td></tr><tr><td style="text-align: left;">Load Store</td><td style="text-align: left;">不保证顺序一致性</td><td style="text-align: left;">顺序一致性</td></tr><tr><td style="text-align: left;">Store Load</td><td style="text-align: left;">不保证顺序一致性</td><td style="text-align: left;">不保证顺序一致性</td></tr><tr><td style="text-align: left;">Store Store</td><td style="text-align: left;">不保证顺序一致性</td><td style="text-align: left;">顺序一致性</td></tr></tbody></table><h3 id="无ht">无HT</h3><p>主频更稳定，功耗优势 <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530225859.png" alt="20230530225859"> <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530225940.png" alt="20230530225940"></p><h3 id="l1l2优势">L1/L2优势</h3><table><thead><tr><th style="text-align: left;"></th><th style="text-align: left;"><strong>Ampere</strong></th><th style="text-align: left;"><strong>Intel cascade</strong></th><th style="text-align: left;"><strong>AMD rome</strong></th></tr></thead><tbody><tr><td style="text-align: left;">L1 大小</td><td style="text-align: left;">64KB</td><td style="text-align: left;">48KB</td><td style="text-align: left;">32KB</td></tr><tr><td style="text-align: left;">L1 延时</td><td style="text-align: left;">1.3ns</td><td style="text-align: left;">1.1ns</td><td style="text-align: left;">1.2ns</td></tr><tr><td style="text-align: left;">L2 大小</td><td style="text-align: left;">1MB</td><td style="text-align: left;">1MB</td><td style="text-align: left;">512KB</td></tr><tr><td style="text-align: left;">L2 延时</td><td style="text-align: left;">4.1ns</td><td style="text-align: left;">4.2ns</td><td style="text-align: left;">3.6ns</td></tr></tbody></table><p>Ampere N1 core参考：<a href="https://en.wikichip.org/wiki/arm_holdings/microarchitectures/neoverse_n1" class="uri">https://en.wikichip.org/wiki/arm_holdings/microarchitectures/neoverse_n1</a></p><h2 id="cpu解析">CPU解析</h2><p>Ampere 是 mesh 结构的 SOC <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530230835.png" alt="20230530230835"></p><p>AMD 是定制soc，有个专门的 IO die，如下：</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530231623.png" alt="20230530231623"><figcaption aria-hidden="true">20230530231623</figcaption></figure><p>intel SRP是多die mesh结构https://www.intel.com/content/www/us/en/developer/articles/technical/fourth-generation-xeon-scalable-family-overview.html</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230531100621.png" alt="20230531100621"><figcaption aria-hidden="true">20230531100621</figcaption></figure><h3 id="subnuma与访存延时">SubNUMA与访存延时</h3><p>•ARM单die多NUMA，SubNUMA调度优化；Intel单die单NUMA架构（截止IceLake）；AMD 多die多NUMA（8个计算die +1个IOdie）</p><p>•ARM多SubNUMA延时跟AMD持平，大于Intel但可接受，多个SubNUMA差别不大，线上配置为单Socket单NUMA</p><table><colgroup><col style="width: 20%"><col style="width: 20%"><col style="width: 20%"><col style="width: 20%"><col style="width: 20%"></colgroup><thead><tr><th style="text-align: left;"><strong>cpubind</strong></th><th style="text-align: left;"><strong>membind</strong></th><th style="text-align: left;"><strong>Ampere altra</strong></th><th style="text-align: left;"><strong>Intel cascade</strong></th><th style="text-align: left;"><strong>AMD rome</strong></th></tr></thead><tbody><tr><td style="text-align: left;">0</td><td style="text-align: left;">0</td><td style="text-align: left;">118ns</td><td style="text-align: left;">80ns</td><td style="text-align: left;">109ns</td></tr><tr><td style="text-align: left;">0</td><td style="text-align: left;">1</td><td style="text-align: left;">119ns</td><td style="text-align: left;">130ns</td><td style="text-align: left;">118ns</td></tr><tr><td style="text-align: left;">0</td><td style="text-align: left;">2</td><td style="text-align: left;">125ns</td><td style="text-align: left;">——</td><td style="text-align: left;">129ns</td></tr><tr><td style="text-align: left;">0</td><td style="text-align: left;">3</td><td style="text-align: left;">128ns</td><td style="text-align: left;">——</td><td style="text-align: left;">131ns</td></tr><tr><td style="text-align: left;">0</td><td style="text-align: left;">4</td><td style="text-align: left;">443ns</td><td style="text-align: left;">——</td><td style="text-align: left;">212ns</td></tr><tr><td style="text-align: left;">0</td><td style="text-align: left;">5</td><td style="text-align: left;">454ns</td><td style="text-align: left;">——</td><td style="text-align: left;">216ns</td></tr><tr><td style="text-align: left;">0</td><td style="text-align: left;">6</td><td style="text-align: left;">446ns</td><td style="text-align: left;">——</td><td style="text-align: left;">205ns</td></tr><tr><td style="text-align: left;">0</td><td style="text-align: left;">7</td><td style="text-align: left;">451ns</td><td style="text-align: left;">——</td><td style="text-align: left;">203ns</td></tr></tbody></table><h3 id="cpm">CPM</h3><p>•相同CPM内的两个core通信更快，需调度优化</p><p>•多个core的L2-L2可直接交互数据</p><p>ampere core2core延迟：</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530230412.png" alt="2-Socket Ampere Altra Q80-33"><figcaption aria-hidden="true">2-Socket Ampere Altra Q80-33</figcaption></figure><p>Ampere与Intel/AMD C2C对比：<a href="https://www.anandtech.com/show/16315/the-ampere-altra-review/3" class="uri">https://www.anandtech.com/show/16315/the-ampere-altra-review/3</a></p><h3 id="l3容量较小延时较大但可接受">L3容量较小，延时较大但可接受</h3><table><thead><tr><th style="text-align: left;"></th><th style="text-align: left;"><strong>Ampere</strong></th><th style="text-align: left;"><strong>Intel cascade</strong></th><th style="text-align: left;"><strong>AMD rome</strong></th></tr></thead><tbody><tr><td style="text-align: left;">L3 大小</td><td style="text-align: left;">32MB</td><td style="text-align: left;">33MB</td><td style="text-align: left;">128MB</td></tr><tr><td style="text-align: left;">L3/core</td><td style="text-align: left;">0.4MB</td><td style="text-align: left;">1.375MB</td><td style="text-align: left;">4MB</td></tr><tr><td style="text-align: left;">L3 延时</td><td style="text-align: left;">30ns</td><td style="text-align: left;">21ns</td><td style="text-align: left;">15ns</td></tr></tbody></table><h2 id="双路互联">双路互联</h2><p>Ampere架构跨路延时大、带宽限制严重影响业务计算和IO性能，需重点优化。</p><p>AmpereAltra本身有设计bug，跨路的PCIE读（PCIE-&gt;memory)延迟大，带宽低。</p><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230531101339.png" alt="20230531101339"><figcaption aria-hidden="true">20230531101339</figcaption></figure><table><thead><tr><th style="text-align: left;"></th><th style="text-align: left;"><strong>Ampere</strong></th><th style="text-align: left;"><strong>Intel cascade</strong></th><th style="text-align: left;"><strong>AMD rome</strong></th></tr></thead><tbody><tr><td style="text-align: left;">跨Socket协议</td><td style="text-align: left;">CCIX</td><td style="text-align: left;">UPI</td><td style="text-align: left;">xGMI</td></tr><tr><td style="text-align: left;">跨Socket访存延时</td><td style="text-align: left;">450ns</td><td style="text-align: left;">130ns</td><td style="text-align: left;">210ns</td></tr><tr><td style="text-align: left;">跨路DMA读带宽</td><td style="text-align: left;">155MB/s</td><td style="text-align: left;">34GB/s</td><td style="text-align: left;">96GB/s</td></tr><tr><td style="text-align: left;">跨路访存带宽</td><td style="text-align: left;">64GB/s</td><td style="text-align: left;">34GB/s</td><td style="text-align: left;">96GB/s</td></tr><tr><td style="text-align: left;">L3跨Socket</td><td style="text-align: left;">不支持</td><td style="text-align: left;">支持</td><td style="text-align: left;">支持</td></tr></tbody></table><h3 id="网卡跨路">网卡跨路</h3><p><strong>现象</strong></p><p>无论netPerf绑定在哪个NUMA，只要网卡中断绑定在NUMA1，那么就会复现“带宽限制的问题”，只要网卡中断绑定在NUMA0，就不存在该问题。</p><p><strong>原因</strong></p><p>对于传统TCP/IP协议栈，网卡数据接收流程：网卡收到数据包后会按预先配置把数据DMA到kernel的memorybuffer(默认在numanode0），然后给CPU发中断，CPU基于中断和软中断处理数据。网卡队列收到数据保存的内存位置如果跟内核memorybuffer是同一个，那么就不会跨Socket DMA 。当前Mellanox的网卡驱动，驱动和内核给每个接收队列单独维护一个内存页池，并优先从该队列相应IRQ绑定的CPU核心所在节点上分配内存页。</p><p><strong>解决方案</strong></p><p>可以通过网卡队列的中断绑定实现对网卡队列数据分配位置的控制。</p><h3 id="磁盘跨路">磁盘跨路</h3><p><strong>现象</strong></p><p>nvme盘在numanode0；fio测试绑定在node1就会有带宽限制。且绑定磁盘队列中断没有效果。</p><p><strong>原因</strong></p><ul><li>device driver: nvme driver的submission和completion队列是nvmedriver在内核启动的时候，在nvmedriver中建立的。所以这部分的内存是和kernel在同一个numa上的.</li><li>Hardware Dispatch queue 直接 调用 nvme driver的nvme_queue_rq来进行的，也就是说，分配的读预内存是在Hardware Dispatchqueue运行的CPU core上的。</li><li>Hardware Dispatch queue/software Dispatchqueue/app的运行numa的关系：Hardware Dispatch queue/software Dispatchqueue应该是在同一个numa上的(除非本numa上的内存全部用完).App直接调用syscall函数(read/open/…)，所以应该也和HardwareDispatch queue/software Dispatch queue在同一个numa上.</li></ul><figure><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230606123857.png" alt="20230606123857"><figcaption aria-hidden="true">20230606123857</figcaption></figure><p><strong>解决方案</strong></p><p>device driver和设备在同一个numa node，但pagecache和app在一个numanode。所以分为两种解决方案： + 不限制app，但pagecache分配到device所在的numanode（内核patch，修改page_cache_alloc）。这种适合对访问内存延迟不敏感的业务。+ 限制app和其使用的disk在一个numanode，适用于对内存延迟敏感的业务，保障业务性能。但可能造成碎片或部署失败。</p><h2 id="参考">参考</h2><p>https://www.anandtech.com/show/16315/the-ampere-altra-review</p>]]></content>
      
      
      <categories>
          
          <category> ARM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memory Consistency Models (X86 VS ARM)</title>
      <link href="/2023/05/29/Memory-Consistency-Models-X86-VS-ARM/"/>
      <url>/2023/05/29/Memory-Consistency-Models-X86-VS-ARM/</url>
      
        <content type="html"><![CDATA[<p><link rel="stylesheet" type="text/css" href="auto-number-title.css"></p><h1 id="memory-consistency-models介绍">Memory ConsistencyModels介绍</h1><p>https://www.cs.utexas.edu/~bornholt/post/memory-models.html</p><table><colgroup><col style="width: 25%"><col style="width: 25%"><col style="width: 25%"><col style="width: 25%"></colgroup><thead><tr><th style="text-align: left;">Memory Consistency Models</th><th style="text-align: left;">特点</th><th style="text-align: left;"><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/memoryConsistency1.png"></th><th style="text-align: left;"><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/memoryConsistency2.png"></th></tr></thead><tbody><tr><td style="text-align: left;"></td><td style="text-align: left;">不同地址一个序</td><td style="text-align: left;">不允许出现00</td><td style="text-align: left;">程序如直观顺序，正确执行</td></tr><tr><td style="text-align: left;"></td><td style="text-align: left;">不同地址写保序，读不保序</td><td style="text-align: left;">允许出现00（不太好理解的顺序）</td><td style="text-align: left;">程序如直观顺序，正确执行</td></tr><tr><td style="text-align: left;">Relaxed memory models</td><td style="text-align: left;"></td><td style="text-align: left;">允许出现00</td><td style="text-align: left;">会出现R2看到 W2，但是 R1没看到 W1</td></tr></tbody></table><h1 id="memory-order-差异">memory order 差异</h1><h2 id="x86">X86</h2><p>x86处理器的内存顺序涉及到内存访问的原子性、顺序性和可见性等方面。下面是x86的内存顺序解析：1.原子性：x86处理器提供了多种原子操作，如xadd、xchg、cmpxchg等。这些操作能够保证内存访问的原子性，即它们能够在不被其他操作打断的情况下执行。2.顺序性：x86处理器的内存顺序遵循一个基本原则：相邻的内存操作之间必须保持顺序一致。也就是说，如果一个内存操作之后还有其他内存操作，那么这些操作必须按照规定的顺序执行。为了确保内存顺序的正确性，x86处理器提供了多种机制，如内存屏障、总线锁定、缓存锁定等。3.可见性：x86处理器使用缓存一致性协议来保证不同处理器的缓存中的数据一致。当一个处理器修改了一个共享变量的值时，它必须通知其他处理器，使得其他处理器缓存中的数据无效，从而保证数据的可见性。总的来说，x86的内存顺序非常复杂，包含了多种机制和协议，以保证内存访问的原子性、顺序性和可见性。这些机制和协议是为了确保多线程程序的正确性和性能。在编写和优化多线程程序时，必须仔细考虑x86的内存顺序，以避免潜在的问题。</p><h2 id="arm">ARM</h2><p>ARM架构的内存模型与x86架构略有不同。在ARM架构中，对于多线程程序中的内存访问顺序，需要使用内存顺序（MemoryOrder）来指定访问顺序。 ARM架构中定义了三种内存顺序： 1.内存顺序未指定（Unspecified memoryorder）未指定内存顺序意味着对于特定的内存访问，没有指定任何顺序关系。这意味着编译器和处理器可以按照任意顺序执行或重排内存访问操作。2. 顺序一致内存顺序（Sequentially consistent memoryorder）顺序一致内存顺序保证所有线程看到的内存访问顺序都是相同的，即所有内存访问按照程序中的顺序执行，不会发生任何重排或乱序操作。这是最保守的内存顺序，也是最容易理解和使用的内存顺序。3. 发布-订阅内存顺序（Release-acquire memoryorder）发布-订阅内存顺序提供了一种更灵活的内存顺序，允许程序员指定一些内存访问之间的顺序关系。在发布-订阅内存顺序中，一个写入操作可以被视为“发布”操作，而一个读取操作可以被视为“订阅”操作。发布-订阅内存顺序保证所有“发布”操作都要先于所有后续的“订阅”操作执行，但不保证所有内存操作按照程序中的顺序执行。在ARM架构中，我们可以使用C++11中的std::memory_order枚举类型来指定内存顺序。常用的内存顺序有：* std::memory_order_relaxed：未指定内存顺序，允许任意顺序执行内存操作。* std::memory_order_seq_cst：顺序一致内存顺序。 *std::memory_order_release：发布-订阅内存顺序中的“发布”操作。 *std::memory_order_acquire：发布-订阅内存顺序中的“订阅”操作。在ARM架构上编写多线程程序时，需要特别注意内存顺序的使用。错误的内存顺序可能会导致程序出现数据竞争、死锁、数据不一致等问题。</p><h2 id="微架构实现">微架构实现</h2><h3 id="问题既然x86和-arm-的架构在-memory-order上不一样那微架构的实现也不一样了x86不能做乱序那不是很影响性能了">问题：既然x86和arm 的架构在 memoryorder上不一样，那微架构的实现也不一样了？x86不能做乱序？那不是很影响性能了？</h3><p>答案：其实x86微架构内部还是乱序执行的，只不过通过顺序提交、乱序读取的检查机制、发现错误后的回滚策略保证其memory order。</p><h3 id="问题具体怎么实现乱序读取的检查发现错误后的回滚呢">问题：具体怎么实现乱序读取的检查、发现错误后的回滚呢？</h3><p>答案：例子: Thread1先进行write address1再执行 write address2；thread2先进行read address2 在进行read address1。</p><p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/memoryConsistency3.png"></p><p>错误情况如何检测呢？ 处理器会 在 STB（store buffer）记录未提交的write（即 store），STB 记录了w1先于 w2的顺序： 1.先执行W2：W2先到HCA2（home coherence agent），获得独占权限（老数据写入core1的cache）。 + 就算是先发送 W1 再发送W2，但是地址不同，W2可能先到其HCA，所以没必要按序发送，只要记录顺序就行。2. 执行 R2，必然 miss，thread1的 core1有独占数据。 +发送请求到HCA2去snoop thread1的 core1去读取数据，core1的W2未提交，thread1的 core1失去独占权限，R2获得W2之前的数据。 + R2不完成，if条件不成立，R1也没办法执行 3. 执行W1：W1到 HCA进行写操作，W1提交 4. 提交W2：发现被 probe 过，重新查 cache，发现不是 E 状态，再去HCA获取E权限，然后提交。</p><p>注意：第三种正确情况不会发生。</p><h3 id="问题io-的-order-是怎么样的">问题：IO 的 order 是怎么样的？</h3><p>答案：IO 的 order 是 PCIE要求的，不能乱序。但是在微架构实现的时候仍然可以选择乱序执行，通过机制保证顺序即可。# 示例假设我们有两个线程A和B，它们共享一个变量x和一个标志变量flag，代码如下所示：</p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Shared variables</span></span><br><span class="line">volatileint x = <span class="number">0</span>;</span><br><span class="line">volatilebool flag = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Thread A</span></span><br><span class="line">x = <span class="number">1</span>;</span><br><span class="line">flag = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Thread B</span></span><br><span class="line"><span class="keyword">if</span> (flag) {</span><br><span class="line">    <span class="type">int</span> y = x + <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// do something with y</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>在这个例子中，线程A会将x设置为1，然后将flag设置为true。线程B会检查flag的值，如果为true，则将x的值加1，并进行一些操作。在x86处理器上，这个程序的行为是可以被正确保证的，因为x86处理器的内存顺序比较严格，会保证写入操作的顺序与代码中的顺序一致。但是，在ARM处理器上，这个程序可能会出现问题。具体来说，如果线程B中的读取操作先于flag的写入操作执行，那么线程B将无法正确地检测到flag的值。此时，线程B将不会执行x的加法操作，导致程序出现错误。为了避免这种情况，我们需要在线程A中插入一个屏障来保证写入操作的顺序，如下所示：</p><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread A</span></span><br><span class="line">x = <span class="number">1</span>;</span><br><span class="line">std::<span class="built_in">atomic_thread_fence</span>(std::memory_order_release); <span class="comment">// 写入屏障</span></span><br><span class="line">flag = <span class="literal">true</span>;</span><br></pre></td></tr></tbody></table></figure><p>在这个例子中，我们在写入操作之后插入了一个写入屏障，以确保写入操作先于标志变量的写入操作执行。这样，即使线程B中的读取操作在写入操作之前执行，也可以正确地检测到flag的值，从而避免程序出现错误。</p><h2 id="例子">例子：</h2><p>hipoas core 问题处理</p>]]></content>
      
      
      <categories>
          
          <category> uarch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
