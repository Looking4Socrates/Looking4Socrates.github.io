<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="The only true wisdom is in knowing you know nothing."><meta name="keywords" content=""><meta name="author" content="Looking4Socrates"><meta name="copyright" content="Looking4Socrates"><title>The unexamined life is not worth living. | Looking For Socrates</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.3.0'
} </script><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230531150845.png"></div><div class="author-info__name text-center">Looking4Socrates</div><div class="author-info__description text-center">The only true wisdom is in knowing you know nothing.</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">16</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">7</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">7</span></a></div></div></div><nav id="nav" style="background-image: url(https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230531150257.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Looking For Socrates</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="site-info"><div id="site-title">Looking For Socrates</div><div id="site-sub-title">The unexamined life is not worth living.</div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/07/benchmark/">benchmark</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-07</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/benchmark/">benchmark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/benchmark/">benchmark</a></span><div class="content"><ul>
<li>memory带宽和延迟的曲线关系<ul>
<li>done：<a target="_blank" rel="noopener" href="https://nga.178.com/read.php?tid=21282980&amp;rand=601">https://nga.178.com/read.php?tid=21282980&amp;rand=601</a> </li>
</ul>
</li>
</ul>
<h2 id="lmbench"><a href="#lmbench" class="headerlink" title="lmbench"></a>lmbench</h2><p>lmbench是一个用来测量Linux/Unix系统性能的工具套件，其名字来源于”LM”, 即 Larry McVoy 和 “benchmark”的组合，Larry McVoy是lmbench的主要开发者。</p>
<p>lmbench工具套件包含多个基准测试工具，每个工具都是用来测量特定系统或硬件性能的，包括CPU（如L1、L2缓存、内存等）、系统调用、管道、进程创建、网络性能（TCP、UDP等）、文件系统等多个方面。该工具套件使用C语言编写，采用微基准测试（micro-benchmark）的方式，即通过大量反复执行简单且对性能影响明显的操作（如读写操作、系统调用）来测量性能。</p>
<p>具体运行时，你可以通过指定参数来选择你想要测试的设备或功能，lmbench将执行相应的操作进行测试，然后统计和分析这些操作的执行时间或者速度，据此来评估系统性能。</p>
<p>其原理主要基于计算机科学中的基准测试原理，即通过一组预定义的操作来客观地评估硬件或软件的性能，并通过这些结果来进行系统优化或者进行设备之间的比较。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36393978/article/details/125989992">https://blog.csdn.net/qq_36393978/article/details/125989992</a></p>
<h2 id="mlc"><a href="#mlc" class="headerlink" title="mlc"></a>mlc</h2><p><a target="_blank" rel="noopener" href="https://www.intel.cn/content/www/cn/zh/developer/articles/tool/intelr-memory-latency-checker.html">https://www.intel.cn/content/www/cn/zh/developer/articles/tool/intelr-memory-latency-checker.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/447936509">https://zhuanlan.zhihu.com/p/447936509</a></p>
<p>Intel开发的Memory Latency Checker（MLC）是一种工具，用于在Intel处理器上测量内存子系统的延迟和带宽。它主要通过两种方法进行测试：</p>
<p>内存延迟测试：MLC使用Load-Use或者Pointer Chasing的方法来测算内存访问的延迟时间。“Load-Use”是将一条指令的输出作为后续指令的输入，通过这种依赖关系测量从内存加载数据到CPU寄存器的时间。“Pointer Chasing”则是创建一个指针数组，然后使CPU沿着这些指针”追踪”数据，这种方法能够有效的测量处理器对内存的访问延迟。</p>
<p>内存带宽测试：MLE通过特定的内存访问模式如顺序访问或随机访问，以及固定数量的并行访问线程，来测量处理器能够达到的最大内存带宽。这个测试能够反映出内存子系统的负载情况，以及多核心间的内存带宽共享情况。</p>
<p>通过这两种方法，MLE可以全面地测量和理解处理器的内存性能，从而帮助系统优化专家针对性的进行硬件调整和软件优化，以充分挖掘和利用计算机系统的定向性能。</p>
<figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">Intel(R) Memory Latency Checker - v3.<span class="number">10</span></span><br><span class="line">Measuring idle latencies for sequential access (in ns)...</span><br><span class="line">        Numa node</span><br><span class="line">Numa node         <span class="number">0</span>	     <span class="number">1</span></span><br><span class="line">       <span class="number">0</span>      <span class="number">83</span>.<span class="number">4</span>	 <span class="number">132</span>.<span class="number">9</span></span><br><span class="line">       <span class="number">1</span>     <span class="number">136</span>.<span class="number">5</span>	  <span class="number">79</span>.<span class="number">7</span></span><br><span class="line"></span><br><span class="line">Measuring Peak Injection Memory Bandwidths for the system</span><br><span class="line">Bandwidths are in MB/sec (<span class="number">1</span> MB/sec = <span class="number">1</span>,<span class="number">000,000</span> Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using traffic with the following read-write ratios</span><br><span class="line">ALL Reads        :    <span class="number">107686.1</span></span><br><span class="line"><span class="number">3</span>:<span class="number">1</span> Reads-Writes :    <span class="number">90658.9</span></span><br><span class="line"><span class="number">2</span>:<span class="number">1</span> Reads-Writes :    <span class="number">86887.9</span></span><br><span class="line"><span class="number">1</span>:<span class="number">1</span> Reads-Writes :    <span class="number">68752.4</span></span><br><span class="line">Stream-triad like:    <span class="number">74245.6</span></span><br><span class="line"></span><br><span class="line">Measuring Memory Bandwidths between nodes within system</span><br><span class="line">Bandwidths are in MB/sec (<span class="number">1</span> MB/sec = <span class="number">1</span>,<span class="number">000,000</span> Bytes/sec)</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using Read-only traffic type</span><br><span class="line">        Numa node</span><br><span class="line">Numa node         <span class="number">0</span>	     <span class="number">1</span></span><br><span class="line">       <span class="number">0    111204.7</span>	<span class="number">34309.2</span></span><br><span class="line">       <span class="number">1    34283.0</span>	<span class="number">110464.5</span></span><br><span class="line"></span><br><span class="line">Measuring Loaded Latencies for the system</span><br><span class="line">Using all the threads from each core if Hyper-threading is enabled</span><br><span class="line">Using Read-only traffic type</span><br><span class="line">Inject    Latency	Bandwidth</span><br><span class="line">Delay    (ns)	MB/sec</span><br><span class="line">==========================</span><br><span class="line"> <span class="number">00000    257</span>.<span class="number">07</span>	 <span class="number">219957.7</span></span><br><span class="line"> <span class="number">00002    257</span>.<span class="number">55</span>	 <span class="number">220385.6</span></span><br><span class="line"> <span class="number">00008    260</span>.<span class="number">01</span>	 <span class="number">219768.3</span></span><br><span class="line"> <span class="number">00015    256</span>.<span class="number">79</span>	 <span class="number">220255.4</span></span><br><span class="line"> <span class="number">00050    253.01</span>	 <span class="number">221044.1</span></span><br><span class="line"> <span class="number">00100    255.28</span>	 <span class="number">220292.6</span></span><br><span class="line"> <span class="number">00200    128.30</span>	 <span class="number">173953.4</span></span><br><span class="line"> <span class="number">00300    111.38</span>	 <span class="number">118262.0</span></span><br><span class="line"> <span class="number">00400    108.22</span>	  <span class="number">89920.4</span></span><br><span class="line"> <span class="number">00500    116.18</span>	  <span class="number">71995.6</span></span><br><span class="line"> <span class="number">00700    105.37</span>	  <span class="number">52788.4</span></span><br><span class="line"> <span class="number">01000</span>     <span class="number">97</span>.<span class="number">67</span>	  <span class="number">37175.9</span></span><br><span class="line"> <span class="number">01300</span>     <span class="number">95</span>.<span class="number">87</span>	  <span class="number">28641.6</span></span><br><span class="line"> <span class="number">01700</span>     <span class="number">94</span>.<span class="number">88</span>	  <span class="number">22091.6</span></span><br><span class="line"> <span class="number">02500</span>     <span class="number">93</span>.<span class="number">82</span>	  <span class="number">15327.3</span></span><br><span class="line"> <span class="number">03500</span>     <span class="number">92</span>.<span class="number">26</span>	  <span class="number">11095.0</span></span><br><span class="line"> <span class="number">05000</span>     <span class="number">92</span>.<span class="number">03</span>	   <span class="number">7988</span>.<span class="number">1</span></span><br><span class="line"> <span class="number">09000</span>     <span class="number">91</span>.<span class="number">29</span>	   <span class="number">4704</span>.<span class="number">6</span></span><br><span class="line"> <span class="number">20000</span>     <span class="number">91</span>.<span class="number">24</span>	   <span class="number">2537</span>.<span class="number">2</span></span><br><span class="line"></span><br><span class="line">Measuring cache-to-cache transfer latency (in ns)...</span><br><span class="line">Local Socket L2-&gt;L2 HIT  latency    <span class="number">51</span>.<span class="number">4</span></span><br><span class="line">Local Socket L2-&gt;L2 HITM latency    <span class="number">51</span>.<span class="number">5</span></span><br><span class="line">Remote Socket L2-&gt;L2 HITM latency (data address homed in writer socket)</span><br><span class="line">            Reader Numa Node</span><br><span class="line">Writer Numa Node     <span class="number">0</span>         <span class="number">1</span></span><br><span class="line">            <span class="number">0</span>         -	 <span class="number">113</span>.<span class="number">5</span></span><br><span class="line">            <span class="number">1</span>     <span class="number">113</span>.<span class="number">5</span>	     -</span><br><span class="line">Remote Socket L2-&gt;L2 HITM latency (data address homed in reader socket)</span><br><span class="line">            Reader Numa Node</span><br><span class="line">Writer Numa Node     <span class="number">0</span>         <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure>
<p>./mlc —loaded_latency -d0 -b${buffer} -${OPERATION} -t${DRATION} -T -k${cores} </p>
<p>在CORES的CPU上配置buffer大小的内存对象，执行OPERATION操作DURATION秒。</p>
<p>mlc —c2c_latency -w${dest} -c${SRC}<br></p><figure class="highlight llvm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="title">@bddwd-sys-xaware08.bddwd.baidu.com</span> Linux]# numactl -N <span class="number">1</span> ./mlc --<span class="keyword">c</span><span class="number">2</span>c_latency -w<span class="number">0</span> -<span class="keyword">c</span><span class="number">24</span></span><br><span class="line">Intel(R) Memory Latency Checker - v<span class="number">3.10</span></span><br><span class="line">Command line parameters: --<span class="keyword">c</span><span class="number">2</span>c_latency -w<span class="number">0</span> -<span class="keyword">c</span><span class="number">24</span></span><br><span class="line"></span><br><span class="line">Measuring cache-<span class="keyword">to</span>-cache transfer latency (in ns)...</span><br><span class="line"></span><br><span class="line">Latency <span class="operator">=</span> <span class="number">294.8</span> base frequency clocks (<span class="number">113.7</span> ns)</span><br><span class="line">[root<span class="title">@bddwd-sys-xaware08.bddwd.baidu.com</span> Linux]# numactl -N <span class="number">1</span> ./mlc --<span class="keyword">c</span><span class="number">2</span>c_latency -w<span class="number">24</span> -<span class="keyword">c</span><span class="number">0</span></span><br><span class="line">Intel(R) Memory Latency Checker - v<span class="number">3.10</span></span><br><span class="line">Command line parameters: --<span class="keyword">c</span><span class="number">2</span>c_latency -w<span class="number">24</span> -<span class="keyword">c</span><span class="number">0</span></span><br><span class="line"></span><br><span class="line">Measuring cache-<span class="keyword">to</span>-cache transfer latency (in ns)...</span><br><span class="line"></span><br><span class="line">Latency <span class="operator">=</span> <span class="number">459.1</span> base frequency clocks (<span class="number">177.0</span> ns)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>原理:copy+scale+add+triad<br>  <img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230607145033.png" alt="20230607145033"></p>
<h3 id="编译安装——Stream"><a href="#编译安装——Stream" class="headerlink" title="编译安装——Stream"></a>编译安装——Stream</h3><h4 id="源码编译安装"><a href="#源码编译安装" class="headerlink" title="源码编译安装"></a>源码编译安装</h4><p>​ 下载源码：<br></p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.cs.virginia.edu/stream/FTP/Code/stream.c</span><br></pre></td></tr></tbody></table></figure><br>​ 解压编译：<br><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -O3 -fopenmp -DSTREAM_ARRAY_SIZE=2000000 -DNTIMES=10 stream.c -o stream</span><br></pre></td></tr></tbody></table></figure><br>​ 参数说明：<br><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">-O3：</span><br><span class="line">    指定最高编译优化级别，即3</span><br><span class="line"></span><br><span class="line">-fopenmp：</span><br><span class="line">    启用OpenMP，适应多处理器环境，更能得到内存带宽实际最大值。开启后，程序默认运行线程为CPU线程数</span><br><span class="line"></span><br><span class="line"><span class="attribute">-DSTREAM_ARRAY_SIZE</span>=2000000：</span><br><span class="line">    指定测试数组a[]、b[]、c[]的大小（Array size）。若stream.c为5.10版本，参数名变为-DSTREAM_ARRAY_SIZE，默认值10000000）。</span><br><span class="line">    注意：必须设置测试数组大小远大于CPU 最高级缓存（一般为L3 Cache）的大小，否则就是测试CPU缓存的吞吐性能，而非内存吞吐性能。</span><br><span class="line">    推荐计算公式：{最高级缓存X MB}×1024×1024×4.1×CPU路数/8，结果取整数</span><br><span class="line">    解释：由于stream.c源码推荐设置至少4倍最高级缓存，且STREAM_ARRAY_SIZE的数据为double类型=8 Byte。所以公式为：最高级缓存(单位：Byte)×4.1倍×CPU路数/8</span><br><span class="line">    例如：测试机器是双路CPU，最高级缓存32MB，则计算值为32×1024×1024×4.1×2/8≈34393292</span><br><span class="line"></span><br><span class="line"><span class="attribute">-DNTIMES</span>=10：</span><br><span class="line">    执行的次数，并从这些结果中选最优值。</span><br><span class="line"></span><br><span class="line">stream.c：</span><br><span class="line">    待编译的源码文件</span><br><span class="line"></span><br><span class="line">stream：</span><br><span class="line">    输出的可执行文件名</span><br><span class="line"></span><br><span class="line">其他参数：</span><br><span class="line"><span class="attribute">-mtune</span>=native <span class="attribute">-march</span>=native：</span><br><span class="line">    针对CPU指令的优化，此处由于编译机即运行机器。故采用native的优化方法。更多编译器对CPU的优化参考</span><br><span class="line">    </span><br><span class="line"><span class="attribute">-mcmodel</span>=medium：</span><br><span class="line">    当单个Memory Array Size 大于2GB时需要设置此参数</span><br><span class="line">    </span><br><span class="line"><span class="attribute">-DOFFSET</span>=4096：</span><br><span class="line">    数组的偏移，一般可以不定义</span><br></pre></td></tr></tbody></table></figure><p></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/407489860">https://zhuanlan.zhihu.com/p/407489860</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/iouwenbo/p/14377478.html">https://www.cnblogs.com/iouwenbo/p/14377478.html</a></p>
<h2 id="multichase"><a href="#multichase" class="headerlink" title="multichase"></a>multichase</h2><p><a target="_blank" rel="noopener" href="https://github.com/google/multichase">https://github.com/google/multichase</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/07/p-state/">C-state and P-state</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-07</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/cpu/">cpu</a></span><div class="content"><h2 id="P-state和C-state"><a href="#P-state和C-state" class="headerlink" title="P-state和C-state"></a>P-state和C-state</h2><h3 id="C-state，也叫做CPU空闲状态，是CPU在没有执行任务时的各种休眠状态。"><a href="#C-state，也叫做CPU空闲状态，是CPU在没有执行任务时的各种休眠状态。" class="headerlink" title="C-state，也叫做CPU空闲状态，是CPU在没有执行任务时的各种休眠状态。"></a>C-state，也叫做CPU空闲状态，是CPU在没有执行任务时的各种休眠状态。</h3><p>各个不同级别的C-state表示着CPU在休眠期间可以关闭的部分和能耗。一般来说，数字越大的C-state说明CPU关闭的部分越多，能耗也就越低。主要有以下几个级别：</p>
<ul>
<li>C0: CPU处于活动状态，正在执行指令。</li>
<li>C1 (Halt): CPU停止执行指令，但可以立即返回C0状态。</li>
<li>C2 (Stop-Clock): 相较于C1，CPU处于更深的休眠状态，关闭更多的内部部品以节省能源，但返回C0状态的代价也比C1略高。</li>
<li>C3 (Sleep): CPU的所有内部缓存都被刷新到主内存中，所有的时钟都被关闭。因此，C3节省的能耗比C2多，但从C3返回C0需要更多的时间。</li>
<li>C4, C5, C6等: 这些都是更深度的C-states，会关闭更多的CPU部分以进一步节省能耗。从这些状态返回C0则需要更多的时间。</li>
</ul>
<p>需要注意的是，具体的CPU型号可能支持的C-state级别以及每个级别的具体作用可能不同，也可能有额外的C-state级别。另外，操作系统和BIOS设置也可能限制了可用的C-state级别。</p>
<h3 id="P-state（P-状态）是-CPU-的性能状态，用于调整-CPU-的工作频率和电压以满足处理需求。"><a href="#P-state（P-状态）是-CPU-的性能状态，用于调整-CPU-的工作频率和电压以满足处理需求。" class="headerlink" title="P-state（P 状态）是 CPU 的性能状态，用于调整 CPU 的工作频率和电压以满足处理需求。"></a>P-state（P 状态）是 CPU 的性能状态，用于调整 CPU 的工作频率和电压以满足处理需求。</h3><p>不同的 CPU 型号和架构具有不同的 P-state 支持，下面是常见的一些 P-state 级别及其特点：</p>
<ol>
<li><p>P0 状态（最高性能状态）：CPU 运行在最高的工作频率，以实现最大的性能。在 P0 状态下，CPU 消耗的功耗和发热最高。</p>
</li>
<li><p>P1 状态：CPU 运行在次高的工作频率，提供相对较高的性能，同时功耗和发热也高于较低级别的 P-state。</p>
</li>
<li><p>P2 状态：CPU 运行在较低的工作频率，提供一定的性能，功耗和发热相对较低。</p>
</li>
<li><p>P3 状态：CPU 运行在较低的工作频率，提供更低的性能，功耗和发热最低。通常在轻负载或空闲状态下使用。</p>
</li>
</ol>
<p>不同的 P-state 级别允许动态调整 CPU 的工作频率和电压，以平衡性能和功耗。当 CPU 负载较高时，会提高 P-state 级别以获得更高的性能，而在负载较低时可以降低 P-state 级别以降低功耗。具体支持的 P-state 级别取决于 CPU 的型号、架构和供应商。</p>
<figure class="highlight tp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CPU <span class="keyword">P</span>-states represent voltage-frequency control states defined as performance states in the industry standard Advanced Configuration and Power Interface (ACPI) specification (see http:<span class="comment">//www.acpi.info for more details).</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">In voltage-frequency control, the voltage and clocks that drive circuits are increased or decreased in response to a workload. The operating system requests specific P-states based on the current workload. The processor may accept or reject the request and set the P-state based on its own state.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">P-states columns represent the processor’s supported frequencies and the time spent in each frequency during the collection period.</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight smali"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C-State residencies are collected from hardware<span class="built_in"> and/or </span>the operating<span class="keyword"> system</span> (OS).</span><br><span class="line">For<span class="keyword"> system</span>s that collect OS C-State residencies, CPU C-states are core power states requested by the Operating System Directed Power Management (OSPM) infrastructure that define the degree to which the processor is <span class="string">"idle"</span>.</span><br><span class="line"></span><br><span class="line">For<span class="keyword"> system</span>s that collect hardware C-State residencies, CPU C-States are obtained by reading the processor’s</span><br><span class="line">MSRs which count the actual time spent in each C-State.</span><br><span class="line">C-States range from C0 to Cn. C0 indicates an active state. All other C-states (C1-Cn) represent idle sleep states where the processor clock is inactive (cannot<span class="built_in"> execute </span>instructions)<span class="built_in"> and </span>different parts of the processor are powered down. As the C-States get deeper, the exit latency duration becomes longer (the time to transition to C0)<span class="built_in"> and </span>the power savings becomes greater.</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/05/30/Ampere-Altra/">Ampere Altra</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-05-30</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/ARM/">ARM</a></span><div class="content"><h1 id="Ampere-Altra"><a href="#Ampere-Altra" class="headerlink" title="Ampere Altra"></a>Ampere Altra</h1><p>参考<br><a target="_blank" rel="noopener" href="https://www.anandtech.com/show/16315/the-ampere-altra-review">https://www.anandtech.com/show/16315/the-ampere-altra-review</a></p>
<h2 id="整体"><a href="#整体" class="headerlink" title="整体"></a>整体</h2><p>Amper在core，CPU，双路互联3个层面跟Intel和AMD均有差异，需要分析差异并给出对应优化</p>
<h2 id="Core解析"><a href="#Core解析" class="headerlink" title="Core解析"></a>Core解析</h2><p><a target="_blank" rel="noopener" href="https://en.wikichip.org/wiki/arm_holdings/microarchitectures/neoverse_n1">https://en.wikichip.org/wiki/arm_holdings/microarchitectures/neoverse_n1</a></p>
<p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530230049.png" alt="20230530230049"></p>
<p>跟x86相比核心的几个差异点：</p>
<ul>
<li>指令集不兼容，适配成本高</li>
<li>弱内存序 vs x86强内存序，需适配</li>
<li>无HT，L1/L2大，资源独占无竞争，更适合云场景</li>
</ul>
<h3 id="指令集"><a href="#指令集" class="headerlink" title="指令集"></a>指令集</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"><strong>指令集</strong></th>
<th style="text-align:left"><strong>ARM与x86对比分析</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">基础指令</td>
<td style="text-align:left">ARM指令与x86指令不兼容，需移植适配</td>
</tr>
<tr>
<td style="text-align:left">SIMD指令</td>
<td style="text-align:left">ARM支持NEON128*2，Intel支持avx512*2，ARM支持avx256*2，单核SIMD性能较差。</td>
</tr>
<tr>
<td style="text-align:left">原子指令</td>
<td style="text-align:left">ARMv8.1支持LSE指令，相比LL/SC性能大幅提升</td>
</tr>
<tr>
<td style="text-align:left">特殊指令</td>
<td style="text-align:left">WFE、WFI，CPU空闲进入低功耗，性能有影响</td>
</tr>
</tbody>
</table>
</div>
<h3 id="弱内存序"><a href="#弱内存序" class="headerlink" title="弱内存序"></a>弱内存序</h3><p>ARM弱内存序，无锁队列场景需要优化，具体参见：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"><strong>内存序</strong></th>
<th style="text-align:left"><strong>Ampere</strong></th>
<th style="text-align:left"><strong>X86</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Load Load</td>
<td style="text-align:left">不保证顺序一致性</td>
<td style="text-align:left">顺序一致性</td>
</tr>
<tr>
<td style="text-align:left">Load Store</td>
<td style="text-align:left">不保证顺序一致性</td>
<td style="text-align:left">顺序一致性</td>
</tr>
<tr>
<td style="text-align:left">Store Load</td>
<td style="text-align:left">不保证顺序一致性</td>
<td style="text-align:left">不保证顺序一致性</td>
</tr>
<tr>
<td style="text-align:left">Store Store</td>
<td style="text-align:left">不保证顺序一致性</td>
<td style="text-align:left">顺序一致性</td>
</tr>
</tbody>
</table>
</div>
<h3 id="无HT"><a href="#无HT" class="headerlink" title="无HT"></a>无HT</h3><p>主频更稳定，功耗优势<br><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530225859.png" alt="20230530225859"><br><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530225940.png" alt="20230530225940"></p>
<h3 id="L1-L2优势"><a href="#L1-L2优势" class="headerlink" title="L1/L2优势"></a>L1/L2优势</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"><strong>Ampere</strong></th>
<th style="text-align:left"><strong>Intel cascade</strong></th>
<th style="text-align:left"><strong>AMD rome</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">L1 大小</td>
<td style="text-align:left">64KB</td>
<td style="text-align:left">48KB</td>
<td style="text-align:left">32KB</td>
</tr>
<tr>
<td style="text-align:left">L1 延时</td>
<td style="text-align:left">1.3ns</td>
<td style="text-align:left">1.1ns</td>
<td style="text-align:left">1.2ns</td>
</tr>
<tr>
<td style="text-align:left">L2 大小</td>
<td style="text-align:left">1MB</td>
<td style="text-align:left">1MB</td>
<td style="text-align:left">512KB</td>
</tr>
<tr>
<td style="text-align:left">L2 延时</td>
<td style="text-align:left">4.1ns</td>
<td style="text-align:left">4.2ns</td>
<td style="text-align:left">3.6ns</td>
</tr>
</tbody>
</table>
</div>
<p>Ampere N1 core参考：<a target="_blank" rel="noopener" href="https://en.wikichip.org/wiki/arm_holdings/microarchitectures/neoverse_n1">https://en.wikichip.org/wiki/arm_holdings/microarchitectures/neoverse_n1</a></p>
<h2 id="CPU解析"><a href="#CPU解析" class="headerlink" title="CPU解析"></a>CPU解析</h2><p>Ampere 是 mesh 结构的 SOC<br><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530230835.png" alt="20230530230835"></p>
<p>AMD 是定制soc，有个专门的 IO die，如下：</p>
<p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530231623.png" alt="20230530231623"></p>
<p>intel SRP是多die mesh结构<br><a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/developer/articles/technical/fourth-generation-xeon-scalable-family-overview.html">https://www.intel.com/content/www/us/en/developer/articles/technical/fourth-generation-xeon-scalable-family-overview.html</a></p>
<p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230531100621.png" alt="20230531100621"></p>
<h3 id="SubNUMA与访存延时"><a href="#SubNUMA与访存延时" class="headerlink" title="SubNUMA与访存延时"></a>SubNUMA与访存延时</h3><p>•ARM单die多NUMA，SubNUMA调度优化；Intel 单die单NUMA架构（截止IceLake）；AMD 多die多NUMA（8个计算die + 1个IOdie）</p>
<p>•ARM多SubNUMA延时跟AMD持平，大于Intel但可接受，多个SubNUMA差别不大，线上配置为单Socket单NUMA</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"><strong>cpubind</strong></th>
<th style="text-align:left"><strong>membind</strong></th>
<th style="text-align:left"><strong>Ampere altra</strong></th>
<th style="text-align:left"><strong>Intel cascade</strong></th>
<th style="text-align:left"><strong>AMD rome</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">0</td>
<td style="text-align:left">118ns</td>
<td style="text-align:left">80ns</td>
<td style="text-align:left">109ns</td>
</tr>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">1</td>
<td style="text-align:left">119ns</td>
<td style="text-align:left">130ns</td>
<td style="text-align:left">118ns</td>
</tr>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">2</td>
<td style="text-align:left">125ns</td>
<td style="text-align:left">——</td>
<td style="text-align:left">129ns</td>
</tr>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">3</td>
<td style="text-align:left">128ns</td>
<td style="text-align:left">——</td>
<td style="text-align:left">131ns</td>
</tr>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">4</td>
<td style="text-align:left">443ns</td>
<td style="text-align:left">——</td>
<td style="text-align:left">212ns</td>
</tr>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">5</td>
<td style="text-align:left">454ns</td>
<td style="text-align:left">——</td>
<td style="text-align:left">216ns</td>
</tr>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">6</td>
<td style="text-align:left">446ns</td>
<td style="text-align:left">——</td>
<td style="text-align:left">205ns</td>
</tr>
<tr>
<td style="text-align:left">0</td>
<td style="text-align:left">7</td>
<td style="text-align:left">451ns</td>
<td style="text-align:left">——</td>
<td style="text-align:left">203ns</td>
</tr>
</tbody>
</table>
</div>
<h3 id="CPM"><a href="#CPM" class="headerlink" title="CPM"></a>CPM</h3><p>•相同CPM内的两个core通信更快，需调度优化</p>
<p>•多个core的L2-L2可直接交互数据</p>
<p>ampere core2core延迟：</p>
<p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230530230412.png" alt="2-Socket Ampere Altra Q80-33"></p>
<p>Ampere与Intel/AMD C2C对比：<a target="_blank" rel="noopener" href="https://www.anandtech.com/show/16315/the-ampere-altra-review/3">https://www.anandtech.com/show/16315/the-ampere-altra-review/3</a></p>
<h3 id="L3容量较小，延时较大但可接受"><a href="#L3容量较小，延时较大但可接受" class="headerlink" title="L3容量较小，延时较大但可接受"></a>L3容量较小，延时较大但可接受</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"><strong>Ampere</strong></th>
<th style="text-align:left"><strong>Intel cascade</strong></th>
<th style="text-align:left"><strong>AMD rome</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">L3 大小</td>
<td style="text-align:left">32MB</td>
<td style="text-align:left">33MB</td>
<td style="text-align:left">128MB</td>
</tr>
<tr>
<td style="text-align:left">L3/core</td>
<td style="text-align:left">0.4MB</td>
<td style="text-align:left">1.375MB</td>
<td style="text-align:left">4MB</td>
</tr>
<tr>
<td style="text-align:left">L3 延时</td>
<td style="text-align:left">30ns</td>
<td style="text-align:left">21ns</td>
<td style="text-align:left">15ns</td>
</tr>
</tbody>
</table>
</div>
<h2 id="双路互联"><a href="#双路互联" class="headerlink" title="双路互联"></a>双路互联</h2><p>Ampere架构跨路延时大、带宽限制严重影响业务计算和IO性能，需重点优化。</p>
<p>Ampere Altra本身有设计bug，跨路的PCIE读（PCIE-&gt;memory)延迟大，带宽低。</p>
<p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230531101339.png" alt="20230531101339"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"><strong>Ampere</strong></th>
<th style="text-align:left"><strong>Intel cascade</strong></th>
<th style="text-align:left"><strong>AMD rome</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">跨Socket协议</td>
<td style="text-align:left">CCIX</td>
<td style="text-align:left">UPI</td>
<td style="text-align:left">xGMI</td>
</tr>
<tr>
<td style="text-align:left">跨Socket访存延时</td>
<td style="text-align:left">450ns</td>
<td style="text-align:left">130ns</td>
<td style="text-align:left">210ns</td>
</tr>
<tr>
<td style="text-align:left">跨路DMA读带宽</td>
<td style="text-align:left">155MB/s</td>
<td style="text-align:left">34GB/s</td>
<td style="text-align:left">96GB/s</td>
</tr>
<tr>
<td style="text-align:left">跨路访存带宽</td>
<td style="text-align:left">64GB/s</td>
<td style="text-align:left">34GB/s</td>
<td style="text-align:left">96GB/s</td>
</tr>
<tr>
<td style="text-align:left">L3跨Socket</td>
<td style="text-align:left">不支持</td>
<td style="text-align:left">支持</td>
<td style="text-align:left">支持</td>
</tr>
</tbody>
</table>
</div>
<h3 id="网卡跨路"><a href="#网卡跨路" class="headerlink" title="网卡跨路"></a>网卡跨路</h3><p><strong>现象</strong></p>
<p>无论netPerf绑定在哪个NUMA，只要网卡中断绑定在NUMA1，那么就会复现“带宽限制的问题”，只要网卡中断绑定在NUMA0，就不存在该问题。</p>
<p><strong>原因</strong></p>
<p>对于传统TCP/IP协议栈，网卡数据接收流程：网卡收到数据包后会按预先配置把数据DMA到kernel的memory buffer(默认在numa node0），然后给CPU发中断，CPU基于中断和软中断处理数据。<br>网卡队列收到数据保存的内存位置如果跟内核memory buffer是同一个，那么就不会跨Socket DMA 。<br>当前Mellanox的网卡驱动，驱动和内核给每个接收队列单独维护一个内存页池，并优先从该队列相应IRQ绑定的CPU核心所在节点上分配内存页。</p>
<p><strong>解决方案</strong></p>
<p>可以通过网卡队列的中断绑定实现对网卡队列数据分配位置的控制。</p>
<h3 id="磁盘跨路"><a href="#磁盘跨路" class="headerlink" title="磁盘跨路"></a>磁盘跨路</h3><p><strong>现象</strong></p>
<p>nvme盘在numa node0；fio测试绑定在node1就会有带宽限制。且绑定磁盘队列中断没有效果。</p>
<p><strong>原因</strong></p>
<ul>
<li>device driver: nvme driver的submission和completion队列是nvme driver在内核启动的时候，在nvme driver中建立的。所以这部分的内存是和kernel在同一个numa上的.</li>
<li>Hardware Dispatch queue 直接 调用 nvme driver 的nvme_queue_rq来进行的，也就是说，分配的读预内存是在Hardware Dispatch queue运行的CPU core上的。</li>
<li>Hardware Dispatch queue/software Dispatch queue/app的运行numa的关系：Hardware Dispatch queue/software Dispatch queue应该是在同一个numa上的(除非本numa上的内存全部用完).App直接调用syscall函数(read/open/…)，所以应该也和Hardware Dispatch queue/software Dispatch queue在同一个numa上.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230606123857.png" alt="20230606123857"></p>
<p><strong>解决方案</strong></p>
<p>device driver和设备在同一个numa node，但pagecache和app在一个numa node。所以分为两种解决方案：</p>
<ul>
<li>不限制app，但page cache分配到device所在的numa node（内核patch，修改page_cache_alloc）。这种适合对访问内存延迟不敏感的业务。</li>
<li>限制app和其使用的disk在一个numa node，适用于对内存延迟敏感的业务，保障业务性能。但可能造成碎片或部署失败。</li>
</ul>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/05/29/Memory-Consistency-Models-X86-VS-ARM/">Memory Consistency Models (X86 VS ARM)</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-05-29</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/uarch/">uarch</a></span><div class="content"><h1 id="Memory-Consistency-Models介绍"><a href="#Memory-Consistency-Models介绍" class="headerlink" title="Memory Consistency Models介绍"></a>Memory Consistency Models介绍</h1><p><a target="_blank" rel="noopener" href="https://www.cs.utexas.edu/~bornholt/post/memory-models.html">https://www.cs.utexas.edu/~bornholt/post/memory-models.html</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Memory Consistency Models</th>
<th style="text-align:left">特点</th>
<th style="text-align:left"><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/memoryConsistency1.png" alt=""></th>
<th style="text-align:left"><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/memoryConsistency2.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><p>SC</p><p>Sequential consistency</p></td>
<td style="text-align:left">不同地址一个序</td>
<td style="text-align:left">不允许出现00</td>
<td style="text-align:left">程序如直观顺序，正确执行</td>
</tr>
<tr>
<td style="text-align:left"><p>TSO</p><p>Total store ordering</p></td>
<td style="text-align:left">不同地址写保序，读不保序</td>
<td style="text-align:left">允许出现00（不太好理解的顺序）</td>
<td style="text-align:left">程序如直观顺序，正确执行</td>
</tr>
<tr>
<td style="text-align:left">Relaxed memory models</td>
<td style="text-align:left"><p>不同地址写不保序。</p><p>读不保序</p></td>
<td style="text-align:left">允许出现00</td>
<td style="text-align:left">会出现R2看到 W2，但是 R1没看到 W1</td>
</tr>
</tbody>
</table>
</div>
<h1 id="memory-order-差异"><a href="#memory-order-差异" class="headerlink" title="memory order 差异"></a>memory order 差异</h1><h2 id="X86"><a href="#X86" class="headerlink" title="X86"></a>X86</h2><p>x86处理器的内存顺序涉及到内存访问的原子性、顺序性和可见性等方面。下面是x86的内存顺序解析：</p>
<ol>
<li>原子性：x86处理器提供了多种原子操作，如xadd、xchg、cmpxchg等。这些操作能够保证内存访问的原子性，即它们能够在不被其他操作打断的情况下执行。</li>
<li>顺序性：x86处理器的内存顺序遵循一个基本原则：相邻的内存操作之间必须保持顺序一致。也就是说，如果一个内存操作之后还有其他内存操作，那么这些操作必须按照规定的顺序执行。为了确保内存顺序的正确性，x86处理器提供了多种机制，如内存屏障、总线锁定、缓存锁定等。</li>
<li>可见性：x86处理器使用缓存一致性协议来保证不同处理器的缓存中的数据一致。当一个处理器修改了一个共享变量的值时，它必须通知其他处理器，使得其他处理器缓存中的数据无效，从而保证数据的可见性。<br>总的来说，x86的内存顺序非常复杂，包含了多种机制和协议，以保证内存访问的原子性、顺序性和可见性。这些机制和协议是为了确保多线程程序的正确性和性能。在编写和优化多线程程序时，必须仔细考虑x86的内存顺序，以避免潜在的问题。</li>
</ol>
<h2 id="ARM"><a href="#ARM" class="headerlink" title="ARM"></a>ARM</h2><p>ARM架构的内存模型与x86架构略有不同。在ARM架构中，对于多线程程序中的内存访问顺序，需要使用内存顺序（Memory Order）来指定访问顺序。<br>ARM架构中定义了三种内存顺序：</p>
<ol>
<li>内存顺序未指定（Unspecified memory order）未指定内存顺序意味着对于特定的内存访问，没有指定任何顺序关系。这意味着编译器和处理器可以按照任意顺序执行或重排内存访问操作。</li>
<li>顺序一致内存顺序（Sequentially consistent memory order）顺序一致内存顺序保证所有线程看到的内存访问顺序都是相同的，即所有内存访问按照程序中的顺序执行，不会发生任何重排或乱序操作。这是最保守的内存顺序，也是最容易理解和使用的内存顺序。</li>
<li>发布-订阅内存顺序（Release-acquire memory order）发布-订阅内存顺序提供了一种更灵活的内存顺序，允许程序员指定一些内存访问之间的顺序关系。在发布-订阅内存顺序中，一个写入操作可以被视为“发布”操作，而一个读取操作可以被视为“订阅”操作。发布-订阅内存顺序保证所有“发布”操作都要先于所有后续的“订阅”操作执行，但不保证所有内存操作按照程序中的顺序执行。<br>在ARM架构中，我们可以使用C++11中的std::memory_order枚举类型来指定内存顺序。常用的内存顺序有：</li>
</ol>
<ul>
<li>std::memory_order_relaxed：未指定内存顺序，允许任意顺序执行内存操作。</li>
<li>std::memory_order_seq_cst：顺序一致内存顺序。</li>
<li>std::memory_order_release：发布-订阅内存顺序中的“发布”操作。</li>
<li>std::memory_order_acquire：发布-订阅内存顺序中的“订阅”操作。<br>在ARM架构上编写多线程程序时，需要特别注意内存顺序的使用。错误的内存顺序可能会导致程序出现数据竞争、死锁、数据不一致等问题。</li>
</ul>
<h2 id="微架构实现"><a href="#微架构实现" class="headerlink" title="微架构实现"></a>微架构实现</h2><h3 id="问题：既然x86和-arm-的架构在-memory-order上不一样，那微架构的实现也不一样了？x86不能做乱序？那不是很影响性能了？"><a href="#问题：既然x86和-arm-的架构在-memory-order上不一样，那微架构的实现也不一样了？x86不能做乱序？那不是很影响性能了？" class="headerlink" title="问题：既然x86和 arm 的架构在 memory order上不一样，那微架构的实现也不一样了？x86不能做乱序？那不是很影响性能了？"></a>问题：既然x86和 arm 的架构在 memory order上不一样，那微架构的实现也不一样了？x86不能做乱序？那不是很影响性能了？</h3><p>答案：其实 x86微架构内部还是乱序执行的，只不过通过顺序提交、乱序读取的检查机制、发现错误后的回滚策略保证其 memory order。</p>
<h3 id="问题：具体怎么实现乱序读取的检查、发现错误后的回滚呢？"><a href="#问题：具体怎么实现乱序读取的检查、发现错误后的回滚呢？" class="headerlink" title="问题：具体怎么实现乱序读取的检查、发现错误后的回滚呢？"></a>问题：具体怎么实现乱序读取的检查、发现错误后的回滚呢？</h3><p>答案：例子: Thread1先进行write address1再执行 write address2；thread2 先进性read address2 在进行read address1。</p>
<p><img src="https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/memoryConsistency3.png" alt=""></p>
<p>错误情况如何检测呢？<br>处理器会 在 STB（store buffer）记录未提交的 write（即 store），STB 记录了w1先于 w2的顺序：</p>
<ol>
<li>先执行W2：W2先到HCA2（home coherence agent），获得独占权限（老数据写入 core1的cache）。<ul>
<li>就算是先发送 W1 再发送 W2，但是地址不同，W2可能先到其HCA，所以没必要按序发送，只要记录顺序就行。</li>
</ul>
</li>
<li>执行 R2，必然 miss，thread1的 core1有独占数据。<ul>
<li>发送请求到HCA2去snoop thread1的 core1 去读取数据，core1的W2未提交，thread1的 core1 失去独占权限，R2获得W2之前的数据。</li>
<li>R2不完成，if 条件不成立，R1也没办法执行</li>
</ul>
</li>
<li>执行W1：W1到 HCA进行写操作，W1提交</li>
<li>提交 W2：发现被 probe 过，重新查 cache，发现不是 E 状态，再去 HCA获取E权限，然后提交。</li>
</ol>
<p>注意：第三种正确情况不会发生。</p>
<h3 id="问题：IO-的-order-是怎么样的？"><a href="#问题：IO-的-order-是怎么样的？" class="headerlink" title="问题：IO 的 order 是怎么样的？"></a>问题：IO 的 order 是怎么样的？</h3><p>答案：IO 的 order 是 PCIE 要求的，不能乱序。但是在微架构实现的时候仍然可以选择乱序执行，通过机制保证顺序即可。</p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><p>假设我们有两个线程A和B，它们共享一个变量x和一个标志变量flag，代码如下所示：</p>
<figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Shared variables</span></span><br><span class="line">volatileint x = <span class="number">0</span>;</span><br><span class="line">volatilebool flag = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Thread A</span></span><br><span class="line">x = <span class="number">1</span>;</span><br><span class="line">flag = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Thread B</span></span><br><span class="line"><span class="keyword">if</span> (flag) {</span><br><span class="line">    <span class="type">int</span> y = x + <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// do something with y</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>在这个例子中，线程A会将x设置为1，然后将flag设置为true。线程B会检查flag的值，如果为true，则将x的值加1，并进行一些操作。<br>在x86处理器上，这个程序的行为是可以被正确保证的，因为x86处理器的内存顺序比较严格，会保证写入操作的顺序与代码中的顺序一致。但是，在ARM处理器上，这个程序可能会出现问题。<br>具体来说，如果线程B中的读取操作先于flag的写入操作执行，那么线程B将无法正确地检测到flag的值。此时，线程B将不会执行x的加法操作，导致程序出现错误。<br>为了避免这种情况，我们需要在线程A中插入一个屏障来保证写入操作的顺序，如下所示：</p>
<figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread A</span></span><br><span class="line">x = <span class="number">1</span>;</span><br><span class="line">std::<span class="built_in">atomic_thread_fence</span>(std::memory_order_release); <span class="comment">// 写入屏障</span></span><br><span class="line">flag = <span class="literal">true</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>在这个例子中，我们在写入操作之后插入了一个写入屏障，以确保写入操作先于标志变量的写入操作执行。这样，即使线程B中的读取操作在写入操作之前执行，也可以正确地检测到flag的值，从而避免程序出现错误。</p>
<h2 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h2><p>hipoas core 问题处理</p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://raw.githubusercontent.com/Looking4Socrates/pic/main/work/20230531150257.png)"><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By Looking4Socrates</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>